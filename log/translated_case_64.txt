I0123 12:31:42.524681 139645810741248 inference_utils.py:69] Parsing gin configuration.
I0123 12:31:42.524785 139645810741248 inference_utils.py:71] Added Gin search path meliad_lib/meliad/transformer/configs
I0123 12:31:42.524995 139645810741248 inference_utils.py:74] Loading Gin config file base_htrans.gin
I0123 12:31:42.525029 139645810741248 inference_utils.py:74] Loading Gin config file size/medium_150M.gin
I0123 12:31:42.525060 139645810741248 inference_utils.py:74] Loading Gin config file options/positions_t5.gin
I0123 12:31:42.525092 139645810741248 inference_utils.py:74] Loading Gin config file options/lr_cosine_decay.gin
I0123 12:31:42.525122 139645810741248 inference_utils.py:74] Loading Gin config file options/seq_1024_nocache.gin
I0123 12:31:42.525149 139645810741248 inference_utils.py:74] Loading Gin config file geometry_150M_generate.gin
I0123 12:31:42.525175 139645810741248 inference_utils.py:76] Overriding Gin param DecoderOnlyLanguageModelGenerate.output_token_losses=True
I0123 12:31:42.525202 139645810741248 inference_utils.py:76] Overriding Gin param TransformerTaskConfig.batch_size=32
I0123 12:31:42.525228 139645810741248 inference_utils.py:76] Overriding Gin param TransformerTaskConfig.sequence_length=128
I0123 12:31:42.525254 139645810741248 inference_utils.py:76] Overriding Gin param Trainer.restore_state_variables=False
I0123 12:31:42.525301 139645810741248 resource_reader.py:50] system_path_file_exists:base_htrans.gin
E0123 12:31:42.525437 139645810741248 resource_reader.py:55] Path not found: base_htrans.gin
I0123 12:31:42.525652 139645810741248 resource_reader.py:50] system_path_file_exists:trainer_configuration.gin
E0123 12:31:42.525761 139645810741248 resource_reader.py:55] Path not found: trainer_configuration.gin
I0123 12:31:42.532147 139645810741248 resource_reader.py:50] system_path_file_exists:size/medium_150M.gin
E0123 12:31:42.532273 139645810741248 resource_reader.py:55] Path not found: size/medium_150M.gin
I0123 12:31:42.532598 139645810741248 resource_reader.py:50] system_path_file_exists:options/positions_t5.gin
E0123 12:31:42.532704 139645810741248 resource_reader.py:55] Path not found: options/positions_t5.gin
I0123 12:31:42.532987 139645810741248 resource_reader.py:50] system_path_file_exists:options/lr_cosine_decay.gin
E0123 12:31:42.533089 139645810741248 resource_reader.py:55] Path not found: options/lr_cosine_decay.gin
I0123 12:31:42.533499 139645810741248 resource_reader.py:50] system_path_file_exists:options/seq_1024_nocache.gin
E0123 12:31:42.533600 139645810741248 resource_reader.py:55] Path not found: options/seq_1024_nocache.gin
I0123 12:31:42.537328 139645810741248 training_loop.py:334] ==== Training loop: initializing model ====
I0123 12:31:42.627858 139645810741248 xla_bridge.py:660] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0123 12:31:42.628569 139645810741248 xla_bridge.py:660] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0123 12:31:42.635292 139645810741248 training_loop.py:335] Process 0 of 1
I0123 12:31:42.635349 139645810741248 training_loop.py:336] Local device count = 1
I0123 12:31:42.635390 139645810741248 training_loop.py:337] Number of replicas = 1
I0123 12:31:42.635423 139645810741248 training_loop.py:339] Using random number seed 42
I0123 12:31:43.092447 139645810741248 training_loop.py:359] Initializing the model.
I0123 12:31:43.489036 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.489266 139645810741248 decoder_stack.py:316] dstack: scanning over 1 windows.
I0123 12:31:43.489365 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489440 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489515 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489599 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489682 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489755 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489824 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489892 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.489959 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.490026 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.490095 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.490163 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 12:31:43.490202 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.490247 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:31:43.490362 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.490402 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.490432 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.492413 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.497659 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.508321 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.508602 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.513251 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.523671 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.523728 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.523765 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.523798 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.523861 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.525021 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.525099 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.525816 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.528237 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.533914 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.535621 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.535702 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.535737 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.535796 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.535923 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.536248 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.536295 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.538198 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.538298 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.541162 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.541241 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.541730 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.551767 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.560553 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.560651 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.560950 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.561030 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:31:43.561140 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.561179 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.561210 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.563041 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.565503 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.571055 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.571314 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.573952 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.578245 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.578357 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.578394 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.578425 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.578501 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.579172 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.579248 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.579631 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.580422 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.582915 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.583544 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.583624 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.583659 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.583716 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.583843 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.584183 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.584226 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.586217 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.586312 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.588830 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.588912 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.589339 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.591650 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.593554 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.593656 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.593953 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.594032 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:31:43.594142 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.594181 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.594212 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.596135 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.598530 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.604497 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.604763 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.607475 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.611555 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.611610 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.611648 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.611680 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.611743 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.612491 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.612567 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.612930 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.613703 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.616227 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.616904 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.617172 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.617207 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.617265 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.617391 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.617725 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.617770 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.619711 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.619804 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.622340 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.622425 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.622925 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.625223 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.627513 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.627608 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.627913 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.627993 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:31:43.628102 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.628141 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.628173 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.630090 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.632518 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.638275 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.638543 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.641220 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.645049 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.645104 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.645140 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.645171 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.645239 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.645812 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.645888 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.646247 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.647023 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.649796 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.650426 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.650503 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.650540 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.650600 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.650735 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.651062 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.651107 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.653049 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.653142 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.655740 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.655829 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.656266 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.658573 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.660498 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.660592 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.660896 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.660976 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:31:43.661087 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.661126 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.661157 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.663083 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.665487 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.671358 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.671621 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.674347 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.678112 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.678167 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.678203 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.678235 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.678297 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.678866 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.678942 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.679300 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.680075 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.682951 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.683575 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.683655 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.683691 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.683756 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.683897 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.684213 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.684256 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.686166 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.686259 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.688822 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.688900 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.689324 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.691619 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.693591 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.693693 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.693990 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.694070 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:31:43.694180 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.694219 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.694251 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.696086 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.698489 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.704123 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.704378 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.707079 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.710816 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.710872 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.710908 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.710940 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.711002 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.711614 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.711690 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.712050 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.712831 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.715323 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.715941 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.716019 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.716055 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.716113 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.716240 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.716564 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.716609 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.718525 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.718618 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.721193 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.721276 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.721713 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.724022 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.725975 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.726071 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.726368 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.726448 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:31:43.726558 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.726597 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.726629 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.728497 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.730977 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.736644 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.736910 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.739563 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.743381 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.743436 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.743472 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.743504 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.743567 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.744137 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.744213 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.744582 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.745364 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.747874 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.748499 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.748578 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.748614 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.748672 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.748799 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.749116 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.749159 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.751157 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.751254 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.753786 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.753868 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.754293 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.756952 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.758886 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.758990 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.759288 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.759374 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:31:43.759485 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.759524 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.759556 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.901876 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.905023 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.910983 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.911288 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.914013 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.917943 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.918001 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.918038 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.918070 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.918133 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.918745 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.918821 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.919187 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.919965 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.922561 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.923191 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.923268 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.923304 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.923364 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.923492 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.923833 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.923877 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.925830 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.925925 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.928495 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.928573 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.929006 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.931329 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.933242 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.933345 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.933645 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.933730 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:31:43.933842 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.933881 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.933914 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.935878 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.938261 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.943905 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.944166 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.946875 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.950630 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.950685 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.950722 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.950754 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.950816 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.951372 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.951447 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.951805 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.952578 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.955129 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.955750 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.955826 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.955861 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.955919 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.956045 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.956360 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.956403 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.958337 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.958430 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.960987 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.961069 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.961495 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.963758 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.965737 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.965834 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.966131 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.966220 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:31:43.966331 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.966370 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.966403 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:43.968220 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.970686 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:43.976399 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.976662 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:43.979708 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:43.983421 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:43.983477 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:43.983513 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:43.983544 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.983606 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.984205 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.984283 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.984642 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.985414 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.987909 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.988534 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.988613 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:43.988649 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:43.988709 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.988835 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:43.989152 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:43.989195 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.991127 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.991221 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.993766 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.993848 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:43.994276 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:43.996563 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:43.998486 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.998584 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:43.998877 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:43.998963 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:31:43.999076 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:43.999116 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:43.999148 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.001000 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.003453 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.009018 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.009301 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.011988 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:44.015757 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.015812 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.015849 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.015880 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.015944 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.016508 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.016584 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.016950 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.017724 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.020219 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.020850 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.020926 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.020962 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.021020 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.021148 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.021463 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.021505 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.023464 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.023561 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.026286 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.026368 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.026788 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.029107 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.031025 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.031122 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.031423 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.031505 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:31:44.031623 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.031663 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.031694 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.033581 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.035977 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.041572 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.041843 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.044481 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:31:44.048325 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.048386 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.048423 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.048454 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.048517 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.049083 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.049159 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.049519 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.050301 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.052792 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.053777 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.053858 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.053894 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.053957 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.054088 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.054409 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.054451 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.056362 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.056455 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.058953 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.059032 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.059512 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.061750 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.063646 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.063740 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.064031 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.064313 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064382 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064448 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064505 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064560 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064613 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064667 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064720 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064772 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064823 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064875 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064925 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 12:31:44.064962 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:31:44.068460 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:31:44.116213 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.116297 139645810741248 decoder_stack.py:333] dstack: autoregressive generator.
I0123 12:31:44.116350 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:31:44.116453 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.116491 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.116522 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.116585 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.118999 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.124480 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.124744 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.127387 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.143862 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.143917 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.143952 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.143983 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.144046 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.145161 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.145241 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.145960 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.147962 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.152715 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.154029 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.154114 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.154151 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.154211 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.154344 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.154456 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.154495 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.156379 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.156475 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.158897 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.158979 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.159091 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.161324 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.163272 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.163368 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.163661 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.163743 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:31:44.163852 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.163892 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.163923 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.163987 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.166250 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.171727 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.171990 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.174664 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.187982 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.188038 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.188074 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.188106 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.188168 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.188728 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.188804 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.189166 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.189870 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.192365 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.192984 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.193060 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.193101 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.193161 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.193289 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.193397 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.193436 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.195370 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.195464 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.197875 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.197954 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.198062 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.200261 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.202190 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.202286 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.202579 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.202660 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:31:44.202770 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.202809 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.202840 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.202903 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.205144 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.210572 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.210832 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.213508 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.226230 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.226286 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.226323 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.226354 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.226417 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.226977 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.227053 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.227418 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.228112 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.230608 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.231236 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.231313 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.231348 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.231413 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.231541 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.231653 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.231693 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.233619 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.233721 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.236171 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.236250 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.236359 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.241753 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.243839 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.243947 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.244252 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.244338 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:31:44.244451 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.244493 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.244525 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.244593 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.246921 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.252394 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.252663 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.255414 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.268289 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.268346 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.268384 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.268418 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.268481 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.269073 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.269148 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.269512 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.270222 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.272747 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.273375 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.273452 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.273487 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.273545 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.273686 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.273797 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.273836 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.275792 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.275886 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.278318 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.278396 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.278506 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.280729 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.282608 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.282702 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.282994 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.283075 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:31:44.283183 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.283223 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.283254 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.283317 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.286101 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.291581 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.291844 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.294508 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.307332 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.307387 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.307424 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.307455 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.307518 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.308079 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.308159 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.308517 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.309218 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.311784 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.312416 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.312493 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.312528 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.312587 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.312727 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.312840 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.312879 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.314782 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.314877 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.317308 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.317386 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.317494 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.319800 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.321678 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.321774 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.322064 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.322146 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:31:44.322255 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.322294 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.322325 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.322388 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.324643 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.330103 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.330363 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.333045 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.345799 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.345854 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.345889 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.345920 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.345981 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.346544 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.346619 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.346981 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.347675 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.350147 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.350766 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.350846 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.350882 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.350940 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.351070 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.351194 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.351233 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.353167 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.353261 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.355672 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.355752 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.355859 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.358215 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.360063 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.360158 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.360445 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.360526 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:31:44.360633 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.360671 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.360702 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.360764 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.363000 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.368519 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.368781 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.371389 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.384051 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.384106 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.384144 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.384177 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.384239 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.384800 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.384876 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.385232 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.385933 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.388417 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.389401 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.389478 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.389514 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.389572 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.389712 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.389827 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.389871 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.391764 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.391859 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.394280 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.394359 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.394466 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.396657 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.398598 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.398694 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.398985 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.399067 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:31:44.399175 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.399214 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.399246 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.399311 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.401551 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.407044 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.407316 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.410020 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.422655 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.422710 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.422745 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.422777 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.422838 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.423446 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.423521 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.423877 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.424572 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.427069 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.427695 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.427772 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.427807 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.427865 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.427990 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.428101 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.428145 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.430042 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.430138 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.432595 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.432673 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.432781 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.434992 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.436872 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.436966 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.437257 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.437337 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:31:44.437445 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.437484 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.437516 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.437580 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.439819 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.445356 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.445620 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.448244 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.461155 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.461210 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.461246 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.461277 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.461339 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.461905 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.461982 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.462337 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.463030 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.465516 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.466190 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.466268 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.466303 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.466362 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.466493 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.466604 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.466643 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.468525 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.468619 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.471036 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.471116 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.471226 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.473425 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.475372 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.475468 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.475758 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.475840 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:31:44.475948 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.475986 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.476017 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.476081 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.478327 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.483749 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.484008 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.486698 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.499609 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.499664 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.499701 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.499733 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.499797 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.500406 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.500483 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.500844 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.501540 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.504009 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.504627 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.504703 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.504738 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.504795 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.504928 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.505037 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.505075 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.506949 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.507047 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.509494 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.509573 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.509689 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.511895 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.513757 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.513851 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.514139 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.514220 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:31:44.514329 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.514368 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.514399 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.514462 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.516697 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.522223 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.522479 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.525102 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.537766 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.537821 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.537858 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.537889 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.537952 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.538509 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.538585 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.538939 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.539633 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.542110 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.542770 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.542848 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.542883 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.542942 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.543073 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.543181 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.543220 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.545096 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.545193 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.547604 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.547682 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.547791 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.549987 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.551891 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.551985 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.552271 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.552351 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:31:44.552459 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.552498 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.552529 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.552591 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.554811 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.560240 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.560498 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.563221 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.575947 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.576003 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.576039 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.576071 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.576133 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.576693 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.576770 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.577130 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.577873 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.580384 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.581002 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.581078 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.581118 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.581179 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.581310 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.581423 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.581464 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.583364 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.583457 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.585879 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.585959 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.586071 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.588347 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.590215 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.590311 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.590598 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.590687 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:31:44.593561 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:31:44.648887 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.648971 139645810741248 decoder_stack.py:333] dstack: autoregressive generator.
I0123 12:31:44.649024 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:31:44.649128 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.649166 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.649197 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.649260 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.651915 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.657274 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.657534 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.660255 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.672646 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.672702 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.672738 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.672769 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.672830 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.673385 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.673461 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.673828 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.674503 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.677011 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.677625 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.677711 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.677747 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.677806 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.677933 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.678048 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.678088 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.679911 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.680004 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.682373 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.682452 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.682562 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.684785 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.686626 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.686722 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.687012 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.687093 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:31:44.687201 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.687241 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.687271 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.687335 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.689548 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.694897 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.695157 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.697791 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.709973 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.710027 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.710064 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.710096 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.710158 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.710709 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.710786 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.711143 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.711830 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.714313 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.714929 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.715182 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.715217 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.715276 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.715402 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.715510 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.715553 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.717394 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.717488 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.719845 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.719924 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.720035 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.722277 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.724113 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.724206 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.724492 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.724573 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:31:44.724680 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.724718 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.724749 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.724810 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.727044 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.732390 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.732650 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.735296 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.747511 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.747566 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.747602 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.747634 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.747696 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.748249 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.748326 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.748686 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.749366 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.751884 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.752493 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.752570 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.752606 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.752665 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.752792 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.752899 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.752938 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.754789 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.754882 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.757250 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.757328 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.757436 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.760100 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.761948 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.762045 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.762337 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.762419 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:31:44.762527 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.762565 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.762597 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.762660 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.764859 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.770183 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.770443 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.773083 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.785416 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.785471 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.785509 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.785556 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.785621 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.786183 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.786258 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.786616 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.787299 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.789832 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.790445 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.790520 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.790554 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.790611 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.790735 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.790841 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.790883 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.792763 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.792853 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.795220 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.795298 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.795404 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.797672 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.799515 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.799607 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.799890 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.799969 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:31:44.800075 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.800112 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.800141 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.800203 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.802438 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.807801 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.808058 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.810741 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.823574 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.823627 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.823662 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.823691 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.823752 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.824298 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.824372 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.824731 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.825417 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.827945 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.828562 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.828637 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.828671 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.828727 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.828852 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.828959 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.828997 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.830867 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.830965 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.833344 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.833421 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.833528 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.835812 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.837666 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.837764 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.838051 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.838130 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:31:44.838236 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.838274 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.838304 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.838364 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.840585 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.845972 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.846229 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.848913 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.861392 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.861446 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.861479 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.861509 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.861571 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.862136 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.862212 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.862574 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.863258 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.865821 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.866428 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.866503 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.866536 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.866592 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.866715 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.866826 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.866863 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.868732 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.868829 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.871218 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.871295 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.871400 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.874064 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.875912 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.876005 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.876291 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.876370 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:31:44.876474 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.876511 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.876540 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.876600 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.878811 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.884177 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.884430 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.887112 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.899614 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.899668 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.899702 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.899733 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.899793 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.900358 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.900433 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.900791 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.901480 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.904004 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.904632 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.904707 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.904742 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.904798 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.904922 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.905028 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.905065 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.906925 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.907017 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.909412 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.909488 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.909594 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.911873 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.913724 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.913818 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.914105 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.914184 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:31:44.914289 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.914326 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.914355 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.914415 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.916749 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.922320 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.922577 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.925261 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.937769 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.937823 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.937857 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.937888 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.937949 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.938509 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.938584 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.938940 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.939633 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.942176 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.942797 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.942872 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.942906 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.942964 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.943089 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.943194 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.943232 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.945096 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.945188 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.947585 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.947669 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.947777 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.950069 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.951924 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.952017 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.952306 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.952385 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:31:44.952491 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.952529 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.952559 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.952620 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.954864 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.960252 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.960510 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:44.963190 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:44.975729 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:44.975784 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:44.975819 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:44.975849 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.975910 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.976475 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.976550 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.976912 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.977593 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.980162 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.980767 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.980843 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:44.980877 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:44.980933 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.981059 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:44.981165 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:44.981202 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.983086 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.983179 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.985564 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.985651 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:44.985761 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:44.988409 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:44.990265 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.990358 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:44.990643 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.990724 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:31:44.990829 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:44.990866 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:44.990897 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:44.990957 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.993169 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:44.998582 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:44.998837 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:45.001493 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:45.013946 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:45.014000 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:45.014033 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:45.014063 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.014124 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.014684 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.014759 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.015117 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.015802 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.018510 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.019285 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.019360 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:45.019394 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:45.019449 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.019572 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:45.019677 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:45.019714 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.022020 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.022112 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.024470 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.024546 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:45.024659 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:45.026910 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.028740 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.028832 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.029119 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.029198 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:31:45.029304 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:45.029341 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:45.029371 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:45.029431 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.031669 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:45.037052 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.037309 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:45.039970 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:45.052443 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:45.052496 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:45.052531 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:45.052561 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.052623 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.053186 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.053261 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.053622 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.054318 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.056854 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.057473 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.057547 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:45.057581 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:45.057636 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.057769 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:45.057877 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:45.057914 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.059761 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.059853 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.062239 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.062318 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:45.062425 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:45.064686 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.066532 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.066627 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.066911 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.066990 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:31:45.067096 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:31:45.067133 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:31:45.067162 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:31:45.067222 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.069443 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:31:45.074801 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.075054 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:31:45.077706 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:31:45.090098 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:31:45.090152 139645810741248 attention.py:418] Single window, no scan.
I0123 12:31:45.090187 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:31:45.090218 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.090278 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.090836 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.090913 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.091274 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.091964 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.094506 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.095123 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.095202 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:31:45.095237 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:31:45.095293 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.095417 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:31:45.095527 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:31:45.095565 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.097414 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.097506 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.099896 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.099974 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:31:45.100081 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:31:45.102725 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:31:45.104600 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.104693 139645810741248 nn_components.py:261] mlp: residual
I0123 12:31:45.104981 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:45.105064 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:31:45.107895 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:31:49.502482 139645810741248 optimizer_config.py:74] Using Flax Adafactor Optimizer. lr=1.000000, b1=0.900000
I0123 12:31:50.054519 139645810741248 training_loop.py:409] No working directory specified.
I0123 12:31:50.054643 139645810741248 training_loop.py:431] Loading pre-trained model from ag_ckpt_vocab:
I0123 12:31:50.055444 139645810741248 checkpoints.py:1062] Restoring legacy Flax checkpoint from ag_ckpt_vocab/checkpoint_10999999
I0123 12:31:53.018386 139645810741248 training_loop.py:447] Only restoring trainable parameters.
I0123 12:31:53.019070 139645810741248 training_loop.py:724] parameter: decoder/embed/embedding, shape (1024, 1024), size 1048576
I0123 12:31:53.019129 139645810741248 training_loop.py:724] parameter: decoder/final_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.019172 139645810741248 training_loop.py:724] parameter: decoder/transformer0/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.019212 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.019252 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019290 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.019328 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019367 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019405 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.019441 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.019477 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019514 139645810741248 training_loop.py:724] parameter: decoder/transformer0/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.019550 139645810741248 training_loop.py:724] parameter: decoder/transformer1/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.019586 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.019621 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019658 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.019693 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019729 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019764 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.019799 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.019847 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.019885 139645810741248 training_loop.py:724] parameter: decoder/transformer1/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.019921 139645810741248 training_loop.py:724] parameter: decoder/transformer10/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.019956 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.019990 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020024 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020059 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020093 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020128 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.020162 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.020197 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020232 139645810741248 training_loop.py:724] parameter: decoder/transformer10/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020267 139645810741248 training_loop.py:724] parameter: decoder/transformer11/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.020302 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.020337 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020372 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020407 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020441 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020476 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.020511 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.020545 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020581 139645810741248 training_loop.py:724] parameter: decoder/transformer11/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020615 139645810741248 training_loop.py:724] parameter: decoder/transformer2/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.020648 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.020683 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020718 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020757 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020793 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020828 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.020862 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.020896 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.020930 139645810741248 training_loop.py:724] parameter: decoder/transformer2/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.020964 139645810741248 training_loop.py:724] parameter: decoder/transformer3/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.020998 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.021031 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021066 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.021100 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021134 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021168 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.021202 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.021236 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021270 139645810741248 training_loop.py:724] parameter: decoder/transformer3/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.021304 139645810741248 training_loop.py:724] parameter: decoder/transformer4/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.021337 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.021371 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021405 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.021439 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021473 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021506 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.021540 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.021574 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021608 139645810741248 training_loop.py:724] parameter: decoder/transformer4/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.021657 139645810741248 training_loop.py:724] parameter: decoder/transformer5/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.021700 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.021736 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021771 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.021807 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021841 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021875 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.021909 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.021943 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.021978 139645810741248 training_loop.py:724] parameter: decoder/transformer5/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022013 139645810741248 training_loop.py:724] parameter: decoder/transformer6/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.022048 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.022082 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022116 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022152 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022186 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022221 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.022255 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.022289 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022324 139645810741248 training_loop.py:724] parameter: decoder/transformer6/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022358 139645810741248 training_loop.py:724] parameter: decoder/transformer7/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.022393 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.022428 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022462 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022495 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022529 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022563 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.022597 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.022637 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022673 139645810741248 training_loop.py:724] parameter: decoder/transformer7/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022707 139645810741248 training_loop.py:724] parameter: decoder/transformer8/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.022742 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.022776 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022811 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.022845 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022880 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.022913 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.022948 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.022982 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.023016 139645810741248 training_loop.py:724] parameter: decoder/transformer8/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.023052 139645810741248 training_loop.py:724] parameter: decoder/transformer9/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 12:31:53.023088 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 12:31:53.023123 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.023158 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.023193 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.023227 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.023262 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 12:31:53.023296 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 12:31:53.023331 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 12:31:53.023365 139645810741248 training_loop.py:724] parameter: decoder/transformer9/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 12:31:53.023392 139645810741248 training_loop.py:725] Total parameters: 152072288
I0123 12:31:53.023596 139645810741248 training_loop.py:739] Total state size: 0
I0123 12:31:53.044753 139645810741248 training_loop.py:492] Training loop: creating task for mode beam_search
I0123 12:31:53.045038 139645810741248 training_loop.py:685] Creating logging writer (train) for mode beam_search
I0123 12:31:53.045686 139645810741248 training_loop.py:652] Compiling mode beam_search with jit.
I0123 12:31:53.046026 139645810741248 training_loop.py:89] registering functions: dict_keys([])
I0123 12:31:53.061894 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b ? para d n o m
I0123 12:31:57.412383 139645810741248 ddar.py:60] Depth 1/1000 time = 4.297642946243286
I0123 12:32:02.540811 139645810741248 ddar.py:60] Depth 2/1000 time = 5.128248453140259
I0123 12:32:08.312956 139645810741248 ddar.py:60] Depth 3/1000 time = 5.77194619178772
I0123 12:32:13.917816 139645810741248 ddar.py:60] Depth 4/1000 time = 5.6046342849731445
I0123 12:32:20.039524 139645810741248 ddar.py:60] Depth 5/1000 time = 6.121342658996582
I0123 12:32:25.345883 139645810741248 ddar.py:60] Depth 6/1000 time = 5.305415868759155
I0123 12:32:31.226583 139645810741248 ddar.py:60] Depth 7/1000 time = 5.880467891693115
I0123 12:32:37.112891 139645810741248 ddar.py:60] Depth 8/1000 time = 5.88610577583313
I0123 12:32:42.957452 139645810741248 ddar.py:60] Depth 9/1000 time = 5.842962980270386
I0123 12:32:48.697483 139645810741248 ddar.py:60] Depth 10/1000 time = 5.726541757583618
I0123 12:32:48.698763 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:32:48.698851 139645810741248 alphageometry.py:540] Depth 0. There are 1 nodes to expand:
I0123 12:32:48.698885 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00
I0123 12:32:48.698914 139645810741248 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00
I0123 12:32:48.846902 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.847074 139645810741248 decoder_stack.py:316] dstack: scanning over 1 windows.
I0123 12:32:48.847166 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847238 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847306 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847371 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847435 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847498 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847561 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847624 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847687 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847750 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847814 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847890 139645810741248 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 12:32:48.847931 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.847975 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:32:48.848078 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:48.848114 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:48.848141 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:48.850018 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.852451 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:48.858023 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.858289 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:48.860943 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:48.865273 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:48.865329 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.865366 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:48.865401 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.865465 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.866155 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.866234 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.866607 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.867399 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.869930 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.870558 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.870635 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:48.870670 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:48.870728 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.870856 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:48.871185 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:48.871227 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.873225 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.873316 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.875825 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.875911 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:48.876351 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:48.878665 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.880626 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.880722 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.881023 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.881111 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:32:48.881223 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:48.881262 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:48.881293 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:48.883201 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.885588 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:48.891329 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.891597 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:48.894326 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:48.898088 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:48.898142 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.898177 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:48.898207 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.898269 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.898838 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.898915 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.899281 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.900087 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.902666 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.903368 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.903446 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:48.903481 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:48.903540 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.903673 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:48.904022 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:48.904067 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.905979 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.906071 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.908596 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.908673 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:48.909094 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:48.911454 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.913418 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.913509 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.913809 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.913894 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:32:48.914002 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:48.914039 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:48.914069 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:48.915894 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.918241 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:48.924483 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.924738 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:48.927290 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:48.930914 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:48.930968 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.931003 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:48.931034 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.931095 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.931699 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.931772 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.932129 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.932884 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.935356 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.935966 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.936041 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:48.936074 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:48.936131 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.936257 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:48.936567 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:48.936608 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.938596 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.938688 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.941131 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.941208 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:48.941628 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:48.943887 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.945815 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.945909 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.946198 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.946277 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:32:48.946389 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:48.946426 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:48.946456 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:48.948304 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.950614 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:48.956179 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.956434 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:48.959022 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:48.962652 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:48.962707 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.962741 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:48.962770 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.962832 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.963387 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.963461 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.963810 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.964567 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.967022 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.967686 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.967761 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:48.967795 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:48.967850 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.967975 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:48.968284 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:48.968325 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.970254 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.970346 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.972782 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.972859 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:48.973281 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:48.975606 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:48.977509 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.977601 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:48.977900 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.977981 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:32:48.978086 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:48.978123 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:48.978158 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:48.979913 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.982229 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:48.987927 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.988184 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:48.990733 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:48.994444 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:48.994498 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:48.994532 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:48.994561 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.994670 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.995222 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.995296 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.995648 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.996400 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.998858 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.999468 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.999543 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:48.999577 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:48.999634 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:48.999759 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.000076 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.000117 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.002078 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.002170 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.004596 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.004673 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.005089 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.007321 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.009222 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.009315 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.009604 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.009690 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:32:49.009797 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.009835 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.009865 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.011693 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.013993 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.019521 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.019775 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.022391 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.025967 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.026021 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.026056 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.026086 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.026147 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.026696 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.026770 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.027122 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.027874 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.030334 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.031346 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.031423 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.031457 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.031514 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.031668 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.031985 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.032026 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.033944 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.034040 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.036525 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.036601 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.037017 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.039296 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.041159 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.041251 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.041538 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.041617 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:32:49.041739 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.041778 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.041808 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.043559 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.045844 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.051411 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.051666 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.054197 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.057813 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.057866 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.057900 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.057930 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.058040 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.058596 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.058670 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.059026 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.059789 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.062237 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.062858 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.062935 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.062968 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.063026 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.063153 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.063467 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.063508 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.065496 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.065587 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.068023 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.068101 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.068513 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.070758 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.072646 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.072739 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.073026 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.073104 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:32:49.073209 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.073246 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.073277 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.075119 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.077420 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.082951 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.083207 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.085814 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.089397 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.089450 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.089484 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.089514 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.089576 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.090134 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.090209 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.090568 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.091324 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.093790 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.094459 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.094652 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.094686 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.094742 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.094867 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.095180 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.095222 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.097142 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.097234 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.099668 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.099745 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.100157 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.102461 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.104364 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.104456 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.104744 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.104823 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:32:49.104928 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.104965 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.104994 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.106978 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.109299 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.114928 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.115184 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.117710 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.121311 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.121365 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.121399 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.121429 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.121490 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.122100 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.122175 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.122534 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.123288 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.125735 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.126340 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.126416 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.126450 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.126506 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.126635 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.126943 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.126983 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.128885 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.128975 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.131466 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.131545 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.131963 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.134208 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.136085 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.136178 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.136469 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.136549 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:32:49.136656 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.136693 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.136723 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.138501 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.141226 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.146817 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.147085 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.149673 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.153310 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.153363 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.153398 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.153427 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.153543 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.154102 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.154175 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.154527 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.155285 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.157735 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.158342 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.158416 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.158450 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.158506 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.158633 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.158942 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.158983 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.160949 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.161040 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.163487 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.163565 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.163980 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.166265 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.168157 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.168250 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.168540 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.168618 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:32:49.168724 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.168762 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.168792 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.170651 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.172959 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.178560 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.178823 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.181372 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.185055 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.185109 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.185143 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.185173 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.185235 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.185796 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.185871 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.186230 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.186993 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.189430 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.190053 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.190127 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.190161 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.190217 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.190343 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.190654 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.190696 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.192677 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.192768 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.195231 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.195309 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.195731 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.197987 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.199898 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.199993 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.200283 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.200362 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:32:49.200469 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.200506 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.200536 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.202400 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.204734 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.210613 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.210867 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.213445 139645810741248 transformer_layer.py:213] tlayer: windowed attention.
I0123 12:32:49.217134 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.217188 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.217222 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.217252 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.217312 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.217872 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.217948 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.218310 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.219077 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.221518 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.222143 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.222220 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.222253 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.222310 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.222434 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.222746 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.222788 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.224750 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.224840 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.227288 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.227367 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.227783 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.230047 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.231941 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.232033 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.232323 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.232569 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232635 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232691 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232743 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232795 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232846 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232897 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232946 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.232996 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.233054 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.233107 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.233157 139645810741248 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 12:32:49.233192 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:32:49.236078 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 12:32:49.280713 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.280795 139645810741248 decoder_stack.py:333] dstack: autoregressive generator.
I0123 12:32:49.280847 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:32:49.280948 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.280985 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.281014 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.281073 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.283451 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.288830 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.289093 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.291700 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.304542 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.304596 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.304631 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.304662 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.304722 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.305279 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.305353 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.305724 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.306421 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.309086 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.309896 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.309972 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.310005 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.310062 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.310192 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.310298 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.310334 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.312305 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.312404 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.314804 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.314881 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.314989 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.317250 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.319094 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.319189 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.319483 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.319562 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:32:49.319671 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.319708 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.319738 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.319799 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.322047 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.327403 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.327660 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.330673 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.343226 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.343281 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.343315 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.343346 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.343408 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.343958 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.344033 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.344392 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.345136 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.347628 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.348243 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.348319 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.348353 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.348411 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.348538 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.348644 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.348680 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.350551 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.350644 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.353049 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.353127 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.353235 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.355518 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.357365 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.357458 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.357760 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.357841 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:32:49.357948 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.357986 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.358016 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.358076 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.360298 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.365695 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.365952 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.368619 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.381036 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.381090 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.381125 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.381157 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.381223 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.381787 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.381862 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.382215 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.382956 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.385437 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.386070 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.386146 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.386180 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.386237 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.386365 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.386472 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.386509 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.388358 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.388447 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.390847 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.390930 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.391038 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.393301 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.395141 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.395234 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.395522 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.395602 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:32:49.395707 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.395744 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.395773 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.395834 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.398056 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.403438 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.403693 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.406369 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.419198 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.419252 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.419286 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.419316 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.419378 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.419937 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.420011 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.420372 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.421116 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.423607 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.424220 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.424295 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.424328 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.424384 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.424510 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.424617 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.424653 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.426497 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.426588 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.428974 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.429060 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.429170 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.431428 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.433261 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.433354 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.433648 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.433730 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:32:49.433835 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.433873 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.433903 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.433963 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.436172 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.441527 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.441798 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.444831 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.457254 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.457307 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.457344 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.457375 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.457435 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.457998 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.458073 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.458427 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.459159 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.461615 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.462245 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.462320 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.462354 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.462411 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.462539 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.462646 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.462683 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.464528 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.464618 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.467026 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.467102 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.467215 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.469456 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.471309 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.471402 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.471688 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.471768 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:32:49.471874 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.471911 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.471941 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.472002 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.474220 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.479598 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.479857 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.482545 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.495015 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.495068 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.495103 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.495134 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.495195 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.495749 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.495822 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.496183 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.496923 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.499402 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.500013 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.500088 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.500121 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.500179 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.500304 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.500411 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.500448 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.502302 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.502394 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.504782 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.504859 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.504966 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.507235 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.509071 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.509162 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.509453 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.509532 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:32:49.509645 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.509685 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.509715 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.509777 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.512006 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.518072 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.518329 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.521035 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.533454 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.533507 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.533541 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.533571 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.533630 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.534188 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.534262 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.534617 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.535353 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.537820 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.538429 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.538502 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.538536 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.538593 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.538717 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.538826 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.538863 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.540711 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.540802 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.543204 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.543280 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.543385 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.545657 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.547504 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.547597 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.547887 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.547966 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:32:49.548071 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.548108 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.548137 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.548198 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.550433 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.555820 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.556081 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.559106 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.571441 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.571496 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.571531 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.571561 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.571621 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.572174 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.572248 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.572604 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.573337 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.575787 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.576401 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.576476 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.576510 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.576566 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.576695 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.576802 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.576839 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.578695 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.578787 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.581188 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.581265 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.581373 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.583618 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.585458 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.585550 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.585848 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.585927 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:32:49.586033 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.586070 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.586099 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.586158 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.588368 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.593740 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.594001 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.596659 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.609025 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.609079 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.609114 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.609144 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.609206 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.609771 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.609846 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.610207 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.610896 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.613419 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.614040 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.614116 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.614149 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.614206 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.614335 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.614444 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.614480 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.616346 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.616437 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.619046 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.619124 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.619232 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.621711 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.623564 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.623663 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.623955 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.624036 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:32:49.624145 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.624183 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.624213 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.624273 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.626512 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.631894 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.632151 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.634839 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.647225 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.647278 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.647312 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.647343 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.647403 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.647950 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.648024 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.648376 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.649055 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.651567 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.652179 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.652253 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.652287 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.652342 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.652467 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.652570 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.652607 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.654472 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.654563 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.656939 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.657014 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.657120 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.659368 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.661204 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.661302 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.661594 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.661680 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:32:49.661788 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.661826 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.661856 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.661917 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.664141 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.669545 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.669811 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.672857 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.846151 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.846278 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.846317 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.846351 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.846435 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.847070 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.847148 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.847517 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.848232 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.850819 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.851453 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.851530 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.851565 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.851626 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.851757 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.851870 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.851908 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.853986 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.854082 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.856557 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.856634 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.856742 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.859016 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.860883 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.860977 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.861285 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.861369 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:32:49.861480 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.861518 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.861547 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.861613 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.864030 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.869576 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.869846 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.872552 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.885337 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.885392 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.885427 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.885456 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.885517 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.886073 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.886149 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.886518 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.887232 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.889773 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.890394 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.890473 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.890507 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.890565 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.890697 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.890808 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.890846 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.892735 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.892828 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.895250 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.895331 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.895440 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.897693 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.899588 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.899685 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.899984 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.900080 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:32:49.902944 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 12:32:49.953951 139645810741248 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.954034 139645810741248 decoder_stack.py:333] dstack: autoregressive generator.
I0123 12:32:49.954086 139645810741248 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 12:32:49.954186 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.954223 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.954253 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.954316 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.956645 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:49.961972 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.962229 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:49.964849 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:49.977226 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:49.977284 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:49.977319 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:49.977350 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.977411 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.977988 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.978066 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.978430 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.979120 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.981592 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.982283 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.982361 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:49.982396 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:49.982455 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.982586 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:49.982695 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:49.982733 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.984616 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.984710 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.987163 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.987244 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:49.987354 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:49.989589 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:49.991896 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.991995 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:49.992304 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.992388 139645810741248 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 12:32:49.992497 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:49.992536 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:49.992568 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:49.992630 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:49.994940 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.000277 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.000533 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.003154 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.015357 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.015411 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.015445 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.015475 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.015536 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.016081 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.016155 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.016508 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.017170 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.019571 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.020176 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.020250 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.020283 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.020338 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.020462 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.020567 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.020603 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.022480 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.022573 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.025149 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.025227 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.025335 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.027654 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.029609 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.029715 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.030015 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.030098 139645810741248 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 12:32:50.030208 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.030247 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.030279 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.030340 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.032604 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.038080 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.038347 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.041031 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.053458 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.053513 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.053547 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.053578 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.053638 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.054198 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.054272 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.054622 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.055288 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.057698 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.058309 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.058384 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.058417 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.058475 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.058600 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.058706 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.058743 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.060621 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.060712 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.063078 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.063157 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.063266 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.065448 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.067372 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.067473 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.067769 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.067849 139645810741248 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 12:32:50.067955 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.067993 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.068022 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.068081 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.070316 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.075767 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.076061 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.078731 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.091922 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.091978 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.092013 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.092044 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.092108 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.092680 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.092757 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.093125 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.093838 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.096347 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.096982 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.097058 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.097092 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.097149 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.097276 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.097385 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.097423 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.099395 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.099491 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.101949 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.102031 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.102144 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.104408 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.106335 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.106434 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.106726 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.106806 139645810741248 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 12:32:50.106913 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.106951 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.106980 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.107039 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.109238 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.114705 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.114964 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.117592 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.130207 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.130261 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.130295 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.130325 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.130386 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.130983 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.131058 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.131410 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.132276 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.134876 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.135512 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.135601 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.135636 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.135694 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.135827 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.135937 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.135977 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.137928 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.138038 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.140530 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.140607 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.140715 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.142872 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.144736 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.144829 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.145134 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.145216 139645810741248 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 12:32:50.145327 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.145366 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.145396 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.145459 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.147729 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.153241 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.153500 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.156141 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.168749 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.168802 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.168836 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.168866 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.168927 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.169475 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.169549 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.169909 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.170584 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.173083 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.173745 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.173821 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.173855 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.173911 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.174036 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.174143 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.174180 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.176063 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.176153 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.178529 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.178610 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.178720 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.180923 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.183185 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.183282 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.183587 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.183676 139645810741248 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 12:32:50.183787 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.183825 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.183855 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.183918 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.186140 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.191544 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.191809 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.194380 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.206912 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.206969 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.207005 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.207036 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.207098 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.207667 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.207744 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.208132 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.208803 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.211343 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.211987 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.212074 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.212108 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.212164 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.212289 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.212394 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.212430 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.214271 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.214366 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.216836 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.216917 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.217030 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.219362 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.221271 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.221367 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.221671 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.221760 139645810741248 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 12:32:50.221871 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.221910 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.221941 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.222004 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.224297 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.229846 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.230112 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.233013 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.245553 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.245609 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.245651 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.245685 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.245746 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.246351 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.246426 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.246780 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.247453 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.249883 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.250492 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.250565 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.250598 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.250654 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.250779 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.250884 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.250921 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.252748 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.252837 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.255309 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.255388 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.255499 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.257750 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.259643 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.259736 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.260033 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.260120 139645810741248 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 12:32:50.260232 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.260271 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.260301 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.260364 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.262669 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.268298 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.268563 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.271236 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.284106 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.284163 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.284198 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.284231 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.284293 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.284862 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.284938 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.285304 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.286017 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.288559 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.289190 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.289267 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.289302 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.289361 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.289490 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.289601 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.289638 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.292004 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.292100 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.294589 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.294669 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.294781 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.296999 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.298886 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.298982 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.299278 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.299358 139645810741248 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 12:32:50.299474 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.299514 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.299545 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.299609 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.301815 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.307320 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.307586 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.310153 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.322704 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.322760 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.322796 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.322828 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.322889 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.323460 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.323536 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.323900 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.324583 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.327063 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.327703 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.327780 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.327816 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.327875 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.328003 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.328111 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.328149 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.330075 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.330166 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.332612 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.332688 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.332795 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.335350 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.337171 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.337263 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.337552 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.337630 139645810741248 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 12:32:50.337744 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.337787 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.337818 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.337879 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.340092 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.345601 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.345865 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.348428 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.360868 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.360924 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.360958 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.360988 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.361047 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.361595 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.361680 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.362039 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.362710 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.365157 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.365775 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.365851 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.365885 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.365942 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.366066 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.366174 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.366211 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.368186 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.368279 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.370681 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.370758 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.370864 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.373031 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.374866 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.374959 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.375247 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.375325 139645810741248 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 12:32:50.375430 139645810741248 transformer_layer.py:154] tlayer: recurrent = False
I0123 12:32:50.375467 139645810741248 transformer_layer.py:155] tlayer: compute_importance = False
I0123 12:32:50.375504 139645810741248 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 12:32:50.375567 139645810741248 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.377830 139645810741248 transformer_base.py:161] kvq: pre_attn dropout.
I0123 12:32:50.383447 139645810741248 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.383713 139645810741248 transformer_base.py:194] kvq: normalize keys, queries.
I0123 12:32:50.386298 139645810741248 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 12:32:50.399077 139645810741248 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 12:32:50.399134 139645810741248 attention.py:418] Single window, no scan.
I0123 12:32:50.399171 139645810741248 transformer_layer.py:389] tlayer: self-attention.
I0123 12:32:50.399203 139645810741248 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.399265 139645810741248 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.399836 139645810741248 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.399918 139645810741248 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.400274 139645810741248 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.400957 139645810741248 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.403491 139645810741248 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.404124 139645810741248 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.404199 139645810741248 transformer_layer.py:468] tlayer: End windows.
I0123 12:32:50.404234 139645810741248 transformer_layer.py:472] tlayer: final FFN.
I0123 12:32:50.404292 139645810741248 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.404420 139645810741248 transformer_base.py:410] tbase: post-attention MLP.
I0123 12:32:50.404530 139645810741248 nn_components.py:325] mlp: activation = None
I0123 12:32:50.404568 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.406898 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.406995 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.409443 139645810741248 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.409518 139645810741248 transformer_base.py:443] tbase: final FFN
I0123 12:32:50.409625 139645810741248 nn_components.py:320] mlp: hidden 4096, relu
I0123 12:32:50.411889 139645810741248 nn_components.py:329] mlp: final activation = None
I0123 12:32:50.413732 139645810741248 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.413823 139645810741248 nn_components.py:261] mlp: residual
I0123 12:32:50.414110 139645810741248 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:32:50.414193 139645810741248 decoder_stack.py:344] dstack: Final layernorm.
I0123 12:32:50.417057 139645810741248 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 12:33:05.454089 139645810741248 alphageometry.py:566] LM output (score=-1.391655): "p : C b l p 23 D b p l p 24 ;"
I0123 12:33:05.454235 139645810741248 alphageometry.py:567] Translation: "p = on_line p b l, on_bline p l b"

I0123 12:33:05.454278 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b ? para d n o m"
I0123 12:33:05.454457 139645810741248 graph.py:498] 
I0123 12:33:05.454514 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b ? para d n o m
I0123 12:33:11.144194 139645810741248 ddar.py:60] Depth 1/1000 time = 5.589576244354248
I0123 12:33:18.230013 139645810741248 ddar.py:60] Depth 2/1000 time = 7.085592985153198
I0123 12:33:25.144021 139645810741248 ddar.py:60] Depth 3/1000 time = 6.913815259933472
I0123 12:33:32.677470 139645810741248 ddar.py:60] Depth 4/1000 time = 7.533273696899414
I0123 12:33:39.640737 139645810741248 ddar.py:60] Depth 5/1000 time = 6.962846040725708
I0123 12:33:46.982291 139645810741248 ddar.py:60] Depth 6/1000 time = 7.34065055847168
I0123 12:33:54.776553 139645810741248 ddar.py:60] Depth 7/1000 time = 7.794080018997192
I0123 12:34:02.261571 139645810741248 ddar.py:60] Depth 8/1000 time = 7.4848151206970215
I0123 12:34:09.533279 139645810741248 ddar.py:60] Depth 9/1000 time = 7.2696733474731445
I0123 12:34:17.302582 139645810741248 ddar.py:60] Depth 10/1000 time = 7.7551109790802
I0123 12:34:17.305813 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:34:17.305918 139645810741248 alphageometry.py:566] LM output (score=-1.507002): "p : C b g p 23 D b p g p 24 ;"
I0123 12:34:17.305956 139645810741248 alphageometry.py:567] Translation: "p = on_line p b g, on_bline p g b"

I0123 12:34:17.305998 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b ? para d n o m"
I0123 12:34:17.306193 139645810741248 graph.py:498] 
I0123 12:34:17.306255 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b ? para d n o m
I0123 12:34:22.165953 139645810741248 ddar.py:60] Depth 1/1000 time = 4.768452882766724
I0123 12:34:28.057426 139645810741248 ddar.py:60] Depth 2/1000 time = 5.891242504119873
I0123 12:34:34.310330 139645810741248 ddar.py:60] Depth 3/1000 time = 6.252620220184326
I0123 12:34:40.347451 139645810741248 ddar.py:60] Depth 4/1000 time = 6.0369343757629395
I0123 12:34:46.598582 139645810741248 ddar.py:60] Depth 5/1000 time = 6.250773668289185
I0123 12:34:52.951001 139645810741248 ddar.py:60] Depth 6/1000 time = 6.351414918899536
I0123 12:34:59.229512 139645810741248 ddar.py:60] Depth 7/1000 time = 6.27831244468689
I0123 12:35:05.337877 139645810741248 ddar.py:60] Depth 8/1000 time = 6.108180999755859
I0123 12:35:11.930018 139645810741248 ddar.py:60] Depth 9/1000 time = 6.590193510055542
I0123 12:35:18.611997 139645810741248 ddar.py:60] Depth 10/1000 time = 6.667413711547852
I0123 12:35:18.614307 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:35:18.614404 139645810741248 alphageometry.py:566] LM output (score=-1.740747): "p : C g m p 23 D g p m p 24 ;"
I0123 12:35:18.614442 139645810741248 alphageometry.py:567] Translation: "p = on_line p g m, on_bline p m g"

I0123 12:35:18.614484 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p g m, on_bline p m g ? para d n o m"
I0123 12:35:18.614680 139645810741248 graph.py:498] 
I0123 12:35:18.614744 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p g m, on_bline p m g ? para d n o m
I0123 12:35:23.627397 139645810741248 ddar.py:60] Depth 1/1000 time = 4.8497374057769775
I0123 12:35:29.549618 139645810741248 ddar.py:60] Depth 2/1000 time = 5.922038555145264
I0123 12:35:35.883784 139645810741248 ddar.py:60] Depth 3/1000 time = 6.333969354629517
I0123 12:35:42.408954 139645810741248 ddar.py:60] Depth 4/1000 time = 6.524961233139038
I0123 12:35:48.733233 139645810741248 ddar.py:60] Depth 5/1000 time = 6.323822736740112
I0123 12:35:55.359714 139645810741248 ddar.py:60] Depth 6/1000 time = 6.625553846359253
I0123 12:36:02.033319 139645810741248 ddar.py:60] Depth 7/1000 time = 6.673360824584961
I0123 12:36:08.655782 139645810741248 ddar.py:60] Depth 8/1000 time = 6.622284650802612
I0123 12:36:15.739006 139645810741248 ddar.py:60] Depth 9/1000 time = 7.081198453903198
I0123 12:36:22.318708 139645810741248 ddar.py:60] Depth 10/1000 time = 6.565783262252808
I0123 12:36:22.321834 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:36:22.321933 139645810741248 alphageometry.py:566] LM output (score=-1.741044): "p : C j m p 23 D j p m p 24 ;"
I0123 12:36:22.321969 139645810741248 alphageometry.py:567] Translation: "p = on_line p j m, on_bline p m j"

I0123 12:36:22.322008 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p j m, on_bline p m j ? para d n o m"
I0123 12:36:22.322199 139645810741248 graph.py:498] 
I0123 12:36:22.322262 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p j m, on_bline p m j ? para d n o m
I0123 12:36:27.032111 139645810741248 ddar.py:60] Depth 1/1000 time = 4.669304609298706
I0123 12:36:33.344494 139645810741248 ddar.py:60] Depth 2/1000 time = 6.31221866607666
I0123 12:36:39.747739 139645810741248 ddar.py:60] Depth 3/1000 time = 6.40306544303894
I0123 12:36:46.154124 139645810741248 ddar.py:60] Depth 4/1000 time = 6.406185626983643
I0123 12:36:52.561141 139645810741248 ddar.py:60] Depth 5/1000 time = 6.40654182434082
I0123 12:36:59.054723 139645810741248 ddar.py:60] Depth 6/1000 time = 6.492635488510132
I0123 12:37:05.465516 139645810741248 ddar.py:60] Depth 7/1000 time = 6.410556316375732
I0123 12:37:12.270076 139645810741248 ddar.py:60] Depth 8/1000 time = 6.804378032684326
I0123 12:37:18.951501 139645810741248 ddar.py:60] Depth 9/1000 time = 6.679214954376221
I0123 12:37:25.992798 139645810741248 ddar.py:60] Depth 10/1000 time = 7.02669882774353
I0123 12:37:25.996297 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:37:25.996393 139645810741248 alphageometry.py:566] LM output (score=-1.851887): "p : C b m p 23 D b p m p 24 ;"
I0123 12:37:25.996430 139645810741248 alphageometry.py:567] Translation: "p = on_line p b m, on_bline p m b"

I0123 12:37:25.996467 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b m, on_bline p m b ? para d n o m"
I0123 12:37:25.996654 139645810741248 graph.py:498] 
I0123 12:37:25.996713 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b m, on_bline p m b ? para d n o m
I0123 12:37:30.814591 139645810741248 ddar.py:60] Depth 1/1000 time = 4.6977033615112305
I0123 12:37:37.357909 139645810741248 ddar.py:60] Depth 2/1000 time = 6.543142318725586
I0123 12:37:43.754111 139645810741248 ddar.py:60] Depth 3/1000 time = 6.39601731300354
I0123 12:37:50.548011 139645810741248 ddar.py:60] Depth 4/1000 time = 6.7937092781066895
I0123 12:37:56.939766 139645810741248 ddar.py:60] Depth 5/1000 time = 6.391345262527466
I0123 12:38:03.606272 139645810741248 ddar.py:60] Depth 6/1000 time = 6.665588617324829
I0123 12:38:10.212334 139645810741248 ddar.py:60] Depth 7/1000 time = 6.605844259262085
I0123 12:38:17.249522 139645810741248 ddar.py:60] Depth 8/1000 time = 7.037010669708252
I0123 12:38:24.232182 139645810741248 ddar.py:60] Depth 9/1000 time = 6.980656623840332
I0123 12:38:31.015908 139645810741248 ddar.py:60] Depth 10/1000 time = 6.76779842376709
I0123 12:38:31.019501 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:38:31.019599 139645810741248 alphageometry.py:566] LM output (score=-1.941036): "p : C e m p 23 D e p m p 24 ;"
I0123 12:38:31.019635 139645810741248 alphageometry.py:567] Translation: "p = on_line p e m, on_bline p m e"

I0123 12:38:31.019675 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p e m, on_bline p m e ? para d n o m"
I0123 12:38:31.019881 139645810741248 graph.py:498] 
I0123 12:38:31.019944 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p e m, on_bline p m e ? para d n o m
I0123 12:38:35.876905 139645810741248 ddar.py:60] Depth 1/1000 time = 4.820589780807495
I0123 12:38:42.265966 139645810741248 ddar.py:60] Depth 2/1000 time = 6.388902425765991
I0123 12:38:48.712075 139645810741248 ddar.py:60] Depth 3/1000 time = 6.445927143096924
I0123 12:38:55.348361 139645810741248 ddar.py:60] Depth 4/1000 time = 6.636079788208008
I0123 12:39:02.003077 139645810741248 ddar.py:60] Depth 5/1000 time = 6.654315948486328
I0123 12:39:08.763271 139645810741248 ddar.py:60] Depth 6/1000 time = 6.759272336959839
I0123 12:39:15.682974 139645810741248 ddar.py:60] Depth 7/1000 time = 6.919501304626465
I0123 12:39:22.403953 139645810741248 ddar.py:60] Depth 8/1000 time = 6.720787525177002
I0123 12:39:29.230021 139645810741248 ddar.py:60] Depth 9/1000 time = 6.824096202850342
I0123 12:39:36.236901 139645810741248 ddar.py:60] Depth 10/1000 time = 6.990388870239258
I0123 12:39:36.239849 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:39:36.239954 139645810741248 alphageometry.py:566] LM output (score=-1.966065): "p : C j l p 23 D j p l p 24 ;"
I0123 12:39:36.239991 139645810741248 alphageometry.py:567] Translation: "p = on_line p j l, on_bline p l j"

I0123 12:39:36.240031 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p j l, on_bline p l j ? para d n o m"
I0123 12:39:36.240230 139645810741248 graph.py:498] 
I0123 12:39:36.240292 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p j l, on_bline p l j ? para d n o m
I0123 12:39:41.457532 139645810741248 ddar.py:60] Depth 1/1000 time = 5.11046576499939
I0123 12:39:47.823586 139645810741248 ddar.py:60] Depth 2/1000 time = 6.365812540054321
I0123 12:39:54.179480 139645810741248 ddar.py:60] Depth 3/1000 time = 6.355600833892822
I0123 12:40:01.006988 139645810741248 ddar.py:60] Depth 4/1000 time = 6.827310562133789
I0123 12:40:07.436178 139645810741248 ddar.py:60] Depth 5/1000 time = 6.428768873214722
I0123 12:40:13.585585 139645810741248 ddar.py:60] Depth 6/1000 time = 6.148292541503906
I0123 12:40:20.699249 139645810741248 ddar.py:60] Depth 7/1000 time = 7.113451957702637
I0123 12:40:27.414665 139645810741248 ddar.py:60] Depth 8/1000 time = 6.715233564376831
I0123 12:40:34.220387 139645810741248 ddar.py:60] Depth 9/1000 time = 6.803776979446411
I0123 12:40:41.027831 139645810741248 ddar.py:60] Depth 10/1000 time = 6.793558359146118
I0123 12:40:41.031250 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:40:41.031359 139645810741248 alphageometry.py:566] LM output (score=-2.040067): "p : C i m p 23 D i p m p 24 ;"
I0123 12:40:41.031410 139645810741248 alphageometry.py:567] Translation: "p = on_line p i m, on_bline p m i"

I0123 12:40:41.031453 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p i m, on_bline p m i ? para d n o m"
I0123 12:40:41.031647 139645810741248 graph.py:498] 
I0123 12:40:41.031711 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p i m, on_bline p m i ? para d n o m
I0123 12:40:46.088413 139645810741248 ddar.py:60] Depth 1/1000 time = 4.895852565765381
I0123 12:40:52.379165 139645810741248 ddar.py:60] Depth 2/1000 time = 6.290534496307373
I0123 12:40:59.072322 139645810741248 ddar.py:60] Depth 3/1000 time = 6.692859411239624
I0123 12:41:05.398031 139645810741248 ddar.py:60] Depth 4/1000 time = 6.3255345821380615
I0123 12:41:12.039015 139645810741248 ddar.py:60] Depth 5/1000 time = 6.640571594238281
I0123 12:41:18.745058 139645810741248 ddar.py:60] Depth 6/1000 time = 6.7051074504852295
I0123 12:41:25.668548 139645810741248 ddar.py:60] Depth 7/1000 time = 6.9233009815216064
I0123 12:41:32.528665 139645810741248 ddar.py:60] Depth 8/1000 time = 6.8599348068237305
I0123 12:41:39.354079 139645810741248 ddar.py:60] Depth 9/1000 time = 6.8234076499938965
I0123 12:41:46.183830 139645810741248 ddar.py:60] Depth 10/1000 time = 6.815784692764282
I0123 12:41:46.186511 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:41:46.186614 139645810741248 alphageometry.py:566] LM output (score=-2.040455): "p : C i l p 23 D i p l p 24 ;"
I0123 12:41:46.186652 139645810741248 alphageometry.py:567] Translation: "p = on_line p i l, on_bline p l i"

I0123 12:41:46.186693 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p i l, on_bline p l i ? para d n o m"
I0123 12:41:46.186889 139645810741248 graph.py:498] 
I0123 12:41:46.186953 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p i l, on_bline p l i ? para d n o m
I0123 12:41:51.267780 139645810741248 ddar.py:60] Depth 1/1000 time = 5.014496088027954
I0123 12:41:57.275434 139645810741248 ddar.py:60] Depth 2/1000 time = 6.007430791854858
I0123 12:42:03.982189 139645810741248 ddar.py:60] Depth 3/1000 time = 6.706472396850586
I0123 12:42:10.415054 139645810741248 ddar.py:60] Depth 4/1000 time = 6.432679653167725
I0123 12:42:17.114945 139645810741248 ddar.py:60] Depth 5/1000 time = 6.699434995651245
I0123 12:42:23.859143 139645810741248 ddar.py:60] Depth 6/1000 time = 6.743154525756836
I0123 12:42:31.149092 139645810741248 ddar.py:60] Depth 7/1000 time = 7.289740085601807
I0123 12:42:37.731634 139645810741248 ddar.py:60] Depth 8/1000 time = 6.582359075546265
I0123 12:42:44.868193 139645810741248 ddar.py:60] Depth 9/1000 time = 7.134531497955322
I0123 12:42:51.764828 139645810741248 ddar.py:60] Depth 10/1000 time = 6.881292343139648
I0123 12:42:51.768269 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:42:51.768368 139645810741248 alphageometry.py:566] LM output (score=-2.133115): "p : C b c p 23 D b p c p 24 ;"
I0123 12:42:51.768405 139645810741248 alphageometry.py:567] Translation: "p = on_line p b c, on_bline p c b"

I0123 12:42:51.768445 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b c, on_bline p c b ? para d n o m"
I0123 12:42:51.768640 139645810741248 graph.py:498] 
I0123 12:42:51.768702 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b c, on_bline p c b ? para d n o m
I0123 12:42:56.904353 139645810741248 ddar.py:60] Depth 1/1000 time = 5.057892084121704
I0123 12:43:03.630681 139645810741248 ddar.py:60] Depth 2/1000 time = 6.726147890090942
I0123 12:43:10.337565 139645810741248 ddar.py:60] Depth 3/1000 time = 6.706690549850464
I0123 12:43:16.992754 139645810741248 ddar.py:60] Depth 4/1000 time = 6.655002593994141
I0123 12:43:24.021214 139645810741248 ddar.py:60] Depth 5/1000 time = 7.027996778488159
I0123 12:43:30.513463 139645810741248 ddar.py:60] Depth 6/1000 time = 6.491045236587524
I0123 12:43:37.435704 139645810741248 ddar.py:60] Depth 7/1000 time = 6.922062873840332
I0123 12:43:45.003033 139645810741248 ddar.py:60] Depth 8/1000 time = 7.567115068435669
I0123 12:43:51.811002 139645810741248 ddar.py:60] Depth 9/1000 time = 6.8057777881622314
I0123 12:43:59.304880 139645810741248 ddar.py:60] Depth 10/1000 time = 7.475567579269409
I0123 12:43:59.307376 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:43:59.307472 139645810741248 alphageometry.py:566] LM output (score=-2.144320): "p : C b i p 23 D b p i p 24 ;"
I0123 12:43:59.307508 139645810741248 alphageometry.py:567] Translation: "p = on_line p b i, on_bline p i b"

I0123 12:43:59.307547 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b i, on_bline p i b ? para d n o m"
I0123 12:43:59.307738 139645810741248 graph.py:498] 
I0123 12:43:59.307798 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b i, on_bline p i b ? para d n o m
I0123 12:44:06.054223 139645810741248 ddar.py:60] Depth 1/1000 time = 6.513486623764038
I0123 12:44:14.489449 139645810741248 ddar.py:60] Depth 2/1000 time = 8.435017108917236
I0123 12:44:22.707891 139645810741248 ddar.py:60] Depth 3/1000 time = 8.218276739120483
I0123 12:44:30.934487 139645810741248 ddar.py:60] Depth 4/1000 time = 8.226396083831787
I0123 12:44:39.012805 139645810741248 ddar.py:60] Depth 5/1000 time = 8.077945470809937
I0123 12:44:47.401054 139645810741248 ddar.py:60] Depth 6/1000 time = 8.38731074333191
I0123 12:44:55.675330 139645810741248 ddar.py:60] Depth 7/1000 time = 8.273966073989868
I0123 12:45:04.542786 139645810741248 ddar.py:60] Depth 8/1000 time = 8.867273330688477
I0123 12:45:13.003813 139645810741248 ddar.py:60] Depth 9/1000 time = 8.459158420562744
I0123 12:45:21.764034 139645810741248 ddar.py:60] Depth 10/1000 time = 8.745567798614502
I0123 12:45:21.766342 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:45:21.766440 139645810741248 alphageometry.py:566] LM output (score=-2.186073): "p : C b j p 23 D b p j p 24 ;"
I0123 12:45:21.766478 139645810741248 alphageometry.py:567] Translation: "p = on_line p b j, on_bline p j b"

I0123 12:45:21.766516 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b j, on_bline p j b ? para d n o m"
I0123 12:45:21.766710 139645810741248 graph.py:498] 
I0123 12:45:21.766771 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b j, on_bline p j b ? para d n o m
I0123 12:45:28.539306 139645810741248 ddar.py:60] Depth 1/1000 time = 6.623902797698975
I0123 12:45:36.703548 139645810741248 ddar.py:60] Depth 2/1000 time = 8.164056301116943
I0123 12:45:44.850667 139645810741248 ddar.py:60] Depth 3/1000 time = 8.146945476531982
I0123 12:45:53.035117 139645810741248 ddar.py:60] Depth 4/1000 time = 8.184251308441162
I0123 12:46:01.148768 139645810741248 ddar.py:60] Depth 5/1000 time = 8.113230466842651
I0123 12:46:09.293819 139645810741248 ddar.py:60] Depth 6/1000 time = 8.144150733947754
I0123 12:46:18.271935 139645810741248 ddar.py:60] Depth 7/1000 time = 8.97790813446045
I0123 12:46:26.747877 139645810741248 ddar.py:60] Depth 8/1000 time = 8.475743293762207
I0123 12:46:35.516538 139645810741248 ddar.py:60] Depth 9/1000 time = 8.766681432723999
I0123 12:46:44.110307 139645810741248 ddar.py:60] Depth 10/1000 time = 8.579184770584106
I0123 12:46:44.112363 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:46:44.112458 139645810741248 alphageometry.py:566] LM output (score=-2.256518): "p : C e l p 23 D e p l p 24 ;"
I0123 12:46:44.112493 139645810741248 alphageometry.py:567] Translation: "p = on_line p e l, on_bline p l e"

I0123 12:46:44.112529 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p e l, on_bline p l e ? para d n o m"
I0123 12:46:44.112731 139645810741248 graph.py:498] 
I0123 12:46:44.112792 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p e l, on_bline p l e ? para d n o m
I0123 12:46:49.861347 139645810741248 ddar.py:60] Depth 1/1000 time = 5.695716381072998
I0123 12:46:57.085464 139645810741248 ddar.py:60] Depth 2/1000 time = 7.2239298820495605
I0123 12:47:04.437711 139645810741248 ddar.py:60] Depth 3/1000 time = 7.352043867111206
I0123 12:47:12.372679 139645810741248 ddar.py:60] Depth 4/1000 time = 7.934784173965454
I0123 12:47:19.871337 139645810741248 ddar.py:60] Depth 5/1000 time = 7.49822735786438
I0123 12:47:27.344521 139645810741248 ddar.py:60] Depth 6/1000 time = 7.472245931625366
I0123 12:47:35.105249 139645810741248 ddar.py:60] Depth 7/1000 time = 7.760540008544922
I0123 12:47:42.936250 139645810741248 ddar.py:60] Depth 8/1000 time = 7.830801963806152
I0123 12:47:50.991626 139645810741248 ddar.py:60] Depth 9/1000 time = 8.053342819213867
I0123 12:47:59.210957 139645810741248 ddar.py:60] Depth 10/1000 time = 8.204572200775146
I0123 12:47:59.214510 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:47:59.214624 139645810741248 alphageometry.py:566] LM output (score=-2.267478): "p : C g l p 23 D g p l p 24 ;"
I0123 12:47:59.214661 139645810741248 alphageometry.py:567] Translation: "p = on_line p g l, on_bline p l g"

I0123 12:47:59.214707 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p g l, on_bline p l g ? para d n o m"
I0123 12:47:59.214916 139645810741248 graph.py:498] 
I0123 12:47:59.215018 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p g l, on_bline p l g ? para d n o m
I0123 12:48:04.253127 139645810741248 ddar.py:60] Depth 1/1000 time = 4.949718952178955
I0123 12:48:10.664179 139645810741248 ddar.py:60] Depth 2/1000 time = 6.410874128341675
I0123 12:48:17.326871 139645810741248 ddar.py:60] Depth 3/1000 time = 6.662522792816162
I0123 12:48:24.104619 139645810741248 ddar.py:60] Depth 4/1000 time = 6.777542352676392
I0123 12:48:30.547695 139645810741248 ddar.py:60] Depth 5/1000 time = 6.442608594894409
I0123 12:48:37.232164 139645810741248 ddar.py:60] Depth 6/1000 time = 6.683537721633911
I0123 12:48:44.212997 139645810741248 ddar.py:60] Depth 7/1000 time = 6.9806060791015625
I0123 12:48:51.156051 139645810741248 ddar.py:60] Depth 8/1000 time = 6.942812919616699
I0123 12:48:57.880026 139645810741248 ddar.py:60] Depth 9/1000 time = 6.722031831741333
I0123 12:49:04.896918 139645810741248 ddar.py:60] Depth 10/1000 time = 7.002295732498169
I0123 12:49:04.899977 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:49:04.900098 139645810741248 alphageometry.py:566] LM output (score=-2.337226): "p : C h m p 23 D h p m p 24 ;"
I0123 12:49:04.900148 139645810741248 alphageometry.py:567] Translation: "p = on_line p h m, on_bline p m h"

I0123 12:49:04.900254 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p h m, on_bline p m h ? para d n o m"
I0123 12:49:04.900467 139645810741248 graph.py:498] 
I0123 12:49:04.900529 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p h m, on_bline p m h ? para d n o m
I0123 12:49:12.787195 139645810741248 ddar.py:60] Depth 1/1000 time = 7.850812673568726
I0123 12:49:21.506208 139645810741248 ddar.py:60] Depth 2/1000 time = 8.718848943710327
I0123 12:49:30.481637 139645810741248 ddar.py:60] Depth 3/1000 time = 8.97524380683899
I0123 12:49:39.674591 139645810741248 ddar.py:60] Depth 4/1000 time = 9.192744493484497
I0123 12:49:48.677695 139645810741248 ddar.py:60] Depth 5/1000 time = 9.002426624298096
I0123 12:49:57.672608 139645810741248 ddar.py:60] Depth 6/1000 time = 8.993955612182617
I0123 12:50:06.862068 139645810741248 ddar.py:60] Depth 7/1000 time = 9.18928074836731
I0123 12:50:15.903374 139645810741248 ddar.py:60] Depth 8/1000 time = 9.041101694107056
I0123 12:50:24.860082 139645810741248 ddar.py:60] Depth 9/1000 time = 8.954736232757568
I0123 12:50:34.584777 139645810741248 ddar.py:60] Depth 10/1000 time = 9.709983587265015
I0123 12:50:34.586997 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:50:34.587090 139645810741248 alphageometry.py:566] LM output (score=-2.339613): "p : C k m p 23 D k p m p 24 ;"
I0123 12:50:34.587127 139645810741248 alphageometry.py:567] Translation: "p = on_line p k m, on_bline p m k"

I0123 12:50:34.587209 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p k m, on_bline p m k ? para d n o m"
I0123 12:50:34.587402 139645810741248 graph.py:498] 
I0123 12:50:34.587463 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p k m, on_bline p m k ? para d n o m
I0123 12:50:42.212848 139645810741248 ddar.py:60] Depth 1/1000 time = 7.396463394165039
I0123 12:50:51.025716 139645810741248 ddar.py:60] Depth 2/1000 time = 8.812652349472046
I0123 12:51:00.070409 139645810741248 ddar.py:60] Depth 3/1000 time = 9.044414043426514
I0123 12:51:09.023093 139645810741248 ddar.py:60] Depth 4/1000 time = 8.952499628067017
I0123 12:51:18.368101 139645810741248 ddar.py:60] Depth 5/1000 time = 9.344419002532959
I0123 12:51:27.415056 139645810741248 ddar.py:60] Depth 6/1000 time = 9.046029567718506
I0123 12:51:37.014905 139645810741248 ddar.py:60] Depth 7/1000 time = 9.59963059425354
I0123 12:51:46.714951 139645810741248 ddar.py:60] Depth 8/1000 time = 9.69981575012207
I0123 12:51:55.870055 139645810741248 ddar.py:60] Depth 9/1000 time = 9.153127431869507
I0123 12:52:05.431850 139645810741248 ddar.py:60] Depth 10/1000 time = 9.547280550003052
I0123 12:52:05.433006 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:52:05.433106 139645810741248 alphageometry.py:566] LM output (score=-2.377380): "p : C a b p 23 D a p b p 24 ;"
I0123 12:52:05.433143 139645810741248 alphageometry.py:567] Translation: "p = on_line p a b, on_bline p b a"

I0123 12:52:05.433180 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p a b, on_bline p b a ? para d n o m"
I0123 12:52:05.433376 139645810741248 graph.py:498] 
I0123 12:52:05.433438 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p a b, on_bline p b a ? para d n o m
I0123 12:52:12.592102 139645810741248 ddar.py:60] Depth 1/1000 time = 7.103930234909058
I0123 12:52:20.860214 139645810741248 ddar.py:60] Depth 2/1000 time = 8.267924308776855
I0123 12:52:29.902004 139645810741248 ddar.py:60] Depth 3/1000 time = 9.041590929031372
I0123 12:52:38.497560 139645810741248 ddar.py:60] Depth 4/1000 time = 8.595329284667969
I0123 12:52:47.354652 139645810741248 ddar.py:60] Depth 5/1000 time = 8.856548547744751
I0123 12:52:56.264402 139645810741248 ddar.py:60] Depth 6/1000 time = 8.908581018447876
I0123 12:53:06.033010 139645810741248 ddar.py:60] Depth 7/1000 time = 9.768417596817017
I0123 12:53:15.338240 139645810741248 ddar.py:60] Depth 8/1000 time = 9.305039882659912
I0123 12:53:25.026411 139645810741248 ddar.py:60] Depth 9/1000 time = 9.685926675796509
I0123 12:53:35.118286 139645810741248 ddar.py:60] Depth 10/1000 time = 10.071665048599243
I0123 12:53:44.582838 139645810741248 ddar.py:60] Depth 11/1000 time = 9.45784044265747
I0123 12:53:44.583104 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:53:44.583211 139645810741248 alphageometry.py:566] LM output (score=-2.387342): "p : C a m p 23 D a p m p 24 ;"
I0123 12:53:44.583249 139645810741248 alphageometry.py:567] Translation: "p = on_line p a m, on_bline p m a"

I0123 12:53:44.583298 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p a m, on_bline p m a ? para d n o m"
I0123 12:53:44.583495 139645810741248 graph.py:498] 
I0123 12:53:44.583557 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p a m, on_bline p m a ? para d n o m
I0123 12:53:50.692222 139645810741248 ddar.py:60] Depth 1/1000 time = 6.056121826171875
I0123 12:53:58.069033 139645810741248 ddar.py:60] Depth 2/1000 time = 7.376636028289795
I0123 12:54:06.036282 139645810741248 ddar.py:60] Depth 3/1000 time = 7.967041492462158
I0123 12:54:13.795819 139645810741248 ddar.py:60] Depth 4/1000 time = 7.7593090534210205
I0123 12:54:21.143235 139645810741248 ddar.py:60] Depth 5/1000 time = 7.346960067749023
I0123 12:54:29.225975 139645810741248 ddar.py:60] Depth 6/1000 time = 8.081810235977173
I0123 12:54:37.165499 139645810741248 ddar.py:60] Depth 7/1000 time = 7.939324855804443
I0123 12:54:45.255434 139645810741248 ddar.py:60] Depth 8/1000 time = 8.089741468429565
I0123 12:54:53.013807 139645810741248 ddar.py:60] Depth 9/1000 time = 7.756396293640137
I0123 12:55:01.405322 139645810741248 ddar.py:60] Depth 10/1000 time = 8.376957654953003
I0123 12:55:01.408732 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:55:01.408837 139645810741248 alphageometry.py:566] LM output (score=-2.506497): "p : T f g h p 23 T f h g p 24 ;"
I0123 12:55:01.408872 139645810741248 alphageometry.py:567] Translation: "p = on_tline p h f g, on_tline p g f h"

I0123 12:55:01.408910 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p h f g, on_tline p g f h ? para d n o m"
I0123 12:55:01.409103 139645810741248 graph.py:498] 
I0123 12:55:01.409166 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p h f g, on_tline p g f h ? para d n o m
I0123 12:55:06.057898 139645810741248 ddar.py:60] Depth 1/1000 time = 4.6155266761779785
I0123 12:55:12.422270 139645810741248 ddar.py:60] Depth 2/1000 time = 6.364195108413696
I0123 12:55:18.453168 139645810741248 ddar.py:60] Depth 3/1000 time = 6.030707597732544
I0123 12:55:24.883418 139645810741248 ddar.py:60] Depth 4/1000 time = 6.4300713539123535
I0123 12:55:31.405344 139645810741248 ddar.py:60] Depth 5/1000 time = 6.521524667739868
I0123 12:55:37.962555 139645810741248 ddar.py:60] Depth 6/1000 time = 6.556121826171875
I0123 12:55:44.928339 139645810741248 ddar.py:60] Depth 7/1000 time = 6.965609312057495
I0123 12:55:51.574102 139645810741248 ddar.py:60] Depth 8/1000 time = 6.645514726638794
I0123 12:55:58.876867 139645810741248 ddar.py:60] Depth 9/1000 time = 7.29991888999939
I0123 12:56:06.264812 139645810741248 ddar.py:60] Depth 10/1000 time = 7.3626110553741455
I0123 12:56:06.267759 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:56:06.267888 139645810741248 alphageometry.py:566] LM output (score=-2.611561): "p : T f g g p 23 ;"
I0123 12:56:06.267929 139645810741248 alphageometry.py:567] Translation: "p = on_tline p g f g"

I0123 12:56:06.267966 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g f g ? para d n o m"
I0123 12:56:06.268180 139645810741248 graph.py:498] 
I0123 12:56:06.268244 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g f g ? para d n o m
I0123 12:56:10.986449 139645810741248 ddar.py:60] Depth 1/1000 time = 4.611619710922241
I0123 12:56:17.266566 139645810741248 ddar.py:60] Depth 2/1000 time = 6.279828310012817
I0123 12:56:23.198059 139645810741248 ddar.py:60] Depth 3/1000 time = 5.931323051452637
I0123 12:56:29.496630 139645810741248 ddar.py:60] Depth 4/1000 time = 6.298388957977295
I0123 12:56:35.543606 139645810741248 ddar.py:60] Depth 5/1000 time = 6.046619415283203
I0123 12:56:41.487780 139645810741248 ddar.py:60] Depth 6/1000 time = 5.943335056304932
I0123 12:56:48.345328 139645810741248 ddar.py:60] Depth 7/1000 time = 6.857369661331177
I0123 12:56:54.632284 139645810741248 ddar.py:60] Depth 8/1000 time = 6.286708116531372
I0123 12:57:01.301683 139645810741248 ddar.py:60] Depth 9/1000 time = 6.667708158493042
I0123 12:57:08.021164 139645810741248 ddar.py:60] Depth 10/1000 time = 6.701802968978882
I0123 12:57:08.022443 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:57:08.022546 139645810741248 alphageometry.py:566] LM output (score=-2.697392): "p : T f g h p 23 ;"
I0123 12:57:08.022582 139645810741248 alphageometry.py:567] Translation: "p = on_tline p h f g"

I0123 12:57:08.022617 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p h f g ? para d n o m"
I0123 12:57:08.022812 139645810741248 graph.py:498] 
I0123 12:57:08.022873 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p h f g ? para d n o m
I0123 12:57:12.427857 139645810741248 ddar.py:60] Depth 1/1000 time = 4.364255905151367
I0123 12:57:18.415066 139645810741248 ddar.py:60] Depth 2/1000 time = 5.987027645111084
I0123 12:57:24.994305 139645810741248 ddar.py:60] Depth 3/1000 time = 6.579035043716431
I0123 12:57:30.933014 139645810741248 ddar.py:60] Depth 4/1000 time = 5.938535451889038
I0123 12:57:37.208851 139645810741248 ddar.py:60] Depth 5/1000 time = 6.275434494018555
I0123 12:57:43.549500 139645810741248 ddar.py:60] Depth 6/1000 time = 6.339690923690796
I0123 12:57:50.129941 139645810741248 ddar.py:60] Depth 7/1000 time = 6.5802388191223145
I0123 12:57:56.472091 139645810741248 ddar.py:60] Depth 8/1000 time = 6.341962099075317
I0123 12:58:03.258491 139645810741248 ddar.py:60] Depth 9/1000 time = 6.7848546504974365
I0123 12:58:09.739113 139645810741248 ddar.py:60] Depth 10/1000 time = 6.462967395782471
I0123 12:58:09.741228 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:58:09.741344 139645810741248 alphageometry.py:566] LM output (score=-2.741094): "p : T c g g p 23 ;"
I0123 12:58:09.741402 139645810741248 alphageometry.py:567] Translation: "p = on_tline p g c g"

I0123 12:58:09.741444 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g c g ? para d n o m"
I0123 12:58:09.741646 139645810741248 graph.py:498] 
I0123 12:58:09.741713 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g c g ? para d n o m
I0123 12:58:14.519104 139645810741248 ddar.py:60] Depth 1/1000 time = 4.734380722045898
I0123 12:58:20.651208 139645810741248 ddar.py:60] Depth 2/1000 time = 6.131856441497803
I0123 12:58:26.736040 139645810741248 ddar.py:60] Depth 3/1000 time = 6.084520101547241
I0123 12:58:33.081691 139645810741248 ddar.py:60] Depth 4/1000 time = 6.345466613769531
I0123 12:58:39.147562 139645810741248 ddar.py:60] Depth 5/1000 time = 6.065536022186279
I0123 12:58:45.590678 139645810741248 ddar.py:60] Depth 6/1000 time = 6.442260503768921
I0123 12:58:51.917607 139645810741248 ddar.py:60] Depth 7/1000 time = 6.3267295360565186
I0123 12:58:58.597192 139645810741248 ddar.py:60] Depth 8/1000 time = 6.679392337799072
I0123 12:59:05.090552 139645810741248 ddar.py:60] Depth 9/1000 time = 6.491748571395874
I0123 12:59:11.928005 139645810741248 ddar.py:60] Depth 10/1000 time = 6.820302963256836
I0123 12:59:11.930138 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 12:59:11.930243 139645810741248 alphageometry.py:566] LM output (score=-3.027347): "p : T i j i p 23 ;"
I0123 12:59:11.930280 139645810741248 alphageometry.py:567] Translation: "p = on_tline p i i j"

I0123 12:59:11.930317 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p i i j ? para d n o m"
I0123 12:59:11.930512 139645810741248 graph.py:498] 
I0123 12:59:11.930575 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p i i j ? para d n o m
I0123 12:59:16.887014 139645810741248 ddar.py:60] Depth 1/1000 time = 4.77485728263855
I0123 12:59:22.708347 139645810741248 ddar.py:60] Depth 2/1000 time = 5.821164131164551
I0123 12:59:29.103188 139645810741248 ddar.py:60] Depth 3/1000 time = 6.39464259147644
I0123 12:59:35.463771 139645810741248 ddar.py:60] Depth 4/1000 time = 6.360364675521851
I0123 12:59:41.868895 139645810741248 ddar.py:60] Depth 5/1000 time = 6.4047651290893555
I0123 12:59:48.026442 139645810741248 ddar.py:60] Depth 6/1000 time = 6.1564249992370605
I0123 12:59:54.818370 139645810741248 ddar.py:60] Depth 7/1000 time = 6.791697263717651
I0123 13:00:01.286681 139645810741248 ddar.py:60] Depth 8/1000 time = 6.468122720718384
I0123 13:00:08.201585 139645810741248 ddar.py:60] Depth 9/1000 time = 6.913159370422363
I0123 13:00:14.881308 139645810741248 ddar.py:60] Depth 10/1000 time = 6.660967826843262
I0123 13:00:14.883409 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:00:14.883525 139645810741248 alphageometry.py:566] LM output (score=-3.034286): "p : D b p e p 23 D e p f p 24 ;"
I0123 13:00:14.883564 139645810741248 alphageometry.py:567] Translation: "p = on_bline p e b, on_bline p f e"

I0123 13:00:14.883603 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_bline p e b, on_bline p f e ? para d n o m"
I0123 13:00:14.883799 139645810741248 graph.py:498] 
I0123 13:00:14.883862 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_bline p e b, on_bline p f e ? para d n o m
I0123 13:00:20.217801 139645810741248 ddar.py:60] Depth 1/1000 time = 5.236109018325806
I0123 13:00:26.647485 139645810741248 ddar.py:60] Depth 2/1000 time = 6.429511070251465
I0123 13:00:33.654339 139645810741248 ddar.py:60] Depth 3/1000 time = 7.006673097610474
I0123 13:00:40.894206 139645810741248 ddar.py:60] Depth 4/1000 time = 7.239675283432007
I0123 13:00:48.210046 139645810741248 ddar.py:60] Depth 5/1000 time = 7.315663814544678
I0123 13:00:55.868091 139645810741248 ddar.py:60] Depth 6/1000 time = 7.657839775085449
I0123 13:01:03.577286 139645810741248 ddar.py:60] Depth 7/1000 time = 7.708760738372803
I0123 13:01:11.121692 139645810741248 ddar.py:60] Depth 8/1000 time = 7.542210578918457
I0123 13:01:19.295180 139645810741248 ddar.py:60] Depth 9/1000 time = 8.17315673828125
I0123 13:01:27.441881 139645810741248 ddar.py:60] Depth 10/1000 time = 8.146522998809814
I0123 13:01:35.397263 139645810741248 ddar.py:60] Depth 11/1000 time = 7.952560186386108
I0123 13:01:43.326440 139645810741248 ddar.py:60] Depth 12/1000 time = 7.885745286941528
I0123 13:01:43.329960 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:01:43.330055 139645810741248 alphageometry.py:566] LM output (score=-3.152665): "p : T g h g p 23 ;"
I0123 13:01:43.330092 139645810741248 alphageometry.py:567] Translation: "p = on_tline p g g h"

I0123 13:01:43.330126 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g g h ? para d n o m"
I0123 13:01:43.330308 139645810741248 graph.py:498] 
I0123 13:01:43.330366 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g g h ? para d n o m
I0123 13:01:48.521806 139645810741248 ddar.py:60] Depth 1/1000 time = 5.143527507781982
I0123 13:01:54.456088 139645810741248 ddar.py:60] Depth 2/1000 time = 5.93407416343689
I0123 13:02:00.568938 139645810741248 ddar.py:60] Depth 3/1000 time = 6.112582445144653
I0123 13:02:06.674160 139645810741248 ddar.py:60] Depth 4/1000 time = 6.105040550231934
I0123 13:02:13.170740 139645810741248 ddar.py:60] Depth 5/1000 time = 6.496238946914673
I0123 13:02:19.578090 139645810741248 ddar.py:60] Depth 6/1000 time = 6.405370712280273
I0123 13:02:26.111593 139645810741248 ddar.py:60] Depth 7/1000 time = 6.533302307128906
I0123 13:02:33.049906 139645810741248 ddar.py:60] Depth 8/1000 time = 6.938122749328613
I0123 13:02:39.729477 139645810741248 ddar.py:60] Depth 9/1000 time = 6.677716493606567
I0123 13:02:46.817060 139645810741248 ddar.py:60] Depth 10/1000 time = 7.072223663330078
I0123 13:02:46.818547 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:02:46.818645 139645810741248 alphageometry.py:566] LM output (score=-3.156978): "p : T h o o p 23 ;"
I0123 13:02:46.818681 139645810741248 alphageometry.py:567] Translation: "p = on_tline p o h o"

I0123 13:02:46.818716 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p o h o ? para d n o m"
I0123 13:02:46.818904 139645810741248 graph.py:498] 
I0123 13:02:46.818965 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p o h o ? para d n o m
I0123 13:02:51.892086 139645810741248 ddar.py:60] Depth 1/1000 time = 4.957584619522095
I0123 13:02:57.508758 139645810741248 ddar.py:60] Depth 2/1000 time = 5.61644983291626
I0123 13:03:04.038438 139645810741248 ddar.py:60] Depth 3/1000 time = 6.529398679733276
I0123 13:03:10.222697 139645810741248 ddar.py:60] Depth 4/1000 time = 6.18408203125
I0123 13:03:16.780035 139645810741248 ddar.py:60] Depth 5/1000 time = 6.5571746826171875
I0123 13:03:23.079879 139645810741248 ddar.py:60] Depth 6/1000 time = 6.29945969581604
I0123 13:03:29.376322 139645810741248 ddar.py:60] Depth 7/1000 time = 6.295209646224976
I0123 13:03:36.352439 139645810741248 ddar.py:60] Depth 8/1000 time = 6.975928544998169
I0123 13:03:42.675273 139645810741248 ddar.py:60] Depth 9/1000 time = 6.322623252868652
I0123 13:03:49.681682 139645810741248 ddar.py:60] Depth 10/1000 time = 7.004306316375732
I0123 13:03:56.433285 139645810741248 ddar.py:60] Depth 11/1000 time = 6.731440305709839
I0123 13:03:56.435203 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:03:56.435301 139645810741248 alphageometry.py:566] LM output (score=-3.164211): "p : T c g c p 23 ;"
I0123 13:03:56.435337 139645810741248 alphageometry.py:567] Translation: "p = on_tline p c c g"

I0123 13:03:56.435372 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p c c g ? para d n o m"
I0123 13:03:56.435579 139645810741248 graph.py:498] 
I0123 13:03:56.435640 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p c c g ? para d n o m
I0123 13:04:01.044816 139645810741248 ddar.py:60] Depth 1/1000 time = 4.581390857696533
I0123 13:04:07.367828 139645810741248 ddar.py:60] Depth 2/1000 time = 6.322833299636841
I0123 13:04:13.552365 139645810741248 ddar.py:60] Depth 3/1000 time = 6.184358358383179
I0123 13:04:19.762136 139645810741248 ddar.py:60] Depth 4/1000 time = 6.209589004516602
I0123 13:04:26.382503 139645810741248 ddar.py:60] Depth 5/1000 time = 6.6200032234191895
I0123 13:04:32.638099 139645810741248 ddar.py:60] Depth 6/1000 time = 6.254767894744873
I0123 13:04:39.088506 139645810741248 ddar.py:60] Depth 7/1000 time = 6.450239896774292
I0123 13:04:46.024188 139645810741248 ddar.py:60] Depth 8/1000 time = 6.93543004989624
I0123 13:04:52.817306 139645810741248 ddar.py:60] Depth 9/1000 time = 6.791415452957153
I0123 13:04:59.213344 139645810741248 ddar.py:60] Depth 10/1000 time = 6.3780577182769775
I0123 13:04:59.214990 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:04:59.215097 139645810741248 alphageometry.py:566] LM output (score=-3.184279): "p : T j p k l 23 ;"
I0123 13:04:59.215133 139645810741248 alphageometry.py:567] Translation: "p = on_tline p j k l"

I0123 13:04:59.215168 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p j k l ? para d n o m"
I0123 13:04:59.215354 139645810741248 graph.py:498] 
I0123 13:04:59.215416 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p j k l ? para d n o m
I0123 13:05:04.181793 139645810741248 ddar.py:60] Depth 1/1000 time = 4.942132949829102
I0123 13:05:10.243755 139645810741248 ddar.py:60] Depth 2/1000 time = 6.061781883239746
I0123 13:05:16.860329 139645810741248 ddar.py:60] Depth 3/1000 time = 6.616395711898804
I0123 13:05:23.171541 139645810741248 ddar.py:60] Depth 4/1000 time = 6.311035871505737
I0123 13:05:29.513497 139645810741248 ddar.py:60] Depth 5/1000 time = 6.341595411300659
I0123 13:05:35.896728 139645810741248 ddar.py:60] Depth 6/1000 time = 6.382114887237549
I0123 13:05:42.484393 139645810741248 ddar.py:60] Depth 7/1000 time = 6.587486982345581
I0123 13:05:49.176161 139645810741248 ddar.py:60] Depth 8/1000 time = 6.691529989242554
I0123 13:05:55.877277 139645810741248 ddar.py:60] Depth 9/1000 time = 6.699285984039307
I0123 13:06:02.598240 139645810741248 ddar.py:60] Depth 10/1000 time = 6.705808401107788
I0123 13:06:02.600387 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:06:02.600508 139645810741248 alphageometry.py:566] LM output (score=-3.184877): "p : T e g g p 23 ;"
I0123 13:06:02.600546 139645810741248 alphageometry.py:567] Translation: "p = on_tline p g e g"

I0123 13:06:02.600595 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g e g ? para d n o m"
I0123 13:06:02.600788 139645810741248 graph.py:498] 
I0123 13:06:02.600850 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p g e g ? para d n o m
I0123 13:06:07.726810 139645810741248 ddar.py:60] Depth 1/1000 time = 5.007636070251465
I0123 13:06:13.862378 139645810741248 ddar.py:60] Depth 2/1000 time = 6.135383605957031
I0123 13:06:20.145437 139645810741248 ddar.py:60] Depth 3/1000 time = 6.282876253128052
I0123 13:06:26.471100 139645810741248 ddar.py:60] Depth 4/1000 time = 6.325467586517334
I0123 13:06:32.907517 139645810741248 ddar.py:60] Depth 5/1000 time = 6.436035633087158
I0123 13:06:38.870882 139645810741248 ddar.py:60] Depth 6/1000 time = 5.962529420852661
I0123 13:06:45.345360 139645810741248 ddar.py:60] Depth 7/1000 time = 6.47429895401001
I0123 13:06:52.322324 139645810741248 ddar.py:60] Depth 8/1000 time = 6.976795673370361
I0123 13:06:59.084476 139645810741248 ddar.py:60] Depth 9/1000 time = 6.760548830032349
I0123 13:07:05.865487 139645810741248 ddar.py:60] Depth 10/1000 time = 6.764296054840088
I0123 13:07:05.867351 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:07:05.867461 139645810741248 alphageometry.py:566] LM output (score=-3.331553): "p : D b p e p 23 ;"
I0123 13:07:05.867500 139645810741248 alphageometry.py:567] Translation: "p = on_bline p e b"

I0123 13:07:05.867536 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_bline p e b ? para d n o m"
I0123 13:07:05.867719 139645810741248 graph.py:498] 
I0123 13:07:05.867779 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_bline p e b ? para d n o m
I0123 13:07:11.078027 139645810741248 ddar.py:60] Depth 1/1000 time = 5.084607839584351
I0123 13:07:17.488247 139645810741248 ddar.py:60] Depth 2/1000 time = 6.410018682479858
I0123 13:07:24.067580 139645810741248 ddar.py:60] Depth 3/1000 time = 6.579119920730591
I0123 13:07:30.636669 139645810741248 ddar.py:60] Depth 4/1000 time = 6.56890082359314
I0123 13:07:37.348625 139645810741248 ddar.py:60] Depth 5/1000 time = 6.711686849594116
I0123 13:07:44.012146 139645810741248 ddar.py:60] Depth 6/1000 time = 6.663030385971069
I0123 13:07:50.683017 139645810741248 ddar.py:60] Depth 7/1000 time = 6.66970682144165
I0123 13:07:57.667209 139645810741248 ddar.py:60] Depth 8/1000 time = 6.983945369720459
I0123 13:08:04.634235 139645810741248 ddar.py:60] Depth 9/1000 time = 6.966695070266724
I0123 13:08:11.583124 139645810741248 ddar.py:60] Depth 10/1000 time = 6.946803331375122
I0123 13:08:19.135060 139645810741248 ddar.py:60] Depth 11/1000 time = 7.529637575149536
I0123 13:08:19.136976 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:08:19.137089 139645810741248 alphageometry.py:566] LM output (score=-3.409664): "p : T a p f h 23 ;"
I0123 13:08:19.137125 139645810741248 alphageometry.py:567] Translation: "p = on_tline p a f h"

I0123 13:08:19.137173 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p a f h ? para d n o m"
I0123 13:08:19.137371 139645810741248 graph.py:498] 
I0123 13:08:19.137429 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p a f h ? para d n o m
I0123 13:08:24.059046 139645810741248 ddar.py:60] Depth 1/1000 time = 4.738923788070679
I0123 13:08:30.150846 139645810741248 ddar.py:60] Depth 2/1000 time = 6.091639280319214
I0123 13:08:36.931813 139645810741248 ddar.py:60] Depth 3/1000 time = 6.7807981967926025
I0123 13:08:43.098565 139645810741248 ddar.py:60] Depth 4/1000 time = 6.1665544509887695
I0123 13:08:49.529668 139645810741248 ddar.py:60] Depth 5/1000 time = 6.4308693408966064
I0123 13:08:55.971693 139645810741248 ddar.py:60] Depth 6/1000 time = 6.441572427749634
I0123 13:09:02.582454 139645810741248 ddar.py:60] Depth 7/1000 time = 6.609508991241455
I0123 13:09:09.036312 139645810741248 ddar.py:60] Depth 8/1000 time = 6.453543424606323
I0123 13:09:16.262620 139645810741248 ddar.py:60] Depth 9/1000 time = 7.226127862930298
I0123 13:09:22.808448 139645810741248 ddar.py:60] Depth 10/1000 time = 6.543649673461914
I0123 13:09:30.166280 139645810741248 ddar.py:60] Depth 11/1000 time = 7.337558031082153
I0123 13:09:30.167981 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:09:30.168082 139645810741248 alphageometry.py:566] LM output (score=-3.582696): "p : T d p e g 23 ;"
I0123 13:09:30.168117 139645810741248 alphageometry.py:567] Translation: "p = on_tline p d e g"

I0123 13:09:30.168153 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p d e g ? para d n o m"
I0123 13:09:30.168340 139645810741248 graph.py:498] 
I0123 13:09:30.168401 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_tline p d e g ? para d n o m
I0123 13:09:34.950481 139645810741248 ddar.py:60] Depth 1/1000 time = 4.746532440185547
I0123 13:09:41.145517 139645810741248 ddar.py:60] Depth 2/1000 time = 6.1948583126068115
I0123 13:09:47.768427 139645810741248 ddar.py:60] Depth 3/1000 time = 6.622716665267944
I0123 13:09:54.944770 139645810741248 ddar.py:60] Depth 4/1000 time = 7.176165819168091
I0123 13:10:01.816918 139645810741248 ddar.py:60] Depth 5/1000 time = 6.871962070465088
I0123 13:10:08.730454 139645810741248 ddar.py:60] Depth 6/1000 time = 6.913116455078125
I0123 13:10:16.091667 139645810741248 ddar.py:60] Depth 7/1000 time = 7.3603434562683105
I0123 13:10:22.904128 139645810741248 ddar.py:60] Depth 8/1000 time = 6.8122875690460205
I0123 13:10:30.505633 139645810741248 ddar.py:60] Depth 9/1000 time = 7.601292133331299
I0123 13:10:38.115759 139645810741248 ddar.py:60] Depth 10/1000 time = 7.60850715637207
I0123 13:10:45.895990 139645810741248 ddar.py:60] Depth 11/1000 time = 7.762774467468262
I0123 13:10:45.900237 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:10:45.900353 139645810741248 alphageometry.py:540] Depth 1. There are 32 nodes to expand:
I0123 13:10:45.900397 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b l p 23 D b p l p 24 ; x00
I0123 13:10:45.900428 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b g p 23 D b p g p 24 ; x00
I0123 13:10:45.900458 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C g m p 23 D g p m p 24 ; x00
I0123 13:10:45.900487 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C j m p 23 D j p m p 24 ; x00
I0123 13:10:45.900515 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b m p 23 D b p m p 24 ; x00
I0123 13:10:45.900544 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C e m p 23 D e p m p 24 ; x00
I0123 13:10:45.900582 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C j l p 23 D j p l p 24 ; x00
I0123 13:10:45.900613 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C i m p 23 D i p m p 24 ; x00
I0123 13:10:45.900642 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C i l p 23 D i p l p 24 ; x00
I0123 13:10:45.900671 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b c p 23 D b p c p 24 ; x00
I0123 13:10:45.900699 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b i p 23 D b p i p 24 ; x00
I0123 13:10:45.900726 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b j p 23 D b p j p 24 ; x00
I0123 13:10:45.900754 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C e l p 23 D e p l p 24 ; x00
I0123 13:10:45.900781 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C g l p 23 D g p l p 24 ; x00
I0123 13:10:45.900813 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C h m p 23 D h p m p 24 ; x00
I0123 13:10:45.900844 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C k m p 23 D k p m p 24 ; x00
I0123 13:10:45.900872 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C a b p 23 D a p b p 24 ; x00
I0123 13:10:45.900899 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C a m p 23 D a p m p 24 ; x00
I0123 13:10:45.900926 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T f g h p 23 T f h g p 24 ; x00
I0123 13:10:45.900952 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T f g g p 23 ; x00
I0123 13:10:45.900980 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T f g h p 23 ; x00
I0123 13:10:45.901007 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T c g g p 23 ; x00
I0123 13:10:45.901037 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T i j i p 23 ; x00
I0123 13:10:45.901065 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : D b p e p 23 D e p f p 24 ; x00
I0123 13:10:45.901093 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T g h g p 23 ; x00
I0123 13:10:45.901119 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T h o o p 23 ; x00
I0123 13:10:45.901146 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T c g c p 23 ; x00
I0123 13:10:45.901170 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T j p k l 23 ; x00
I0123 13:10:45.901196 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T e g g p 23 ; x00
I0123 13:10:45.901222 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : D b p e p 23 ; x00
I0123 13:10:45.901248 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T a p f h 23 ; x00
I0123 13:10:45.901271 139645810741248 alphageometry.py:544] {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : T d p e g 23 ; x00
I0123 13:10:45.901297 139645810741248 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b l p 23 D b p l p 24 ; x00
I0123 13:10:53.779902 139645810741248 alphageometry.py:566] LM output (score=-0.024892): "q : C b m q 25 D b q m q 26 ;"
I0123 13:10:53.780163 139645810741248 alphageometry.py:567] Translation: "q = on_line q b m, on_bline q m b"

I0123 13:10:53.780217 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q b m, on_bline q m b ? para d n o m"
I0123 13:10:53.780489 139645810741248 graph.py:498] 
I0123 13:10:53.780553 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q b m, on_bline q m b ? para d n o m
I0123 13:11:00.954052 139645810741248 ddar.py:60] Depth 1/1000 time = 7.021411180496216
I0123 13:11:10.275992 139645810741248 ddar.py:60] Depth 2/1000 time = 9.321783781051636
I0123 13:11:21.319376 139645810741248 ddar.py:60] Depth 3/1000 time = 11.043211698532104
I0123 13:11:31.646486 139645810741248 ddar.py:60] Depth 4/1000 time = 10.326870203018188
I0123 13:11:42.418769 139645810741248 ddar.py:60] Depth 5/1000 time = 10.771711349487305
I0123 13:11:52.820343 139645810741248 ddar.py:60] Depth 6/1000 time = 10.4006667137146
I0123 13:12:03.335444 139645810741248 ddar.py:60] Depth 7/1000 time = 10.514901638031006
I0123 13:12:14.625294 139645810741248 ddar.py:60] Depth 8/1000 time = 11.289620637893677
I0123 13:12:25.717192 139645810741248 ddar.py:60] Depth 9/1000 time = 11.089422941207886
I0123 13:12:36.812638 139645810741248 ddar.py:60] Depth 10/1000 time = 11.076177597045898
I0123 13:12:36.820100 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:12:36.820183 139645810741248 alphageometry.py:566] LM output (score=-2.885776): "q : C h l q 25 D h q l q 26 ;"
I0123 13:12:36.820218 139645810741248 alphageometry.py:567] Translation: "q = on_line q h l, on_bline q l h"

I0123 13:12:36.820275 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q h l, on_bline q l h ? para d n o m"
I0123 13:12:36.820496 139645810741248 graph.py:498] 
I0123 13:12:36.820560 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q h l, on_bline q l h ? para d n o m
I0123 13:12:46.965914 139645810741248 ddar.py:60] Depth 1/1000 time = 10.06026840209961
I0123 13:12:59.562822 139645810741248 ddar.py:60] Depth 2/1000 time = 12.596725702285767
I0123 13:13:13.011053 139645810741248 ddar.py:60] Depth 3/1000 time = 13.447999477386475
I0123 13:13:25.309837 139645810741248 ddar.py:60] Depth 4/1000 time = 12.298480749130249
I0123 13:13:37.842602 139645810741248 ddar.py:60] Depth 5/1000 time = 12.532179355621338
I0123 13:13:51.200827 139645810741248 ddar.py:60] Depth 6/1000 time = 13.357229471206665
I0123 13:14:04.426154 139645810741248 ddar.py:60] Depth 7/1000 time = 13.225014686584473
I0123 13:14:17.335635 139645810741248 ddar.py:60] Depth 8/1000 time = 12.909269094467163
I0123 13:14:30.312154 139645810741248 ddar.py:60] Depth 9/1000 time = 12.973785161972046
I0123 13:14:43.735137 139645810741248 ddar.py:60] Depth 10/1000 time = 13.405043125152588
I0123 13:14:43.742524 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:14:43.742591 139645810741248 alphageometry.py:566] LM output (score=-3.669762): "q : T c g g q 25 ;"
I0123 13:14:43.742626 139645810741248 alphageometry.py:567] Translation: "q = on_tline q g c g"

I0123 13:14:43.742669 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g c g ? para d n o m"
I0123 13:14:43.742871 139645810741248 graph.py:498] 
I0123 13:14:43.742933 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g c g ? para d n o m
I0123 13:14:50.611052 139645810741248 ddar.py:60] Depth 1/1000 time = 6.805104494094849
I0123 13:14:58.465727 139645810741248 ddar.py:60] Depth 2/1000 time = 7.8544816970825195
I0123 13:15:06.705563 139645810741248 ddar.py:60] Depth 3/1000 time = 8.239632844924927
I0123 13:15:15.325141 139645810741248 ddar.py:60] Depth 4/1000 time = 8.619359016418457
I0123 13:15:23.644975 139645810741248 ddar.py:60] Depth 5/1000 time = 8.319398880004883
I0123 13:15:31.907148 139645810741248 ddar.py:60] Depth 6/1000 time = 8.26127815246582
I0123 13:15:40.451481 139645810741248 ddar.py:60] Depth 7/1000 time = 8.544087886810303
I0123 13:15:49.032667 139645810741248 ddar.py:60] Depth 8/1000 time = 8.580874919891357
I0123 13:15:58.113291 139645810741248 ddar.py:60] Depth 9/1000 time = 9.078672647476196
I0123 13:16:06.882063 139645810741248 ddar.py:60] Depth 10/1000 time = 8.75062084197998
I0123 13:16:06.884785 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:16:06.884862 139645810741248 alphageometry.py:566] LM output (score=-3.754451): "q : C h m q 25 D h q m q 26 ;"
I0123 13:16:06.884898 139645810741248 alphageometry.py:567] Translation: "q = on_line q h m, on_bline q m h"

I0123 13:16:06.884938 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q h m, on_bline q m h ? para d n o m"
I0123 13:16:06.885150 139645810741248 graph.py:498] 
I0123 13:16:06.885212 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q h m, on_bline q m h ? para d n o m
I0123 13:16:16.809437 139645810741248 ddar.py:60] Depth 1/1000 time = 9.808531284332275
I0123 13:16:28.672294 139645810741248 ddar.py:60] Depth 2/1000 time = 11.862665176391602
I0123 13:16:40.836329 139645810741248 ddar.py:60] Depth 3/1000 time = 12.163829565048218
I0123 13:16:53.090637 139645810741248 ddar.py:60] Depth 4/1000 time = 12.254114866256714
I0123 13:17:04.953737 139645810741248 ddar.py:60] Depth 5/1000 time = 11.862435340881348
I0123 13:17:16.780045 139645810741248 ddar.py:60] Depth 6/1000 time = 11.825352191925049
I0123 13:17:29.122942 139645810741248 ddar.py:60] Depth 7/1000 time = 12.3426673412323
I0123 13:17:41.598414 139645810741248 ddar.py:60] Depth 8/1000 time = 12.475272417068481
I0123 13:17:54.058278 139645810741248 ddar.py:60] Depth 9/1000 time = 12.457090854644775
I0123 13:18:06.652745 139645810741248 ddar.py:60] Depth 10/1000 time = 12.579047918319702
I0123 13:18:06.655897 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:18:06.655962 139645810741248 alphageometry.py:566] LM output (score=-3.774078): "q : D b p p q 25 T b p p q 26 ;"
I0123 13:18:06.655995 139645810741248 alphageometry.py:567] Translation: "q = on_circle q p b, on_tline q p b p"

I0123 13:18:06.656033 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_circle q p b, on_tline q p b p ? para d n o m"
I0123 13:18:06.656236 139645810741248 graph.py:498] 
I0123 13:18:06.656299 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_circle q p b, on_tline q p b p ? para d n o m
I0123 13:18:12.937020 139645810741248 ddar.py:60] Depth 1/1000 time = 6.199795722961426
I0123 13:18:21.591007 139645810741248 ddar.py:60] Depth 2/1000 time = 8.653810739517212
I0123 13:18:30.736442 139645810741248 ddar.py:60] Depth 3/1000 time = 9.14521837234497
I0123 13:18:39.035934 139645810741248 ddar.py:60] Depth 4/1000 time = 8.299283266067505
I0123 13:18:48.091092 139645810741248 ddar.py:60] Depth 5/1000 time = 9.054942607879639
I0123 13:18:57.133785 139645810741248 ddar.py:60] Depth 6/1000 time = 9.042242050170898
I0123 13:19:06.912969 139645810741248 ddar.py:60] Depth 7/1000 time = 9.77701997756958
I0123 13:19:15.954507 139645810741248 ddar.py:60] Depth 8/1000 time = 9.041332721710205
I0123 13:19:25.649274 139645810741248 ddar.py:60] Depth 9/1000 time = 9.694568634033203
I0123 13:19:35.003919 139645810741248 ddar.py:60] Depth 10/1000 time = 9.35218334197998
I0123 13:19:44.477022 139645810741248 ddar.py:60] Depth 11/1000 time = 9.447125911712646
I0123 13:19:44.480604 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:19:44.480662 139645810741248 alphageometry.py:566] LM output (score=-3.929280): "q : T f g h q 25 T f h g q 26 ;"
I0123 13:19:44.480695 139645810741248 alphageometry.py:567] Translation: "q = on_tline q h f g, on_tline q g f h"

I0123 13:19:44.480736 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g, on_tline q g f h ? para d n o m"
I0123 13:19:44.480932 139645810741248 graph.py:498] 
I0123 13:19:44.480991 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g, on_tline q g f h ? para d n o m
I0123 13:19:50.623761 139645810741248 ddar.py:60] Depth 1/1000 time = 6.099432945251465
I0123 13:19:58.592537 139645810741248 ddar.py:60] Depth 2/1000 time = 7.9685587882995605
I0123 13:20:06.994414 139645810741248 ddar.py:60] Depth 3/1000 time = 8.401590347290039
I0123 13:20:15.923790 139645810741248 ddar.py:60] Depth 4/1000 time = 8.92919111251831
I0123 13:20:24.475449 139645810741248 ddar.py:60] Depth 5/1000 time = 8.551223993301392
I0123 13:20:33.076249 139645810741248 ddar.py:60] Depth 6/1000 time = 8.599751472473145
I0123 13:20:42.269201 139645810741248 ddar.py:60] Depth 7/1000 time = 9.192758321762085
I0123 13:20:51.346139 139645810741248 ddar.py:60] Depth 8/1000 time = 9.076760530471802
I0123 13:21:00.404598 139645810741248 ddar.py:60] Depth 9/1000 time = 9.055370807647705
I0123 13:21:09.929177 139645810741248 ddar.py:60] Depth 10/1000 time = 9.498145818710327
I0123 13:21:09.933291 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:21:09.933355 139645810741248 alphageometry.py:566] LM output (score=-4.104853): "q : C k m q 25 D k q m q 26 ;"
I0123 13:21:09.933390 139645810741248 alphageometry.py:567] Translation: "q = on_line q k m, on_bline q m k"

I0123 13:21:09.933444 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q k m, on_bline q m k ? para d n o m"
I0123 13:21:09.933662 139645810741248 graph.py:498] 
I0123 13:21:09.933729 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_line q k m, on_bline q m k ? para d n o m
I0123 13:21:20.497519 139645810741248 ddar.py:60] Depth 1/1000 time = 10.475842475891113
I0123 13:21:32.132777 139645810741248 ddar.py:60] Depth 2/1000 time = 11.635021686553955
I0123 13:21:44.006799 139645810741248 ddar.py:60] Depth 3/1000 time = 11.873744010925293
I0123 13:21:55.884671 139645810741248 ddar.py:60] Depth 4/1000 time = 11.877663612365723
I0123 13:22:08.043163 139645810741248 ddar.py:60] Depth 5/1000 time = 12.15781283378601
I0123 13:22:20.295276 139645810741248 ddar.py:60] Depth 6/1000 time = 12.250869035720825
I0123 13:22:32.752856 139645810741248 ddar.py:60] Depth 7/1000 time = 12.457371473312378
I0123 13:22:45.283025 139645810741248 ddar.py:60] Depth 8/1000 time = 12.529918670654297
I0123 13:22:57.839777 139645810741248 ddar.py:60] Depth 9/1000 time = 12.554188251495361
I0123 13:23:10.560387 139645810741248 ddar.py:60] Depth 10/1000 time = 12.704522132873535
I0123 13:23:10.564088 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:23:10.564145 139645810741248 alphageometry.py:566] LM output (score=-4.150578): "q : T g h g q 25 ;"
I0123 13:23:10.564180 139645810741248 alphageometry.py:567] Translation: "q = on_tline q g g h"

I0123 13:23:10.564219 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g g h ? para d n o m"
I0123 13:23:10.564418 139645810741248 graph.py:498] 
I0123 13:23:10.564481 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g g h ? para d n o m
I0123 13:23:17.152737 139645810741248 ddar.py:60] Depth 1/1000 time = 6.548860788345337
I0123 13:23:24.708203 139645810741248 ddar.py:60] Depth 2/1000 time = 7.555257081985474
I0123 13:23:33.398713 139645810741248 ddar.py:60] Depth 3/1000 time = 8.690290689468384
I0123 13:23:41.711454 139645810741248 ddar.py:60] Depth 4/1000 time = 8.312490463256836
I0123 13:23:50.076534 139645810741248 ddar.py:60] Depth 5/1000 time = 8.36449909210205
I0123 13:23:59.390375 139645810741248 ddar.py:60] Depth 6/1000 time = 9.311717987060547
I0123 13:24:08.365190 139645810741248 ddar.py:60] Depth 7/1000 time = 8.974508285522461
I0123 13:24:17.223407 139645810741248 ddar.py:60] Depth 8/1000 time = 8.857958555221558
I0123 13:24:26.168622 139645810741248 ddar.py:60] Depth 9/1000 time = 8.942837238311768
I0123 13:24:35.595082 139645810741248 ddar.py:60] Depth 10/1000 time = 9.410644054412842
I0123 13:24:35.598360 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:24:35.598458 139645810741248 alphageometry.py:566] LM output (score=-4.207304): "q : T b p e q 25 ;"
I0123 13:24:35.598496 139645810741248 alphageometry.py:567] Translation: "q = on_tline q e b p"

I0123 13:24:35.598545 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e b p ? para d n o m"
I0123 13:24:35.598773 139645810741248 graph.py:498] 
I0123 13:24:35.598835 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e b p ? para d n o m
I0123 13:24:42.013112 139645810741248 ddar.py:60] Depth 1/1000 time = 6.289798021316528
I0123 13:24:50.150940 139645810741248 ddar.py:60] Depth 2/1000 time = 8.137657880783081
I0123 13:24:58.709630 139645810741248 ddar.py:60] Depth 3/1000 time = 8.558493614196777
I0123 13:25:06.778309 139645810741248 ddar.py:60] Depth 4/1000 time = 8.068474531173706
I0123 13:25:15.266151 139645810741248 ddar.py:60] Depth 5/1000 time = 8.48762035369873
I0123 13:25:24.223606 139645810741248 ddar.py:60] Depth 6/1000 time = 8.956968784332275
I0123 13:25:33.131157 139645810741248 ddar.py:60] Depth 7/1000 time = 8.906272888183594
I0123 13:25:41.988478 139645810741248 ddar.py:60] Depth 8/1000 time = 8.857000350952148
I0123 13:25:51.288643 139645810741248 ddar.py:60] Depth 9/1000 time = 9.299917936325073
I0123 13:26:00.184829 139645810741248 ddar.py:60] Depth 10/1000 time = 8.8938627243042
I0123 13:26:09.718850 139645810741248 ddar.py:60] Depth 11/1000 time = 9.51408839225769
I0123 13:26:09.721997 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:26:09.722076 139645810741248 alphageometry.py:566] LM output (score=-4.325161): "q : T b o d q 25 ;"
I0123 13:26:09.722111 139645810741248 alphageometry.py:567] Translation: "q = on_tline q d b o"

I0123 13:26:09.722160 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q d b o ? para d n o m"
I0123 13:26:09.722370 139645810741248 graph.py:498] 
I0123 13:26:09.722429 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q d b o ? para d n o m
I0123 13:26:16.091297 139645810741248 ddar.py:60] Depth 1/1000 time = 6.287489414215088
I0123 13:26:24.285846 139645810741248 ddar.py:60] Depth 2/1000 time = 8.194385051727295
I0123 13:26:32.903385 139645810741248 ddar.py:60] Depth 3/1000 time = 8.617350578308105
I0123 13:26:41.125658 139645810741248 ddar.py:60] Depth 4/1000 time = 8.222078800201416
I0123 13:26:50.589874 139645810741248 ddar.py:60] Depth 5/1000 time = 9.464022397994995
I0123 13:26:59.037761 139645810741248 ddar.py:60] Depth 6/1000 time = 8.447699069976807
I0123 13:27:07.946107 139645810741248 ddar.py:60] Depth 7/1000 time = 8.90790343284607
I0123 13:27:17.362032 139645810741248 ddar.py:60] Depth 8/1000 time = 9.414735078811646
I0123 13:27:26.251124 139645810741248 ddar.py:60] Depth 9/1000 time = 8.888895511627197
I0123 13:27:35.919581 139645810741248 ddar.py:60] Depth 10/1000 time = 9.668264389038086
I0123 13:27:45.219277 139645810741248 ddar.py:60] Depth 11/1000 time = 9.29710841178894
I0123 13:27:55.094657 139645810741248 ddar.py:60] Depth 12/1000 time = 9.852411270141602
I0123 13:28:04.579322 139645810741248 ddar.py:60] Depth 13/1000 time = 9.477669954299927
I0123 13:28:04.579545 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:28:04.579596 139645810741248 alphageometry.py:566] LM output (score=-4.411543): "q : T f g g q 25 ;"
I0123 13:28:04.579628 139645810741248 alphageometry.py:567] Translation: "q = on_tline q g f g"

I0123 13:28:04.579665 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g f g ? para d n o m"
I0123 13:28:04.579862 139645810741248 graph.py:498] 
I0123 13:28:04.579920 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g f g ? para d n o m
I0123 13:28:10.938008 139645810741248 ddar.py:60] Depth 1/1000 time = 6.321905612945557
I0123 13:28:19.318755 139645810741248 ddar.py:60] Depth 2/1000 time = 8.38057255744934
I0123 13:28:27.359075 139645810741248 ddar.py:60] Depth 3/1000 time = 8.040131568908691
I0123 13:28:35.950633 139645810741248 ddar.py:60] Depth 4/1000 time = 8.591316938400269
I0123 13:28:44.414460 139645810741248 ddar.py:60] Depth 5/1000 time = 8.463277101516724
I0123 13:28:52.984686 139645810741248 ddar.py:60] Depth 6/1000 time = 8.569288730621338
I0123 13:29:01.858337 139645810741248 ddar.py:60] Depth 7/1000 time = 8.873462915420532
I0123 13:29:10.751665 139645810741248 ddar.py:60] Depth 8/1000 time = 8.89313530921936
I0123 13:29:19.293720 139645810741248 ddar.py:60] Depth 9/1000 time = 8.540116548538208
I0123 13:29:28.296034 139645810741248 ddar.py:60] Depth 10/1000 time = 8.983987808227539
I0123 13:29:28.299183 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:29:28.299245 139645810741248 alphageometry.py:566] LM output (score=-4.413530): "q : T i j i q 25 ;"
I0123 13:29:28.299278 139645810741248 alphageometry.py:567] Translation: "q = on_tline q i i j"

I0123 13:29:28.299313 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q i i j ? para d n o m"
I0123 13:29:28.299528 139645810741248 graph.py:498] 
I0123 13:29:28.299590 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q i i j ? para d n o m
I0123 13:29:34.830994 139645810741248 ddar.py:60] Depth 1/1000 time = 6.468645095825195
I0123 13:29:42.572403 139645810741248 ddar.py:60] Depth 2/1000 time = 7.741227626800537
I0123 13:29:51.089261 139645810741248 ddar.py:60] Depth 3/1000 time = 8.516631126403809
I0123 13:29:59.615714 139645810741248 ddar.py:60] Depth 4/1000 time = 8.526155710220337
I0123 13:30:08.142004 139645810741248 ddar.py:60] Depth 5/1000 time = 8.525818586349487
I0123 13:30:16.622645 139645810741248 ddar.py:60] Depth 6/1000 time = 8.479367017745972
I0123 13:30:25.924653 139645810741248 ddar.py:60] Depth 7/1000 time = 9.301780939102173
I0123 13:30:34.335330 139645810741248 ddar.py:60] Depth 8/1000 time = 8.410370349884033
I0123 13:30:43.665340 139645810741248 ddar.py:60] Depth 9/1000 time = 9.327925443649292
I0123 13:30:52.820219 139645810741248 ddar.py:60] Depth 10/1000 time = 9.134751081466675
I0123 13:30:52.823443 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:30:52.823513 139645810741248 alphageometry.py:566] LM output (score=-4.442073): "q : T d q g h 25 ;"
I0123 13:30:52.823551 139645810741248 alphageometry.py:567] Translation: "q = on_tline q d g h"

I0123 13:30:52.823590 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q d g h ? para d n o m"
I0123 13:30:52.823786 139645810741248 graph.py:498] 
I0123 13:30:52.823912 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q d g h ? para d n o m
I0123 13:30:58.797598 139645810741248 ddar.py:60] Depth 1/1000 time = 5.825990438461304
I0123 13:31:07.074252 139645810741248 ddar.py:60] Depth 2/1000 time = 8.276458263397217
I0123 13:31:15.054081 139645810741248 ddar.py:60] Depth 3/1000 time = 7.979633569717407
I0123 13:31:23.566799 139645810741248 ddar.py:60] Depth 4/1000 time = 8.512464761734009
I0123 13:31:32.333116 139645810741248 ddar.py:60] Depth 5/1000 time = 8.765756607055664
I0123 13:31:41.152102 139645810741248 ddar.py:60] Depth 6/1000 time = 8.816972494125366
I0123 13:31:50.610101 139645810741248 ddar.py:60] Depth 7/1000 time = 9.457691431045532
I0123 13:31:59.628645 139645810741248 ddar.py:60] Depth 8/1000 time = 9.018327236175537
I0123 13:32:08.702394 139645810741248 ddar.py:60] Depth 9/1000 time = 9.071577548980713
I0123 13:32:18.028694 139645810741248 ddar.py:60] Depth 10/1000 time = 9.309470653533936
I0123 13:32:18.032376 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:32:18.032453 139645810741248 alphageometry.py:566] LM output (score=-4.512915): "q : T b p n q 25 ;"
I0123 13:32:18.032487 139645810741248 alphageometry.py:567] Translation: "q = on_tline q n b p"

I0123 13:32:18.032598 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q n b p ? para d n o m"
I0123 13:32:18.032815 139645810741248 graph.py:498] 
I0123 13:32:18.032878 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q n b p ? para d n o m
I0123 13:32:24.502545 139645810741248 ddar.py:60] Depth 1/1000 time = 6.392964839935303
I0123 13:32:32.737964 139645810741248 ddar.py:60] Depth 2/1000 time = 8.235248327255249
I0123 13:32:40.972430 139645810741248 ddar.py:60] Depth 3/1000 time = 8.23428225517273
I0123 13:32:49.613494 139645810741248 ddar.py:60] Depth 4/1000 time = 8.640873432159424
I0123 13:32:57.878758 139645810741248 ddar.py:60] Depth 5/1000 time = 8.265035390853882
I0123 13:33:06.506331 139645810741248 ddar.py:60] Depth 6/1000 time = 8.627134323120117
I0123 13:33:14.739288 139645810741248 ddar.py:60] Depth 7/1000 time = 8.231815576553345
I0123 13:33:24.132578 139645810741248 ddar.py:60] Depth 8/1000 time = 9.39307188987732
I0123 13:33:32.663695 139645810741248 ddar.py:60] Depth 9/1000 time = 8.530869245529175
I0123 13:33:41.660661 139645810741248 ddar.py:60] Depth 10/1000 time = 8.994773864746094
I0123 13:33:50.840467 139645810741248 ddar.py:60] Depth 11/1000 time = 9.1597261428833
I0123 13:33:50.843563 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:33:50.843638 139645810741248 alphageometry.py:566] LM output (score=-4.531923): "q : T f g h q 25 ;"
I0123 13:33:50.843672 139645810741248 alphageometry.py:567] Translation: "q = on_tline q h f g"

I0123 13:33:50.843716 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g ? para d n o m"
I0123 13:33:50.843920 139645810741248 graph.py:498] 
I0123 13:33:50.844040 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g ? para d n o m
I0123 13:33:57.237964 139645810741248 ddar.py:60] Depth 1/1000 time = 6.3402769565582275
I0123 13:34:05.416068 139645810741248 ddar.py:60] Depth 2/1000 time = 8.177932739257812
I0123 13:34:13.979051 139645810741248 ddar.py:60] Depth 3/1000 time = 8.562797784805298
I0123 13:34:22.943363 139645810741248 ddar.py:60] Depth 4/1000 time = 8.964111089706421
I0123 13:34:31.732793 139645810741248 ddar.py:60] Depth 5/1000 time = 8.78900146484375
I0123 13:34:39.967393 139645810741248 ddar.py:60] Depth 6/1000 time = 8.233758926391602
I0123 13:34:48.437405 139645810741248 ddar.py:60] Depth 7/1000 time = 8.469817638397217
I0123 13:34:57.254848 139645810741248 ddar.py:60] Depth 8/1000 time = 8.817246913909912
I0123 13:35:06.290812 139645810741248 ddar.py:60] Depth 9/1000 time = 9.03404974937439
I0123 13:35:15.331532 139645810741248 ddar.py:60] Depth 10/1000 time = 9.02251672744751
I0123 13:35:15.334501 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:35:15.334562 139645810741248 alphageometry.py:566] LM output (score=-4.578361): "q : T b o e q 25 ;"
I0123 13:35:15.334594 139645810741248 alphageometry.py:567] Translation: "q = on_tline q e b o"

I0123 13:35:15.334683 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e b o ? para d n o m"
I0123 13:35:15.334882 139645810741248 graph.py:498] 
I0123 13:35:15.334944 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e b o ? para d n o m
I0123 13:35:21.824233 139645810741248 ddar.py:60] Depth 1/1000 time = 6.3867857456207275
I0123 13:35:30.130655 139645810741248 ddar.py:60] Depth 2/1000 time = 8.306143522262573
I0123 13:35:39.323204 139645810741248 ddar.py:60] Depth 3/1000 time = 9.19231390953064
I0123 13:35:47.748916 139645810741248 ddar.py:60] Depth 4/1000 time = 8.425407409667969
I0123 13:35:56.185713 139645810741248 ddar.py:60] Depth 5/1000 time = 8.436610698699951
I0123 13:36:04.615103 139645810741248 ddar.py:60] Depth 6/1000 time = 8.42889142036438
I0123 13:36:12.985139 139645810741248 ddar.py:60] Depth 7/1000 time = 8.368842124938965
I0123 13:36:21.677408 139645810741248 ddar.py:60] Depth 8/1000 time = 8.6920645236969
I0123 13:36:31.330952 139645810741248 ddar.py:60] Depth 9/1000 time = 9.653350114822388
I0123 13:36:40.214574 139645810741248 ddar.py:60] Depth 10/1000 time = 8.881098747253418
I0123 13:36:49.048749 139645810741248 ddar.py:60] Depth 11/1000 time = 8.81181263923645
I0123 13:36:49.051983 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:36:49.052047 139645810741248 alphageometry.py:566] LM output (score=-4.647709): "q : T e g g q 25 ;"
I0123 13:36:49.052082 139645810741248 alphageometry.py:567] Translation: "q = on_tline q g e g"

I0123 13:36:49.052119 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g e g ? para d n o m"
I0123 13:36:49.052330 139645810741248 graph.py:498] 
I0123 13:36:49.052441 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q g e g ? para d n o m
I0123 13:36:55.718796 139645810741248 ddar.py:60] Depth 1/1000 time = 6.549145221710205
I0123 13:37:03.625893 139645810741248 ddar.py:60] Depth 2/1000 time = 7.906891822814941
I0123 13:37:12.400636 139645810741248 ddar.py:60] Depth 3/1000 time = 8.774511575698853
I0123 13:37:20.696193 139645810741248 ddar.py:60] Depth 4/1000 time = 8.295227289199829
I0123 13:37:29.478891 139645810741248 ddar.py:60] Depth 5/1000 time = 8.782289743423462
I0123 13:37:37.913548 139645810741248 ddar.py:60] Depth 6/1000 time = 8.433840036392212
I0123 13:37:46.530682 139645810741248 ddar.py:60] Depth 7/1000 time = 8.616941452026367
I0123 13:37:55.191079 139645810741248 ddar.py:60] Depth 8/1000 time = 8.660188913345337
I0123 13:38:03.750149 139645810741248 ddar.py:60] Depth 9/1000 time = 8.557127237319946
I0123 13:38:13.005921 139645810741248 ddar.py:60] Depth 10/1000 time = 9.237993478775024
I0123 13:38:13.009421 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:38:13.009479 139645810741248 alphageometry.py:566] LM output (score=-4.655530): "q : T e g e q 25 ;"
I0123 13:38:13.009515 139645810741248 alphageometry.py:567] Translation: "q = on_tline q e e g"

I0123 13:38:13.009552 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e e g ? para d n o m"
I0123 13:38:13.009762 139645810741248 graph.py:498] 
I0123 13:38:13.009867 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e e g ? para d n o m
I0123 13:38:19.640590 139645810741248 ddar.py:60] Depth 1/1000 time = 6.560574293136597
I0123 13:38:27.637607 139645810741248 ddar.py:60] Depth 2/1000 time = 7.996823787689209
I0123 13:38:36.250609 139645810741248 ddar.py:60] Depth 3/1000 time = 8.612767219543457
I0123 13:38:45.051492 139645810741248 ddar.py:60] Depth 4/1000 time = 8.800625324249268
I0123 13:38:53.886368 139645810741248 ddar.py:60] Depth 5/1000 time = 8.834308624267578
I0123 13:39:02.249790 139645810741248 ddar.py:60] Depth 6/1000 time = 8.362527847290039
I0123 13:39:10.851933 139645810741248 ddar.py:60] Depth 7/1000 time = 8.601830959320068
I0123 13:39:19.879530 139645810741248 ddar.py:60] Depth 8/1000 time = 9.02741026878357
I0123 13:39:28.999000 139645810741248 ddar.py:60] Depth 9/1000 time = 9.117518424987793
I0123 13:39:38.801404 139645810741248 ddar.py:60] Depth 10/1000 time = 9.78365159034729
I0123 13:39:38.804857 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:39:38.804937 139645810741248 alphageometry.py:566] LM output (score=-4.697958): "q : T c g c q 25 ;"
I0123 13:39:38.804986 139645810741248 alphageometry.py:567] Translation: "q = on_tline q c c g"

I0123 13:39:38.805031 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q c c g ? para d n o m"
I0123 13:39:38.805242 139645810741248 graph.py:498] 
I0123 13:39:38.805346 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q c c g ? para d n o m
I0123 13:39:45.098023 139645810741248 ddar.py:60] Depth 1/1000 time = 6.181669235229492
I0123 13:39:52.519120 139645810741248 ddar.py:60] Depth 2/1000 time = 7.4209020137786865
I0123 13:40:01.255609 139645810741248 ddar.py:60] Depth 3/1000 time = 8.736272811889648
I0123 13:40:10.032475 139645810741248 ddar.py:60] Depth 4/1000 time = 8.776649475097656
I0123 13:40:18.951343 139645810741248 ddar.py:60] Depth 5/1000 time = 8.918447256088257
I0123 13:40:27.349503 139645810741248 ddar.py:60] Depth 6/1000 time = 8.397261381149292
I0123 13:40:35.976125 139645810741248 ddar.py:60] Depth 7/1000 time = 8.6263427734375
I0123 13:40:45.152812 139645810741248 ddar.py:60] Depth 8/1000 time = 9.17634630203247
I0123 13:40:53.895771 139645810741248 ddar.py:60] Depth 9/1000 time = 8.740986585617065
I0123 13:41:03.293268 139645810741248 ddar.py:60] Depth 10/1000 time = 9.379879236221313
I0123 13:41:03.296231 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:41:03.296295 139645810741248 alphageometry.py:566] LM output (score=-4.731525): "q : C b m q 25 D b r m q 26 ;"
I0123 13:41:03.296330 139645810741248 alphageometry.py:567] Translation: "ERROR: point r does not exist."

I0123 13:41:03.296364 139645810741248 alphageometry.py:566] LM output (score=-4.774055): "q : T h o o q 25 ;"
I0123 13:41:03.296391 139645810741248 alphageometry.py:567] Translation: "q = on_tline q o h o"

I0123 13:41:03.296421 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o h o ? para d n o m"
I0123 13:41:03.296617 139645810741248 graph.py:498] 
I0123 13:41:03.296722 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o h o ? para d n o m
I0123 13:41:09.436792 139645810741248 ddar.py:60] Depth 1/1000 time = 6.103795289993286
I0123 13:41:17.467106 139645810741248 ddar.py:60] Depth 2/1000 time = 8.030109882354736
I0123 13:41:26.299004 139645810741248 ddar.py:60] Depth 3/1000 time = 8.83169174194336
I0123 13:41:34.882433 139645810741248 ddar.py:60] Depth 4/1000 time = 8.583176136016846
I0123 13:41:43.285918 139645810741248 ddar.py:60] Depth 5/1000 time = 8.403266906738281
I0123 13:41:52.358770 139645810741248 ddar.py:60] Depth 6/1000 time = 9.072381496429443
I0123 13:42:00.960259 139645810741248 ddar.py:60] Depth 7/1000 time = 8.600322008132935
I0123 13:42:09.313758 139645810741248 ddar.py:60] Depth 8/1000 time = 8.353286504745483
I0123 13:42:18.528698 139645810741248 ddar.py:60] Depth 9/1000 time = 9.2146897315979
I0123 13:42:27.902731 139645810741248 ddar.py:60] Depth 10/1000 time = 9.371471166610718
I0123 13:42:37.313008 139645810741248 ddar.py:60] Depth 11/1000 time = 9.387882471084595
I0123 13:42:37.315779 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:42:37.315862 139645810741248 alphageometry.py:566] LM output (score=-4.805226): "q : T i j o q 25 ;"
I0123 13:42:37.315902 139645810741248 alphageometry.py:567] Translation: "q = on_tline q o i j"

I0123 13:42:37.315943 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o i j ? para d n o m"
I0123 13:42:37.316153 139645810741248 graph.py:498] 
I0123 13:42:37.316221 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o i j ? para d n o m
I0123 13:42:44.063169 139645810741248 ddar.py:60] Depth 1/1000 time = 6.691258192062378
I0123 13:42:52.147525 139645810741248 ddar.py:60] Depth 2/1000 time = 8.084084749221802
I0123 13:43:00.532512 139645810741248 ddar.py:60] Depth 3/1000 time = 8.384819507598877
I0123 13:43:08.889871 139645810741248 ddar.py:60] Depth 4/1000 time = 8.35715937614441
I0123 13:43:17.765445 139645810741248 ddar.py:60] Depth 5/1000 time = 8.875168085098267
I0123 13:43:26.235467 139645810741248 ddar.py:60] Depth 6/1000 time = 8.468880414962769
I0123 13:43:35.482669 139645810741248 ddar.py:60] Depth 7/1000 time = 9.247014045715332
I0123 13:43:44.333430 139645810741248 ddar.py:60] Depth 8/1000 time = 8.85054898262024
I0123 13:43:53.717839 139645810741248 ddar.py:60] Depth 9/1000 time = 9.382317066192627
I0123 13:44:02.873354 139645810741248 ddar.py:60] Depth 10/1000 time = 9.13552474975586
I0123 13:44:02.876815 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:44:02.876874 139645810741248 alphageometry.py:566] LM output (score=-4.809657): "q : T i j j q 25 ;"
I0123 13:44:02.876908 139645810741248 alphageometry.py:567] Translation: "q = on_tline q j i j"

I0123 13:44:02.876992 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q j i j ? para d n o m"
I0123 13:44:02.877193 139645810741248 graph.py:498] 
I0123 13:44:02.877253 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q j i j ? para d n o m
I0123 13:44:08.656681 139645810741248 ddar.py:60] Depth 1/1000 time = 5.662123680114746
I0123 13:44:17.289450 139645810741248 ddar.py:60] Depth 2/1000 time = 8.63253927230835
I0123 13:44:25.824249 139645810741248 ddar.py:60] Depth 3/1000 time = 8.534485340118408
I0123 13:44:33.773700 139645810741248 ddar.py:60] Depth 4/1000 time = 7.949195146560669
I0123 13:44:42.784418 139645810741248 ddar.py:60] Depth 5/1000 time = 9.010157585144043
I0123 13:44:51.356022 139645810741248 ddar.py:60] Depth 6/1000 time = 8.570449590682983
I0123 13:45:00.203830 139645810741248 ddar.py:60] Depth 7/1000 time = 8.847596883773804
I0123 13:45:09.106039 139645810741248 ddar.py:60] Depth 8/1000 time = 8.902010202407837
I0123 13:45:18.028578 139645810741248 ddar.py:60] Depth 9/1000 time = 8.920469522476196
I0123 13:45:27.606158 139645810741248 ddar.py:60] Depth 10/1000 time = 9.557567596435547
I0123 13:45:27.609165 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:45:27.609289 139645810741248 alphageometry.py:566] LM output (score=-4.865698): "q : T j k o q 25 ;"
I0123 13:45:27.609326 139645810741248 alphageometry.py:567] Translation: "q = on_tline q o j k"

I0123 13:45:27.609362 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o j k ? para d n o m"
I0123 13:45:27.609571 139645810741248 graph.py:498] 
I0123 13:45:27.609632 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q o j k ? para d n o m
I0123 13:45:33.989727 139645810741248 ddar.py:60] Depth 1/1000 time = 6.324610471725464
I0123 13:45:42.171888 139645810741248 ddar.py:60] Depth 2/1000 time = 8.18197250366211
I0123 13:45:50.111623 139645810741248 ddar.py:60] Depth 3/1000 time = 7.939531326293945
I0123 13:45:58.413196 139645810741248 ddar.py:60] Depth 4/1000 time = 8.301355838775635
I0123 13:46:07.263091 139645810741248 ddar.py:60] Depth 5/1000 time = 8.849420070648193
I0123 13:46:15.673435 139645810741248 ddar.py:60] Depth 6/1000 time = 8.409090280532837
I0123 13:46:24.212080 139645810741248 ddar.py:60] Depth 7/1000 time = 8.538468360900879
I0123 13:46:32.804194 139645810741248 ddar.py:60] Depth 8/1000 time = 8.591920137405396
I0123 13:46:41.928796 139645810741248 ddar.py:60] Depth 9/1000 time = 9.122112512588501
I0123 13:46:51.239274 139645810741248 ddar.py:60] Depth 10/1000 time = 9.31027626991272
I0123 13:46:59.543368 139645810741248 ddar.py:60] Depth 11/1000 time = 8.284088850021362
I0123 13:46:59.546095 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:46:59.546204 139645810741248 alphageometry.py:566] LM output (score=-4.933651): "q : T f q g h 25 ;"
I0123 13:46:59.546241 139645810741248 alphageometry.py:567] Translation: "q = on_tline q f g h"

I0123 13:46:59.546287 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q f g h ? para d n o m"
I0123 13:46:59.546491 139645810741248 graph.py:498] 
I0123 13:46:59.546552 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q f g h ? para d n o m
I0123 13:47:06.346566 139645810741248 ddar.py:60] Depth 1/1000 time = 6.68117618560791
I0123 13:47:13.792713 139645810741248 ddar.py:60] Depth 2/1000 time = 7.4459614753723145
I0123 13:47:22.616955 139645810741248 ddar.py:60] Depth 3/1000 time = 8.824056386947632
I0123 13:47:30.900750 139645810741248 ddar.py:60] Depth 4/1000 time = 8.28357720375061
I0123 13:47:39.207987 139645810741248 ddar.py:60] Depth 5/1000 time = 8.306780815124512
I0123 13:47:48.299331 139645810741248 ddar.py:60] Depth 6/1000 time = 9.089297533035278
I0123 13:47:57.092154 139645810741248 ddar.py:60] Depth 7/1000 time = 8.792568922042847
I0123 13:48:05.887953 139645810741248 ddar.py:60] Depth 8/1000 time = 8.795486450195312
I0123 13:48:15.273626 139645810741248 ddar.py:60] Depth 9/1000 time = 9.383484840393066
I0123 13:48:23.702232 139645810741248 ddar.py:60] Depth 10/1000 time = 8.410969257354736
I0123 13:48:23.705592 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:48:23.705697 139645810741248 alphageometry.py:566] LM output (score=-4.953084): "q : T c q g h 25 ;"
I0123 13:48:23.705735 139645810741248 alphageometry.py:567] Translation: "q = on_tline q c g h"

I0123 13:48:23.705774 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q c g h ? para d n o m"
I0123 13:48:23.705974 139645810741248 graph.py:498] 
I0123 13:48:23.706036 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q c g h ? para d n o m
I0123 13:48:30.358416 139645810741248 ddar.py:60] Depth 1/1000 time = 6.598224878311157
I0123 13:48:38.451588 139645810741248 ddar.py:60] Depth 2/1000 time = 8.09299635887146
I0123 13:48:46.796485 139645810741248 ddar.py:60] Depth 3/1000 time = 8.344713687896729
I0123 13:48:55.800760 139645810741248 ddar.py:60] Depth 4/1000 time = 9.004060506820679
I0123 13:49:03.634177 139645810741248 ddar.py:60] Depth 5/1000 time = 7.83301568031311
I0123 13:49:12.261295 139645810741248 ddar.py:60] Depth 6/1000 time = 8.625163793563843
I0123 13:49:21.579301 139645810741248 ddar.py:60] Depth 7/1000 time = 9.317672967910767
I0123 13:49:30.503409 139645810741248 ddar.py:60] Depth 8/1000 time = 8.92385721206665
I0123 13:49:39.457938 139645810741248 ddar.py:60] Depth 9/1000 time = 8.95225191116333
I0123 13:49:48.451016 139645810741248 ddar.py:60] Depth 10/1000 time = 8.97728157043457
I0123 13:49:48.454578 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:49:48.454659 139645810741248 alphageometry.py:566] LM output (score=-4.956017): "q : T i j p q 25 ;"
I0123 13:49:48.454693 139645810741248 alphageometry.py:567] Translation: "q = on_tline q p i j"

I0123 13:49:48.454783 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q p i j ? para d n o m"
I0123 13:49:48.455002 139645810741248 graph.py:498] 
I0123 13:49:48.455064 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q p i j ? para d n o m
I0123 13:49:54.704144 139645810741248 ddar.py:60] Depth 1/1000 time = 6.207830429077148
I0123 13:50:03.310300 139645810741248 ddar.py:60] Depth 2/1000 time = 8.605976581573486
I0123 13:50:11.251526 139645810741248 ddar.py:60] Depth 3/1000 time = 7.9410223960876465
I0123 13:50:19.619226 139645810741248 ddar.py:60] Depth 4/1000 time = 8.367490291595459
I0123 13:50:28.052491 139645810741248 ddar.py:60] Depth 5/1000 time = 8.432847023010254
I0123 13:50:36.469803 139645810741248 ddar.py:60] Depth 6/1000 time = 8.416168212890625
I0123 13:50:45.833509 139645810741248 ddar.py:60] Depth 7/1000 time = 9.363497734069824
I0123 13:50:54.749541 139645810741248 ddar.py:60] Depth 8/1000 time = 8.91578984260559
I0123 13:51:03.188541 139645810741248 ddar.py:60] Depth 9/1000 time = 8.436922788619995
I0123 13:51:12.195115 139645810741248 ddar.py:60] Depth 10/1000 time = 8.985962390899658
I0123 13:51:12.198329 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:51:12.198392 139645810741248 alphageometry.py:566] LM output (score=-4.989550): "q : T f g h q 25 T f q g h 26 ;"
I0123 13:51:12.198425 139645810741248 alphageometry.py:567] Translation: "q = on_tline q h f g, on_tline q f g h"

I0123 13:51:12.198525 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g, on_tline q f g h ? para d n o m"
I0123 13:51:12.198735 139645810741248 graph.py:498] 
I0123 13:51:12.198798 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h f g, on_tline q f g h ? para d n o m
I0123 13:51:19.175493 139645810741248 ddar.py:60] Depth 1/1000 time = 6.884680271148682
I0123 13:51:26.950613 139645810741248 ddar.py:60] Depth 2/1000 time = 7.7749412059783936
I0123 13:51:35.531302 139645810741248 ddar.py:60] Depth 3/1000 time = 8.580502986907959
I0123 13:51:44.189392 139645810741248 ddar.py:60] Depth 4/1000 time = 8.65787672996521
I0123 13:51:52.748753 139645810741248 ddar.py:60] Depth 5/1000 time = 8.558961153030396
I0123 13:52:02.250431 139645810741248 ddar.py:60] Depth 6/1000 time = 9.499913930892944
I0123 13:52:10.841985 139645810741248 ddar.py:60] Depth 7/1000 time = 8.591346025466919
I0123 13:52:20.039473 139645810741248 ddar.py:60] Depth 8/1000 time = 9.197272062301636
I0123 13:52:29.726179 139645810741248 ddar.py:60] Depth 9/1000 time = 9.684063196182251
I0123 13:52:39.146929 139645810741248 ddar.py:60] Depth 10/1000 time = 9.399533033370972
I0123 13:52:39.150520 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:52:39.150581 139645810741248 alphageometry.py:566] LM output (score=-4.995108): "q : T h o h q 25 ;"
I0123 13:52:39.150615 139645810741248 alphageometry.py:567] Translation: "q = on_tline q h h o"

I0123 13:52:39.150651 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h h o ? para d n o m"
I0123 13:52:39.150847 139645810741248 graph.py:498] 
I0123 13:52:39.150906 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q h h o ? para d n o m
I0123 13:52:45.548514 139645810741248 ddar.py:60] Depth 1/1000 time = 6.267459154129028
I0123 13:52:53.221987 139645810741248 ddar.py:60] Depth 2/1000 time = 7.673259258270264
I0123 13:53:02.238740 139645810741248 ddar.py:60] Depth 3/1000 time = 9.016462087631226
I0123 13:53:10.915424 139645810741248 ddar.py:60] Depth 4/1000 time = 8.676451921463013
I0123 13:53:19.027943 139645810741248 ddar.py:60] Depth 5/1000 time = 8.112215280532837
I0123 13:53:27.672423 139645810741248 ddar.py:60] Depth 6/1000 time = 8.64406156539917
I0123 13:53:35.861842 139645810741248 ddar.py:60] Depth 7/1000 time = 8.188250064849854
I0123 13:53:44.847309 139645810741248 ddar.py:60] Depth 8/1000 time = 8.985273122787476
I0123 13:53:53.934937 139645810741248 ddar.py:60] Depth 9/1000 time = 9.087408542633057
I0123 13:54:02.959260 139645810741248 ddar.py:60] Depth 10/1000 time = 9.021774053573608
I0123 13:54:12.149354 139645810741248 ddar.py:60] Depth 11/1000 time = 9.1680166721344
I0123 13:54:12.152757 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:54:12.152815 139645810741248 alphageometry.py:566] LM output (score=-5.019589): "q : T c g i q 25 ;"
I0123 13:54:12.152849 139645810741248 alphageometry.py:567] Translation: "q = on_tline q i c g"

I0123 13:54:12.152937 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q i c g ? para d n o m"
I0123 13:54:12.153144 139645810741248 graph.py:498] 
I0123 13:54:12.153206 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q i c g ? para d n o m
I0123 13:54:18.581999 139645810741248 ddar.py:60] Depth 1/1000 time = 6.261149883270264
I0123 13:54:26.857726 139645810741248 ddar.py:60] Depth 2/1000 time = 8.275543689727783
I0123 13:54:35.382614 139645810741248 ddar.py:60] Depth 3/1000 time = 8.524672985076904
I0123 13:54:44.585770 139645810741248 ddar.py:60] Depth 4/1000 time = 9.20289421081543
I0123 13:54:52.747502 139645810741248 ddar.py:60] Depth 5/1000 time = 8.161167860031128
I0123 13:55:01.475731 139645810741248 ddar.py:60] Depth 6/1000 time = 8.727383613586426
I0123 13:55:09.856518 139645810741248 ddar.py:60] Depth 7/1000 time = 8.380477905273438
I0123 13:55:19.422211 139645810741248 ddar.py:60] Depth 8/1000 time = 9.565464973449707
I0123 13:55:27.896984 139645810741248 ddar.py:60] Depth 9/1000 time = 8.472718954086304
I0123 13:55:36.920609 139645810741248 ddar.py:60] Depth 10/1000 time = 9.004647493362427
I0123 13:55:36.923814 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:55:36.923885 139645810741248 alphageometry.py:566] LM output (score=-5.027497): "q : T c g e q 25 ;"
I0123 13:55:36.923918 139645810741248 alphageometry.py:567] Translation: "q = on_tline q e c g"

I0123 13:55:36.923953 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e c g ? para d n o m"
I0123 13:55:36.924159 139645810741248 graph.py:498] 
I0123 13:55:36.924263 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q e c g ? para d n o m
I0123 13:55:43.873203 139645810741248 ddar.py:60] Depth 1/1000 time = 6.9157843589782715
I0123 13:55:51.571403 139645810741248 ddar.py:60] Depth 2/1000 time = 7.698019742965698
I0123 13:56:00.132145 139645810741248 ddar.py:60] Depth 3/1000 time = 8.56053876876831
I0123 13:56:09.327497 139645810741248 ddar.py:60] Depth 4/1000 time = 9.195116758346558
I0123 13:56:17.524487 139645810741248 ddar.py:60] Depth 5/1000 time = 8.19654655456543
I0123 13:56:26.206834 139645810741248 ddar.py:60] Depth 6/1000 time = 8.681500434875488
I0123 13:56:35.285336 139645810741248 ddar.py:60] Depth 7/1000 time = 9.078274488449097
I0123 13:56:43.713172 139645810741248 ddar.py:60] Depth 8/1000 time = 8.42759370803833
I0123 13:56:52.817182 139645810741248 ddar.py:60] Depth 9/1000 time = 9.101995706558228
I0123 13:57:01.402037 139645810741248 ddar.py:60] Depth 10/1000 time = 8.566184520721436
I0123 13:57:01.405183 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:57:01.405266 139645810741248 alphageometry.py:566] LM output (score=-5.099990): "q : T b p n q 25 T b q n p 26 ;"
I0123 13:57:01.405307 139645810741248 alphageometry.py:567] Translation: "q = on_tline q n b p, on_tline q b n p"

I0123 13:57:01.405349 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q n b p, on_tline q b n p ? para d n o m"
I0123 13:57:01.405554 139645810741248 graph.py:498] 
I0123 13:57:01.405823 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b l, on_bline p l b; q = on_tline q n b p, on_tline q b n p ? para d n o m
I0123 13:57:08.470390 139645810741248 ddar.py:60] Depth 1/1000 time = 7.013649940490723
I0123 13:57:16.441922 139645810741248 ddar.py:60] Depth 2/1000 time = 7.971329689025879
I0123 13:57:25.170263 139645810741248 ddar.py:60] Depth 3/1000 time = 8.728148937225342
I0123 13:57:33.561708 139645810741248 ddar.py:60] Depth 4/1000 time = 8.391246795654297
I0123 13:57:42.397412 139645810741248 ddar.py:60] Depth 5/1000 time = 8.835509300231934
I0123 13:57:50.729180 139645810741248 ddar.py:60] Depth 6/1000 time = 8.331311464309692
I0123 13:57:59.592247 139645810741248 ddar.py:60] Depth 7/1000 time = 8.861600637435913
I0123 13:58:08.843030 139645810741248 ddar.py:60] Depth 8/1000 time = 9.250576257705688
I0123 13:58:17.521718 139645810741248 ddar.py:60] Depth 9/1000 time = 8.678452968597412
I0123 13:58:26.836584 139645810741248 ddar.py:60] Depth 10/1000 time = 9.312222003936768
I0123 13:58:36.261809 139645810741248 ddar.py:60] Depth 11/1000 time = 9.401178121566772
I0123 13:58:36.265540 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 13:58:36.265606 139645810741248 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : D a d b d 00 D b d c d 01 ; e : D b d d e 02 ; f : C c e f 03 ^ b c b f b f b e 04 ; g : C c e g 05 ^ a c a g a g a e 06 ; h : C a g h 07 C b f h 08 ; i : C a b i 09 ^ e a e i e i e b 10 ; j : C a b j 11 ^ c a c j c j c b 12 ; k : C c j k 13 C e i k 14 ; l : C b e l 15 C h k l 16 ; m : C a c m 17 C h k m 18 ; n : C l m n 19 D l n m n 20 ; o : C b h o 21 D b d d o 22 ? P d n o m {F1} x00 p : C b g p 23 D b p g p 24 ; x00
I0123 13:58:45.289226 139645810741248 alphageometry.py:566] LM output (score=-1.055529): "q : C b j q 25 D b q j q 26 ;"
I0123 13:58:45.289372 139645810741248 alphageometry.py:567] Translation: "q = on_line q b j, on_bline q j b"

I0123 13:58:45.289414 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b j, on_bline q j b ? para d n o m"
I0123 13:58:45.289605 139645810741248 graph.py:498] 
I0123 13:58:45.289672 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b j, on_bline q j b ? para d n o m
I0123 13:58:53.376950 139645810741248 ddar.py:60] Depth 1/1000 time = 7.977138519287109
I0123 13:59:03.154879 139645810741248 ddar.py:60] Depth 2/1000 time = 9.777755737304688
I0123 13:59:13.049232 139645810741248 ddar.py:60] Depth 3/1000 time = 9.894179821014404
I0123 13:59:23.551864 139645810741248 ddar.py:60] Depth 4/1000 time = 10.502433776855469
I0123 13:59:33.552235 139645810741248 ddar.py:60] Depth 5/1000 time = 9.999844551086426
I0123 13:59:43.622908 139645810741248 ddar.py:60] Depth 6/1000 time = 10.069596767425537
I0123 13:59:53.327718 139645810741248 ddar.py:60] Depth 7/1000 time = 9.704564809799194
I0123 14:00:04.964263 139645810741248 ddar.py:60] Depth 8/1000 time = 11.636146545410156
I0123 14:00:15.779089 139645810741248 ddar.py:60] Depth 9/1000 time = 10.81215524673462
I0123 14:00:27.095275 139645810741248 ddar.py:60] Depth 10/1000 time = 11.300330638885498
I0123 14:00:27.098557 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 14:00:27.098616 139645810741248 alphageometry.py:566] LM output (score=-1.125611): "q : C b p q 25 D b q p q 26 ;"
I0123 14:00:27.098651 139645810741248 alphageometry.py:567] Translation: "q = on_line q b p, on_bline q p b"

I0123 14:00:27.098690 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b p, on_bline q p b ? para d n o m"
I0123 14:00:27.098888 139645810741248 graph.py:498] 
I0123 14:00:27.098950 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b p, on_bline q p b ? para d n o m
I0123 14:00:34.138065 139645810741248 ddar.py:60] Depth 1/1000 time = 6.813365459442139
I0123 14:00:42.068368 139645810741248 ddar.py:60] Depth 2/1000 time = 7.930097341537476
I0123 14:00:50.130572 139645810741248 ddar.py:60] Depth 3/1000 time = 8.06200122833252
I0123 14:00:58.789470 139645810741248 ddar.py:60] Depth 4/1000 time = 8.65849256515503
I0123 14:01:06.917973 139645810741248 ddar.py:60] Depth 5/1000 time = 8.12754774093628
I0123 14:01:15.029968 139645810741248 ddar.py:60] Depth 6/1000 time = 8.111005544662476
I0123 14:01:23.273106 139645810741248 ddar.py:60] Depth 7/1000 time = 8.24289608001709
I0123 14:01:32.131843 139645810741248 ddar.py:60] Depth 8/1000 time = 8.858413696289062
I0123 14:01:41.183914 139645810741248 ddar.py:60] Depth 9/1000 time = 9.049573183059692
I0123 14:01:49.020339 139645810741248 ddar.py:60] Depth 10/1000 time = 7.821057081222534
I0123 14:01:49.022340 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 14:01:49.022402 139645810741248 alphageometry.py:566] LM output (score=-1.377393): "q : C b l q 25 D b q l q 26 ;"
I0123 14:01:49.022438 139645810741248 alphageometry.py:567] Translation: "q = on_line q b l, on_bline q l b"

I0123 14:01:49.022476 139645810741248 alphageometry.py:576] Solving: "a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b l, on_bline q l b ? para d n o m"
I0123 14:01:49.022706 139645810741248 graph.py:498] 
I0123 14:01:49.022770 139645810741248 graph.py:499] a b c = triangle a b c; d = circle d a b c; e = on_circle e d b; f = angle_bisector f c b e, on_line f c e; g = angle_bisector g c a e, on_line g c e; h = on_line h b f, on_line h a g; i = angle_bisector i b e a, on_line i b a; j = angle_bisector j b c a, on_line j b a; k = on_line k e i, on_line k c j; l = on_line l h k, on_line l b e; m = on_line m h k, on_line m a c; n = midpoint n l m; o = on_circle o d b, on_line o h b; p = on_line p b g, on_bline p g b; q = on_line q b l, on_bline q l b ? para d n o m
I0123 14:01:56.761632 139645810741248 ddar.py:60] Depth 1/1000 time = 7.677716493606567
I0123 14:02:06.331666 139645810741248 ddar.py:60] Depth 2/1000 time = 9.56952452659607
I0123 14:02:15.469366 139645810741248 ddar.py:60] Depth 3/1000 time = 9.137341737747192
I0123 14:02:24.905637 139645810741248 ddar.py:60] Depth 4/1000 time = 9.435938835144043
I0123 14:02:24.906179 139645810741248 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 14:02:24.906222 139645810741248 alphageometry.py:585] Timeout.
