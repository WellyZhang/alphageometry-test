I0123 17:55:11.151293 140567322951680 inference_utils.py:69] Parsing gin configuration.
I0123 17:55:11.151392 140567322951680 inference_utils.py:71] Added Gin search path meliad_lib/meliad/transformer/configs
I0123 17:55:11.151589 140567322951680 inference_utils.py:74] Loading Gin config file base_htrans.gin
I0123 17:55:11.151622 140567322951680 inference_utils.py:74] Loading Gin config file size/medium_150M.gin
I0123 17:55:11.151652 140567322951680 inference_utils.py:74] Loading Gin config file options/positions_t5.gin
I0123 17:55:11.151680 140567322951680 inference_utils.py:74] Loading Gin config file options/lr_cosine_decay.gin
I0123 17:55:11.151708 140567322951680 inference_utils.py:74] Loading Gin config file options/seq_1024_nocache.gin
I0123 17:55:11.151737 140567322951680 inference_utils.py:74] Loading Gin config file geometry_150M_generate.gin
I0123 17:55:11.151765 140567322951680 inference_utils.py:76] Overriding Gin param DecoderOnlyLanguageModelGenerate.output_token_losses=True
I0123 17:55:11.151791 140567322951680 inference_utils.py:76] Overriding Gin param TransformerTaskConfig.batch_size=32
I0123 17:55:11.151817 140567322951680 inference_utils.py:76] Overriding Gin param TransformerTaskConfig.sequence_length=128
I0123 17:55:11.151843 140567322951680 inference_utils.py:76] Overriding Gin param Trainer.restore_state_variables=False
I0123 17:55:11.151887 140567322951680 resource_reader.py:50] system_path_file_exists:base_htrans.gin
E0123 17:55:11.152018 140567322951680 resource_reader.py:55] Path not found: base_htrans.gin
I0123 17:55:11.152218 140567322951680 resource_reader.py:50] system_path_file_exists:trainer_configuration.gin
E0123 17:55:11.152314 140567322951680 resource_reader.py:55] Path not found: trainer_configuration.gin
I0123 17:55:11.158457 140567322951680 resource_reader.py:50] system_path_file_exists:size/medium_150M.gin
E0123 17:55:11.158573 140567322951680 resource_reader.py:55] Path not found: size/medium_150M.gin
I0123 17:55:11.158884 140567322951680 resource_reader.py:50] system_path_file_exists:options/positions_t5.gin
E0123 17:55:11.158986 140567322951680 resource_reader.py:55] Path not found: options/positions_t5.gin
I0123 17:55:11.159259 140567322951680 resource_reader.py:50] system_path_file_exists:options/lr_cosine_decay.gin
E0123 17:55:11.159356 140567322951680 resource_reader.py:55] Path not found: options/lr_cosine_decay.gin
I0123 17:55:11.159752 140567322951680 resource_reader.py:50] system_path_file_exists:options/seq_1024_nocache.gin
E0123 17:55:11.159849 140567322951680 resource_reader.py:55] Path not found: options/seq_1024_nocache.gin
I0123 17:55:11.163415 140567322951680 training_loop.py:334] ==== Training loop: initializing model ====
I0123 17:55:11.260228 140567322951680 xla_bridge.py:660] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0123 17:55:11.260965 140567322951680 xla_bridge.py:660] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0123 17:55:11.267875 140567322951680 training_loop.py:335] Process 0 of 1
I0123 17:55:11.267931 140567322951680 training_loop.py:336] Local device count = 1
I0123 17:55:11.267971 140567322951680 training_loop.py:337] Number of replicas = 1
I0123 17:55:11.268004 140567322951680 training_loop.py:339] Using random number seed 42
I0123 17:55:11.767167 140567322951680 training_loop.py:359] Initializing the model.
I0123 17:55:12.186982 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.187251 140567322951680 decoder_stack.py:316] dstack: scanning over 1 windows.
I0123 17:55:12.187354 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187432 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187507 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187588 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187659 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187730 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187799 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187868 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.187936 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.188005 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.188073 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.188142 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode init.
I0123 17:55:12.188181 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.188225 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:12.188338 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.188377 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.188407 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.190452 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.195747 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.206550 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.206832 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.211205 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.221760 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.221817 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.221855 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.221887 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.221949 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.223141 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.223219 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.223932 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.226370 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.232124 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.233854 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.233936 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.233971 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.234032 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.234158 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.234487 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.234534 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.236461 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.236562 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.239437 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.239517 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.240008 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.250189 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.259197 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.259297 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.259603 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.259685 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:12.259798 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.259838 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.259871 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.261741 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.264256 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.269943 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.270212 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.272879 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.276732 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.276788 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.276826 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.276858 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.276921 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.277496 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.277572 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.277953 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.278736 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.281253 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.281884 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.281965 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.282001 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.282062 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.282192 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.282523 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.282567 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.284536 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.284629 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.287195 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.287275 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.287715 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.290057 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.291973 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.292069 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.292365 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.292446 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:12.292556 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.292596 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.292628 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.294546 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.296952 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.302980 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.303241 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.305945 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.310461 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.310576 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.310614 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.310647 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.310720 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.311387 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.311466 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.311853 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.312657 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.315235 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.315909 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.315987 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.316024 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.316084 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.316215 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.316562 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.316606 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.318588 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.318684 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.321232 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.322596 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.323095 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.325440 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.327374 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.327469 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.327766 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.327851 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:12.327964 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.328005 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.328037 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.329946 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.332360 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.338056 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.338323 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.340981 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.344851 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.344908 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.344945 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.344977 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.345040 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.345608 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.345689 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.346065 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.346855 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.349442 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.350082 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.350162 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.350198 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.350259 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.350393 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.350727 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.350771 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.352733 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.352826 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.355440 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.355529 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.355965 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.358278 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.360213 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.360307 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.360605 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.360689 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:12.360798 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.360838 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.360870 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.362780 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.365208 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.370931 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.371198 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.373966 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.377784 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.377841 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.377878 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.377911 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.377973 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.378546 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.378624 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.378996 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.379782 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.382694 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.383328 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.383407 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.383444 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.383506 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.383639 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.383968 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.384012 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.385954 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.386047 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.388643 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.388723 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.389162 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.391472 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.393466 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.393561 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.393872 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.393955 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:12.394068 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.394107 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.394140 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.396007 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.398439 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.404180 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.404439 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.407186 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.410976 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.411036 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.411073 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.411107 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.411170 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.411786 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.411864 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.412234 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.413029 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.415562 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.416190 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.416269 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.416306 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.416367 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.416495 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.416821 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.416866 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.418797 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.418890 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.421496 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.421576 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.422013 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.424355 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.426311 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.426408 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.426710 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.426793 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:12.426905 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.426944 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.426977 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.428849 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.431352 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.437088 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.437352 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.440058 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.443907 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.443965 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.444002 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.444034 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.444097 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.444673 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.444753 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.445118 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.445911 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.448462 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.449092 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.449170 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.449206 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.449267 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.449394 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.449731 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.449777 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.451792 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.451886 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.454464 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.454546 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.454979 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.457664 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.459603 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.459704 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.460006 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.460088 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:12.460198 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.460238 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.460271 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.600594 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.603857 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.609838 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.610145 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.612918 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.616939 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.616996 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.617036 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.617069 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.617131 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.617776 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.617855 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.618232 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.619032 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.621684 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.622330 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.622409 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.622447 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.622508 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.622639 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.622983 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.623029 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.624966 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.625061 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.627756 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.627837 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.628282 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.630659 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.632610 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.632717 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.633018 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.633103 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:12.633215 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.633255 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.633288 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.635256 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.637690 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.643423 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.643696 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.646461 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.650285 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.650341 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.650379 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.650412 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.650475 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.651055 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.651133 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.651495 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.652280 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.654905 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.655532 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.655610 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.655646 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.655706 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.655834 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.656174 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.656219 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.658179 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.658275 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.660897 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.660976 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.661415 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.663741 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.665737 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.665834 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.666138 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.666226 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:12.666341 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.666382 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.666415 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.668379 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.670898 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.676520 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.676785 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.679887 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.683671 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.683728 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.683765 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.683797 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.683860 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.684481 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.684559 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.684926 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.685724 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.688244 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.688871 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.688950 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.688986 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.689045 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.689177 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.689508 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.689553 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.691479 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.691573 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.694181 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.694261 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.694694 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.697036 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.698982 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.699077 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.699379 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.699467 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:12.699582 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.699622 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.699655 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.701530 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.704013 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.709678 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.709948 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.712626 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.716466 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.716522 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.716561 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.716594 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.716658 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.717232 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.717308 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.717689 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.718473 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.720978 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.721607 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.721691 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.721728 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.721788 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.721916 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.722242 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.722286 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.724259 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.724354 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.727175 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.727256 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.727693 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.730033 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.731964 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.732059 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.732366 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.732448 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:12.732569 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.732609 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.732641 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.734553 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.736983 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.742596 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.742869 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.745475 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:12.749327 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.749384 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.749422 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.749455 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.749517 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.750099 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.750176 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.750544 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.751327 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.753850 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.754830 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.754909 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.754945 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.755007 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.755139 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.755468 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.755513 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.757457 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.757550 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.760101 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.760181 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.760670 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.762940 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.764854 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.764948 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.765242 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.765527 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765598 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765673 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765734 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765792 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765850 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765907 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.765961 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.766016 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.766071 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.766127 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.766181 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode init.
I0123 17:55:12.766219 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:12.769814 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:12.817843 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.817929 140567322951680 decoder_stack.py:333] dstack: autoregressive generator.
I0123 17:55:12.817984 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:12.818089 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.818127 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.818158 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.818222 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.820665 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.826140 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.826401 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.829075 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:12.845524 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.845581 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.845616 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.845652 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.845716 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.846835 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.846915 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.847627 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.849635 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.854396 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.855709 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.855800 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.855838 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.855900 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.856034 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.856146 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.856186 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.858151 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.858247 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.860725 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.860809 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.860920 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.863193 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.865358 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.865453 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.865753 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.865838 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:12.865946 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.865985 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.866015 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.866077 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.868337 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.873838 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.874098 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.876831 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:12.889898 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.889954 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.889991 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.890022 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.890085 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.890642 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.890851 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.891208 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.891909 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.894433 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.895055 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.895134 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.895175 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.895234 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.895365 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.895480 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.895519 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.897445 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.897538 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.899964 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.900045 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.900154 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.902370 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.904308 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.904403 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.904694 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.904775 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:12.904886 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.904925 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.904957 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.905020 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.907285 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.912708 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.912963 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.915650 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:12.928217 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.928274 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.928310 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.928340 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.928402 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.928957 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.929033 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.929390 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.930095 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.932570 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.933182 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.933258 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.933294 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.933361 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.933492 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.933601 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.933645 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.935579 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.935672 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.938091 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.938171 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.938280 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.940500 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.942421 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.942515 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.942803 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.942883 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:12.942992 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.943031 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.943062 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.943125 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.945372 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.950813 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.951071 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.953743 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:12.966256 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:12.966311 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:12.966347 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:12.966379 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.966439 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.966989 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.967068 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.967419 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.968100 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.974658 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.975392 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.975473 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:12.975510 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:12.975582 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.975726 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:12.975854 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:12.975894 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.977986 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.978081 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.980571 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.980649 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:12.980759 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:12.983019 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:12.984897 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.984991 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:12.985280 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.985366 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:12.985479 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:12.985520 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:12.985552 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:12.985619 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.988237 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:12.993832 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:12.994097 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:12.996789 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.009476 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.009531 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.009567 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.009598 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.009666 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.010230 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.010308 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.010673 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.011373 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.013979 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.014607 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.014688 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.014725 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.014785 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.014921 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.015031 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.015070 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.016967 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.017060 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.019498 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.019578 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.019690 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.021971 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.023847 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.023941 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.024236 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.024318 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:13.024428 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.024467 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.024498 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.024560 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.026826 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.032316 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.032572 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.035299 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.047993 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.048050 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.048088 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.048120 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.048184 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.048744 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.048819 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.049177 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.049882 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.052385 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.053007 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.053085 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.053121 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.053178 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.053310 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.053426 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.053469 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.055431 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.055526 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.057972 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.058053 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.058165 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.060416 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.062289 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.062385 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.062674 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.062756 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:13.062866 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.062906 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.062937 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.063001 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.065268 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.070817 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.071073 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.073687 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.086317 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.086373 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.086409 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.086440 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.086501 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.087059 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.087135 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.087494 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.088177 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.090672 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.091667 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.091746 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.091781 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.091842 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.091973 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.092083 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.092126 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.094057 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.094152 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.096567 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.096646 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.096752 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.098971 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.100922 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.101017 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.101310 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.101391 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:13.101500 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.101539 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.101570 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.101632 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.103884 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.109334 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.109601 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.112286 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.124831 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.124887 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.124923 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.124953 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.125015 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.125621 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.125702 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.126065 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.126763 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.129264 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.129881 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.129958 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.129993 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.130051 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.130183 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.130292 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.130336 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.132232 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.132326 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.134812 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.134893 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.135000 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.137207 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.139071 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.139168 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.139457 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.139539 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:13.139647 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.139685 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.139715 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.139777 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.142020 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.147502 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.147759 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.150380 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.162957 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.163013 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.163050 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.163081 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.163143 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.163714 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.163791 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.164155 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.164853 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.167358 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.168020 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.168098 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.168133 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.168194 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.168329 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.168440 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.168480 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.170371 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.170464 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.172855 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.172933 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.173040 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.175248 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.177175 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.177269 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.177558 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.177644 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:13.177756 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.177795 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.177826 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.177890 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.180136 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.185543 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.185806 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.188488 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.201304 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.201360 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.201396 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.201426 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.201486 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.202105 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.202183 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.202541 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.203236 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.205722 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.206339 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.206415 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.206450 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.206506 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.206632 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.206739 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.206778 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.208645 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.208742 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.211197 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.211282 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.211389 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.213578 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.215426 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.215521 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.215803 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.215883 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:13.215991 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.216029 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.216060 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.216121 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.218356 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.223839 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.224097 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.226714 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.239208 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.239264 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.239299 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.239329 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.239389 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.239943 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.240018 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.240375 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.241059 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.243566 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.244226 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.244303 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.244338 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.244395 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.244525 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.244635 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.244673 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.246555 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.246653 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.249068 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.249147 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.249252 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.251452 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.253371 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.253466 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.253760 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.253841 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:13.253948 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.253987 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.254017 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.254080 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.256306 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.261764 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.262017 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.264679 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.277165 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.277221 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.277257 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.277288 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.277349 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.277920 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.277997 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.278354 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.279086 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.281599 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.282224 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.282302 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.282337 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.282395 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.282521 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.282633 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.282672 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.284544 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.284637 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.287040 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.287120 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.287226 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.289479 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.291339 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.291433 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.291716 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.291803 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:13.294676 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:13.349873 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.349958 140567322951680 decoder_stack.py:333] dstack: autoregressive generator.
I0123 17:55:13.350013 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:13.350118 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.350157 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.350188 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.350251 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.352877 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.358230 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.358489 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.361037 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.373195 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.373251 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.373287 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.373318 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.373379 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.373937 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.374013 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.374369 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.375041 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.377547 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.378158 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.378234 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.378268 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.378326 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.378451 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.378565 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.378604 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.380441 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.380533 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.382919 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.382998 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.383105 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.385330 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.387176 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.387271 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.387558 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.387638 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:13.387746 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.387786 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.387817 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.387878 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.390109 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.395418 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.395675 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.398313 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.410388 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.410443 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.410480 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.410510 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.410570 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.411121 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.411196 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.411549 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.412220 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.414725 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.415333 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.415410 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.415445 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.415504 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.415631 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.415738 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.415783 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.417627 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.417726 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.420077 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.420156 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.420264 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.422511 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.424355 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.424451 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.424740 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.424822 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:13.424929 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.424968 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.424999 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.425061 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.427275 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.432617 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.432871 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.435513 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.447573 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.447629 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.447665 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.447695 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.447756 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.448303 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.448378 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.448730 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.449392 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.451891 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.452496 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.452573 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.452608 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.452666 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.452796 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.452905 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.452943 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.454775 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.454869 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.457247 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.457325 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.457432 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.460124 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.461964 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.462059 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.462348 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.462429 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:13.462536 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.462575 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.462606 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.462667 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.464884 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.470218 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.470473 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.473121 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.485253 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.485310 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.485353 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.485394 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.485458 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.486030 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.486105 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.486456 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.487135 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.489648 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.490255 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.490331 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.490365 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.490422 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.490546 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.490651 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.490690 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.492542 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.492632 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.495009 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.495088 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.495194 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.497481 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.499340 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.499434 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.499720 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.499798 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:13.499904 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.499941 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.499970 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.500030 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.502218 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.507528 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.507780 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.510491 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.522828 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.522881 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.522915 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.522944 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.523007 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.523558 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.523632 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.523985 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.524663 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.527195 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.527809 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.527884 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.527917 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.527971 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.528095 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.528202 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.528239 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.530091 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.530187 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.532560 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.532636 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.532741 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.535008 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.536855 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.536948 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.537231 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.537311 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:13.537417 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.537456 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.537485 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.537546 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.539772 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.545344 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.545598 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.548277 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.560809 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.560862 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.560896 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.560926 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.560987 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.561539 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.561614 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.561977 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.562667 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.565209 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.565829 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.565907 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.565940 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.565996 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.566122 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.566229 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.566266 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.568123 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.568220 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.570615 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.570693 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.570802 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.573505 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.575364 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.575459 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.575745 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.575824 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:13.575931 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.575969 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.575999 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.576060 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.578307 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.583719 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.583978 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.586669 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.599078 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.599132 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.599165 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.599195 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.599254 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.599811 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.599887 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.600244 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.600933 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.603483 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.604102 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.604178 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.604212 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.604268 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.604391 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.604497 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.604534 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.606402 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.606493 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.608916 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.608994 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.609105 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.611420 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.613287 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.613381 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.613679 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.613760 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:13.613868 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.613907 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.613937 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.614000 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.616258 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.621748 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.622004 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.624721 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.637140 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.637195 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.637229 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.637259 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.637319 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.637889 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.637965 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.638324 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.639004 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.641537 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.642162 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.642238 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.642271 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.642329 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.642454 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.642559 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.642597 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.644534 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.644625 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.647024 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.647108 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.647217 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.649496 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.651371 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.651465 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.651753 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.651832 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:13.651940 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.651978 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.652007 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.652071 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.654300 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.659691 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.659947 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.662651 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.675074 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.675127 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.675162 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.675191 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.675255 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.675811 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.675885 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.676237 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.676920 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.679490 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.680101 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.680176 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.680209 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.680267 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.680393 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.680499 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.680537 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.682389 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.682480 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.684882 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.684963 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.685071 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.687731 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.689613 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.689712 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.689999 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.690080 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:13.690186 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.690224 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.690253 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.690313 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.692534 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.697948 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.698204 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.700894 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.713296 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.713350 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.713384 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.713414 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.713475 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.714050 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.714125 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.714486 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.715172 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.717726 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.718350 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.718426 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.718459 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.718514 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.718638 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.718743 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.718780 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.721135 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.721229 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.723621 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.723700 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.723812 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.726052 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.727908 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.728001 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.728286 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.728365 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:13.728471 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.728509 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.728539 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.728599 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.730831 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.736235 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.736489 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.739147 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.751496 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.751550 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.751584 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.751614 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.751675 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.752230 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.752304 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.752658 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.753354 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.755900 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.756520 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.756594 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.756628 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.756685 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.756813 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.756920 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.756958 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.758826 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.758918 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.761277 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.761354 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.761460 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.763737 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.765579 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.765679 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.765968 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.766050 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:13.766156 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:13.766193 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:13.766223 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:13.766283 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.768507 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:13.773882 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.774134 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:13.776786 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:13.789082 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:13.789139 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:13.789174 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:13.789204 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.789265 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.789834 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.789910 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.790272 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.790964 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.793483 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.794106 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.794184 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:13.794218 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:13.794274 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.794400 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:13.794511 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:13.794550 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.796413 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.796503 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.798897 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.798974 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:13.799079 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:13.801728 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:13.803608 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.803701 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:13.803985 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:13.804068 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:13.806876 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:18.220096 140567322951680 optimizer_config.py:74] Using Flax Adafactor Optimizer. lr=1.000000, b1=0.900000
I0123 17:55:18.767433 140567322951680 training_loop.py:409] No working directory specified.
I0123 17:55:18.767557 140567322951680 training_loop.py:431] Loading pre-trained model from ag_ckpt_vocab:
I0123 17:55:18.768349 140567322951680 checkpoints.py:1062] Restoring legacy Flax checkpoint from ag_ckpt_vocab/checkpoint_10999999
I0123 17:55:22.166237 140567322951680 training_loop.py:447] Only restoring trainable parameters.
I0123 17:55:22.166900 140567322951680 training_loop.py:724] parameter: decoder/embed/embedding, shape (1024, 1024), size 1048576
I0123 17:55:22.166983 140567322951680 training_loop.py:724] parameter: decoder/final_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167037 140567322951680 training_loop.py:724] parameter: decoder/transformer0/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.167084 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.167128 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167170 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167212 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167252 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167291 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.167329 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.167367 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167404 140567322951680 training_loop.py:724] parameter: decoder/transformer0/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167442 140567322951680 training_loop.py:724] parameter: decoder/transformer1/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.167479 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.167516 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167552 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167588 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167624 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167660 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.167697 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.167748 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167788 140567322951680 training_loop.py:724] parameter: decoder/transformer1/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167825 140567322951680 training_loop.py:724] parameter: decoder/transformer10/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.167861 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.167898 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.167934 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.167970 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168005 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168042 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.168078 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.168115 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168152 140567322951680 training_loop.py:724] parameter: decoder/transformer10/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.168188 140567322951680 training_loop.py:724] parameter: decoder/transformer11/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.168225 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.168262 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168299 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.168336 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168372 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168408 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.168443 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.168479 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168515 140567322951680 training_loop.py:724] parameter: decoder/transformer11/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.168551 140567322951680 training_loop.py:724] parameter: decoder/transformer2/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.168586 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.168622 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168658 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.168699 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168738 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168775 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.168811 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.168847 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.168883 140567322951680 training_loop.py:724] parameter: decoder/transformer2/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.168919 140567322951680 training_loop.py:724] parameter: decoder/transformer3/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.168955 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.168991 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169027 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.169062 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169098 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169134 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.169170 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.169206 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169242 140567322951680 training_loop.py:724] parameter: decoder/transformer3/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.169277 140567322951680 training_loop.py:724] parameter: decoder/transformer4/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.169313 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.169349 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169386 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.169422 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169457 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169493 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.169529 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.169564 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169600 140567322951680 training_loop.py:724] parameter: decoder/transformer4/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.169635 140567322951680 training_loop.py:724] parameter: decoder/transformer5/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.169695 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.169734 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169776 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.169813 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169849 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169885 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.169920 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.169955 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.169991 140567322951680 training_loop.py:724] parameter: decoder/transformer5/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170026 140567322951680 training_loop.py:724] parameter: decoder/transformer6/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.170061 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.170096 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170132 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170168 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170203 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170238 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.170274 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.170309 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170344 140567322951680 training_loop.py:724] parameter: decoder/transformer6/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170380 140567322951680 training_loop.py:724] parameter: decoder/transformer7/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.170415 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.170450 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170485 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170521 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170557 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170593 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.170628 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.170668 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170706 140567322951680 training_loop.py:724] parameter: decoder/transformer7/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170742 140567322951680 training_loop.py:724] parameter: decoder/transformer8/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.170778 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.170814 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170850 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.170886 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170922 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.170957 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.170992 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.171027 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.171062 140567322951680 training_loop.py:724] parameter: decoder/transformer8/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.171097 140567322951680 training_loop.py:724] parameter: decoder/transformer9/relative_positions/rel_embedding, shape (8, 32), size 256
I0123 17:55:22.171131 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/attention_scale, shape (8,), size 8
I0123 17:55:22.171166 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/keys_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.171201 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/pre_attn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.171238 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/queries_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.171273 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/_kvq/values_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.171308 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/ffn/hidden0/kernel, shape (1024, 4096), size 4194304
I0123 17:55:22.171344 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/ffn/output_layer/kernel, shape (4096, 1024), size 4194304
I0123 17:55:22.171378 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/post_attn_mlp/output_layer/kernel, shape (1024, 1024), size 1048576
I0123 17:55:22.171413 140567322951680 training_loop.py:724] parameter: decoder/transformer9/tbase/pre_ffn_layernorm/scale, shape (1024,), size 1024
I0123 17:55:22.171441 140567322951680 training_loop.py:725] Total parameters: 152072288
I0123 17:55:22.171672 140567322951680 training_loop.py:739] Total state size: 0
I0123 17:55:22.196485 140567322951680 training_loop.py:492] Training loop: creating task for mode beam_search
I0123 17:55:22.196718 140567322951680 training_loop.py:685] Creating logging writer (train) for mode beam_search
I0123 17:55:22.197067 140567322951680 training_loop.py:652] Compiling mode beam_search with jit.
I0123 17:55:22.197377 140567322951680 training_loop.py:89] registering functions: dict_keys([])
I0123 17:55:22.213476 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j ? perp a c c k
I0123 17:55:22.781527 140567322951680 ddar.py:60] Depth 1/1000 time = 0.5412697792053223
I0123 17:55:26.164674 140567322951680 ddar.py:60] Depth 2/1000 time = 3.382955312728882
I0123 17:55:29.642249 140567322951680 ddar.py:60] Depth 3/1000 time = 3.477389335632324
I0123 17:55:33.157202 140567322951680 ddar.py:60] Depth 4/1000 time = 3.5147647857666016
I0123 17:55:36.675682 140567322951680 ddar.py:60] Depth 5/1000 time = 3.5179052352905273
I0123 17:55:40.485170 140567322951680 ddar.py:60] Depth 6/1000 time = 3.787229061126709
I0123 17:55:40.485486 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:55:40.485572 140567322951680 alphageometry.py:540] Depth 0. There are 1 nodes to expand:
I0123 17:55:40.485609 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00
I0123 17:55:40.485646 140567322951680 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00
I0123 17:55:40.626843 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.627028 140567322951680 decoder_stack.py:316] dstack: scanning over 1 windows.
I0123 17:55:40.627135 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627215 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627286 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627355 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627423 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627490 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627557 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627624 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627691 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627758 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627826 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627893 140567322951680 transformer_layer.py:657] tlayer: Skipping XL cache for mode beam_search.
I0123 17:55:40.627930 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.627975 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:40.628081 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.628119 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.628149 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.630067 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.632533 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.638280 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.638552 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.641147 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.644990 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.645046 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.645082 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.645116 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.645178 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.646242 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.646318 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.646691 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.647464 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.650010 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.650632 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.650707 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.650741 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.650799 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.650925 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.651251 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.651292 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.653262 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.653355 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.655822 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.655900 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.656325 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.658622 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.660535 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.660628 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.660916 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.660996 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:40.661102 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.661139 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.661169 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.663029 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.665347 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.670883 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.671144 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.673763 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.677371 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.677424 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.677459 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.677488 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.677549 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.678100 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.678174 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.678525 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.679274 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.681711 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.682367 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.682442 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.682476 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.682534 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.682657 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.682966 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.683007 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.684921 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.685013 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.687454 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.687532 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.687958 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.690270 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.692175 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.692266 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.692556 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.692635 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:40.692741 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.692779 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.692808 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.694586 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.696904 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.702628 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.702892 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.705461 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.709099 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.709153 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.709187 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.709218 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.709277 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.709891 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.709966 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.710321 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.711075 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.713494 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.714108 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.714183 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.714216 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.714272 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.714399 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.714716 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.714759 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.716734 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.716825 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.719252 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.719330 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.719751 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.721975 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.723881 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.723973 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.724261 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.724339 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:40.724443 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.724479 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.724508 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.726352 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.728596 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.734067 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.734315 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.736883 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.740494 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.740548 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.740583 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.740613 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.740674 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.741224 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.741298 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.741651 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.742401 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.744837 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.745501 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.745577 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.745611 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.745675 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.745804 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.746115 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.746157 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.748036 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.748126 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.750533 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.750612 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.751030 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.753655 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.755550 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.755642 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.755928 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.756008 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:40.756114 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.756151 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.756181 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.757932 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.760205 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.765780 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.766031 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.768561 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.772122 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.772182 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.772217 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.772247 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.772357 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.772910 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.772984 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.773334 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.774084 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.776500 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.777094 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.777167 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.777200 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.777256 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.777380 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.777701 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.777743 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.779685 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.779774 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.782202 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.782281 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.782698 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.784909 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.786787 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.786878 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.787160 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.787237 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:40.787341 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.787379 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.787407 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.789218 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.791495 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.796956 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.797204 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.799788 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.803332 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.803384 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.803424 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.803455 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.803515 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.804054 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.804127 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.804477 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.805220 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.807647 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.808306 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.808382 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.808415 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.808470 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.808625 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.808946 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.808987 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.810879 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.810969 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.813405 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.813480 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.813905 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.816201 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.818104 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.818197 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.818482 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.818561 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:40.818665 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.818702 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.818731 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.820487 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.822760 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.828290 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.828540 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.831045 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.834574 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.834629 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.834663 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.834700 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.834811 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.835367 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.835440 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.835791 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.836537 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.838921 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.839516 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.839590 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.839623 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.839678 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.839801 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.840110 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.840151 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.842079 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.842170 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.844591 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.844667 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.845084 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.847292 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.849164 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.849254 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.849538 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.849616 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:40.849728 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.849765 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.849794 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.851613 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.853911 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.859449 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.859702 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.862642 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.866245 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.866300 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.866334 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.866364 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.866429 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.866977 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.867050 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.867403 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.868170 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.870620 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.871278 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.871353 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.871386 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.871441 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.871565 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.871881 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.871922 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.873815 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.873906 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.876304 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.876380 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.876792 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.879073 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.880926 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.881017 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.881302 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.881380 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:40.881485 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.881521 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.881551 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.883307 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.885580 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.891162 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.891413 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.893940 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.897513 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.897565 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.897600 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.897629 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.897698 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.898312 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.898387 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.898748 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.899516 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.901974 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.902583 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.902657 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.902692 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.902747 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.902876 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.903187 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.903228 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.905126 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.905216 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.907691 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.907769 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.908184 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.910415 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.912295 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.912388 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.912678 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.912757 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:40.912864 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.912902 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.912931 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.914697 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.917055 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.922610 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.922857 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.925384 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.928975 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.929029 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.929063 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.929092 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.929204 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.929764 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.929839 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.930191 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.930943 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.933393 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.934005 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.934081 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.934113 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.934168 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.934292 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.934605 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.934646 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.936584 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.936674 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.939089 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.939166 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.939584 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.941813 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.943684 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.943775 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.944066 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.944144 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:40.944251 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.944288 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.944317 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.946142 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.948416 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.953933 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.954184 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.956702 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.960344 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.960398 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.960432 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.960461 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.960522 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.961074 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.961153 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.961505 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.962260 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.964693 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.965301 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.965377 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.965411 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.965467 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.965591 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.965911 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.965954 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.967906 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.967996 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.970405 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.970482 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:40.970897 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:40.973097 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.974965 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.975057 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:40.975342 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.975421 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:40.975526 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:40.975563 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:40.975592 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:40.977755 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.980009 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:40.985473 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.985734 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:40.988255 140567322951680 transformer_layer.py:213] tlayer: windowed attention.
I0123 17:55:40.991873 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:40.991926 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:40.991959 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:40.991989 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.992049 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.992593 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.992671 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[1,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.993024 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.993783 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.996227 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.996830 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.996905 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:40.996938 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:40.996994 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.997118 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:40.997428 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:40.997469 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:40.999411 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:40.999501 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.001881 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:41.001957 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.002371 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.004593 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.006468 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:41.006560 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.006845 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:41.007086 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007151 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007205 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007256 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007307 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007358 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007408 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007457 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007506 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007556 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007607 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007657 140567322951680 transformer_layer.py:673] tlayer: Skipping XL cache update for mode beam_search.
I0123 17:55:41.007690 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:41.010528 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=1/0)>
I0123 17:55:41.054407 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.054496 140567322951680 decoder_stack.py:333] dstack: autoregressive generator.
I0123 17:55:41.054549 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:41.054654 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.054692 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.054720 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.054780 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.057137 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.062474 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.062727 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.065278 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.077831 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.077886 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.077920 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.077950 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.078009 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.078567 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.078640 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.078996 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.079683 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.082237 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.082853 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.082928 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.082962 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.083017 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.083141 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.083246 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.083283 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.085126 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.085218 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.087600 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.087678 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.087782 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.090000 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.091820 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.091912 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.092197 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.092281 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:41.092389 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.092427 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.092457 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.092516 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.094731 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.100034 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.100289 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.102909 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.115087 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.115141 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.115175 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.115203 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.115262 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.115811 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.115885 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.116235 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.116962 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.119431 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.120033 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.120107 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.120140 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.120196 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.120321 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.120426 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.120463 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.122297 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.122387 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.124762 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.124840 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.124945 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.127171 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.128999 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.129091 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.129375 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.129459 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:41.129566 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.129604 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.129633 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.129701 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.131900 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.137252 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.137501 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.140139 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.152331 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.152384 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.152417 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.152447 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.152506 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.153057 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.153132 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.153485 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.154628 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.157095 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.157716 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.157792 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.157825 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.157880 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.158007 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.158114 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.158152 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.159978 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.160069 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.162467 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.162545 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.162651 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.164885 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.166767 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.166860 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.167150 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.167229 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:41.167342 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.167381 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.167410 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.167469 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.169693 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.174993 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.175246 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.177881 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.190053 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.190105 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.190139 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.190169 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.190228 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.190775 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.190850 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.191203 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.191940 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.194401 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.195008 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.195082 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.195116 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.195171 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.195299 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.195406 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.195443 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.197280 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.197370 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.199730 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.199806 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.199910 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.202143 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.203973 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.204065 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.204351 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.204430 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:41.204536 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.204580 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.204611 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.204672 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.206885 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.212188 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.212444 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.215078 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.227306 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.227360 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.227395 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.227424 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.227484 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.228030 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.228103 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.228455 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.229189 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.231648 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.232264 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.232337 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.232371 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.232427 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.232551 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.232657 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.232694 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.234527 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.234619 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.236993 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.237070 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.237176 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.239423 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.241261 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.241352 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.241645 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.241725 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:41.241833 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.241871 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.241906 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.241968 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.244175 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.249530 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.249789 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.252415 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.264657 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.264710 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.264744 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.264773 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.264832 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.265378 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.265453 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.265819 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.266937 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.269412 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.270023 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.270099 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.270133 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.270189 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.270316 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.270423 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.270461 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.272301 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.272392 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.274784 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.274862 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.274969 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.277215 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.279047 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.279140 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.279432 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.279512 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:41.279619 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.279658 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.279692 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.279755 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.281966 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.287303 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.287558 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.290188 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.302337 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.302390 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.302424 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.302453 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.302514 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.303060 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.303133 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.303483 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.304205 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.306643 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.307252 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.307327 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.307362 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.307418 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.307546 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.307653 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.307690 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.309533 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.309623 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.311985 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.312061 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.312166 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.314411 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.316236 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.316327 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.316616 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.316695 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:41.316801 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.316838 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.316867 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.316932 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.319144 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.324471 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.324730 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.327372 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.339581 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.339635 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.339669 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.339700 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.339761 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.340311 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.340384 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.340736 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.341461 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.343908 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.344516 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.344598 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.344631 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.344686 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.344813 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.344921 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.344958 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.346802 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.346894 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.349271 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.349347 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.349453 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.351673 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.353501 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.353592 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.353883 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.353964 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:41.354069 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.354107 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.354135 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.354194 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.356405 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.361731 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.361986 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.364630 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.376830 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.376884 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.376919 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.376948 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.377009 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.377555 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.377628 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.377994 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.378672 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.381572 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.382193 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.382269 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.382302 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.382358 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.382483 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.382590 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.382627 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.384450 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.384541 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.386921 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.386998 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.387103 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.389328 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.391158 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.391250 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.391536 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.391616 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:41.391723 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.391761 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.391791 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.391851 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.394090 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.399412 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.399668 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.402326 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.414487 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.414540 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.414574 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.414603 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.414663 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.415205 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.415278 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.415627 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.416299 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.418817 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.419419 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.419492 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.419525 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.419580 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.419704 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.419810 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.419847 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.421788 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.421879 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.424358 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.424434 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.424540 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.426769 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.428591 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.428786 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.429072 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.429151 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:41.429256 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.429294 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.429323 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.429382 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.431584 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.436900 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.437152 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.439802 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.451954 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.452007 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.452041 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.452070 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.452130 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.452672 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.452744 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.453099 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.453779 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.456284 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.456889 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.456963 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.456997 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.457050 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.457175 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.457279 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.457317 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.459155 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.459246 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.461608 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.461692 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.461797 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.464002 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.465826 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.465918 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.466204 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.466283 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:41.466390 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.466427 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.466456 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.466517 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.468694 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.473991 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.474252 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.476872 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.488982 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.489036 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.489069 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.489098 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.489157 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.489712 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.489786 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.490137 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.490821 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.493682 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.494288 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.494364 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.494397 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.494454 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.494578 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.494684 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.494722 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.496538 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.496628 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.498983 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.499059 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.499165 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.501375 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.503217 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.503310 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.503597 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.503682 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:41.506482 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=3/0)>
I0123 17:55:41.555779 140567322951680 decoder_stack.py:275] dstack: embeddings = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.555863 140567322951680 decoder_stack.py:333] dstack: autoregressive generator.
I0123 17:55:41.555916 140567322951680 decoder_stack.py:224] dstack: ---- Layer 0 ----
I0123 17:55:41.556016 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.556054 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.556089 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.556154 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.558412 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.563993 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.564248 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.566775 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.579005 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.579060 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.579094 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.579123 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.579184 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.579732 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.579805 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.580156 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.580828 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.583250 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.583849 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.583924 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.583956 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.584012 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.584137 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.584243 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.584280 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.586155 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.586248 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.588624 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.588700 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.588804 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.590945 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.592749 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.592842 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.593132 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.593211 140567322951680 decoder_stack.py:224] dstack: ---- Layer 1 ----
I0123 17:55:41.593316 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.593353 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.593382 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.593450 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.595660 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.601042 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.601296 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.603866 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.615952 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.616005 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.616039 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.616068 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.616128 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.616675 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.616749 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.617098 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.617782 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.620204 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.620803 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.620877 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.620911 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.620968 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.621092 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.621196 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.621233 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.623120 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.623213 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.625567 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.625652 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.625760 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.627889 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.629705 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.629798 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.630086 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.630165 140567322951680 decoder_stack.py:224] dstack: ---- Layer 2 ----
I0123 17:55:41.630271 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.630309 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.630339 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.630406 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.632618 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.637983 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.638235 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.640771 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.652785 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.652839 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.652873 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.652903 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.652962 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.653507 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.653580 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.653939 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.654602 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.657010 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.657611 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.657693 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.657727 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.657782 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.657907 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.658011 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.658048 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.659912 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.660002 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.662362 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.662440 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.662544 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.664718 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.666531 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.666624 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.666910 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.666989 140567322951680 decoder_stack.py:224] dstack: ---- Layer 3 ----
I0123 17:55:41.667093 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.667130 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.667160 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.667220 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.669422 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.675266 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.675519 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.678095 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.690226 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.690280 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.690314 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.690344 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.690404 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.690954 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.691028 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.691377 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.692039 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.694463 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.695068 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.695142 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.695176 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.695232 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.695358 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.695464 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.695501 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.697388 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.697479 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.699858 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.699937 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.700043 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.702197 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.704027 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.704118 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.704406 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.704486 140567322951680 decoder_stack.py:224] dstack: ---- Layer 4 ----
I0123 17:55:41.704591 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.704628 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.704658 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.704717 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.706957 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.712356 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.712610 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.715193 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.727325 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.727378 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.727412 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.727442 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.727502 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.728048 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.728120 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.728468 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.729135 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.731535 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.732131 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.732204 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.732237 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.732292 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.732414 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.732518 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.732554 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.734448 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.734540 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.736885 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.736961 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.737064 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.739210 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.741010 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.741102 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.741385 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.741465 140567322951680 decoder_stack.py:224] dstack: ---- Layer 5 ----
I0123 17:55:41.741570 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.741608 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.741637 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.741703 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.743878 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.749247 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.749502 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.752069 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.764249 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.764303 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.764336 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.764365 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.764425 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.764971 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.765045 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.765401 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.766083 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.768558 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.769160 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.769234 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.769267 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.769325 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.769449 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.769554 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.769591 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.771495 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.771586 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.773948 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.774026 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.774130 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.776292 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.778121 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.778213 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.778502 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.778580 140567322951680 decoder_stack.py:224] dstack: ---- Layer 6 ----
I0123 17:55:41.778686 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.778723 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.778753 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.778813 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.781009 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.786822 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.787084 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.789653 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.801836 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.801889 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.801923 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.801953 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.802013 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.802557 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.802629 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.802980 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.803647 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.806074 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.806678 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.806752 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.806784 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.806840 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.806962 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.807067 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.807104 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.808982 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.809072 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.811419 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.811496 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.811601 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.813737 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.815554 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.815646 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.815933 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.816012 140567322951680 decoder_stack.py:224] dstack: ---- Layer 7 ----
I0123 17:55:41.816118 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.816154 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.816184 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.816244 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.818426 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.823781 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.824043 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.826610 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.838739 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.838792 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.838825 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.838854 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.838915 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.839463 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.839536 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.839888 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.840556 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.842995 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.843596 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.843669 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.843702 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.843757 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.843879 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.843984 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.844020 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.845911 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.846001 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.848366 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.848441 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.848547 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.850704 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.852518 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.852609 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.852897 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.852975 140567322951680 decoder_stack.py:224] dstack: ---- Layer 8 ----
I0123 17:55:41.853080 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.853117 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.853147 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.853208 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.855387 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.860728 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.860980 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.863561 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.875886 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.875940 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.875974 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.876003 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.876062 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.876612 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.876684 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.877036 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.877715 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.880221 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.880830 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.880903 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.880936 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.880992 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.881116 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.881223 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.881260 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.883166 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.883258 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.885632 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.885716 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.885823 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.887985 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.889814 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.889906 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.890196 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.890275 140567322951680 decoder_stack.py:224] dstack: ---- Layer 9 ----
I0123 17:55:41.890381 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.890419 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.890448 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.890508 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.892731 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.898521 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.898772 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.901344 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.913595 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.913655 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.913692 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.913722 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.913780 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.914324 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.914397 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.914755 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.915430 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.917865 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.918471 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.918545 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.918578 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.918634 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.918761 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.918869 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.918907 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.920782 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.920873 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.923264 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.923341 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.923446 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.925590 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.927432 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.927523 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.927807 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.927884 140567322951680 decoder_stack.py:224] dstack: ---- Layer 10 ----
I0123 17:55:41.927991 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.928028 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.928057 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.928117 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.930297 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.935667 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.935921 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.938462 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.950640 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.950694 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.950728 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.950757 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.950815 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.951362 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.951434 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.951783 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.952453 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.954883 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.955487 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.955559 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.955592 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.955648 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.955769 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.955874 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.955911 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.957782 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.957871 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.960219 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.960295 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.960399 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.962532 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.964334 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.964426 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.964714 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.964792 140567322951680 decoder_stack.py:224] dstack: ---- Layer 11 ----
I0123 17:55:41.964898 140567322951680 transformer_layer.py:154] tlayer: recurrent = False
I0123 17:55:41.964936 140567322951680 transformer_layer.py:155] tlayer: compute_importance = False
I0123 17:55:41.964966 140567322951680 transformer_layer.py:161] tlayer: compute keys,values,queries.
I0123 17:55:41.965025 140567322951680 transformer_base.py:146] kvq: pre_attn xs = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.967225 140567322951680 transformer_base.py:161] kvq: pre_attn dropout.
I0123 17:55:41.972580 140567322951680 transformer_base.py:173] kvq: queries = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.972832 140567322951680 transformer_base.py:194] kvq: normalize keys, queries.
I0123 17:55:41.975375 140567322951680 transformer_layer.py:169] tlayer: using autoregressive decoder.
I0123 17:55:41.987533 140567322951680 transformer_layer.py:299] tlayer: num_windows = 1.
I0123 17:55:41.987593 140567322951680 attention.py:418] Single window, no scan.
I0123 17:55:41.987628 140567322951680 transformer_layer.py:389] tlayer: self-attention.
I0123 17:55:41.987658 140567322951680 attention.py:133] attn: keys = Traced<ShapedArray(bfloat16[32,1024,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.987718 140567322951680 attention.py:134] attn: queries = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.988266 140567322951680 attention.py:139] attn: content attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.988339 140567322951680 attention.py:143] attn: pbias = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.988697 140567322951680 attention.py:150] attn: learned attention scale: Traced<ShapedArray(bfloat16[8])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.989370 140567322951680 attention.py:161] attn: pre-softmax attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.991821 140567322951680 attention.py:177] attn: final attn = Traced<ShapedArray(bfloat16[32,8,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.992428 140567322951680 attention.py:182] attn: y = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.992502 140567322951680 transformer_layer.py:468] tlayer: End windows.
I0123 17:55:41.992536 140567322951680 transformer_layer.py:472] tlayer: final FFN.
I0123 17:55:41.992592 140567322951680 transformer_base.py:399] tbase: attn_ys = Traced<ShapedArray(bfloat16[32,1,8,128])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.992714 140567322951680 transformer_base.py:410] tbase: post-attention MLP.
I0123 17:55:41.992820 140567322951680 nn_components.py:325] mlp: activation = None
I0123 17:55:41.992856 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:41.994747 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.994837 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:41.997175 140567322951680 transformer_base.py:431] tbase: pre-FFN layernorm = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:41.997251 140567322951680 transformer_base.py:443] tbase: final FFN
I0123 17:55:41.997355 140567322951680 nn_components.py:320] mlp: hidden 4096, relu
I0123 17:55:41.999497 140567322951680 nn_components.py:329] mlp: final activation = None
I0123 17:55:42.001306 140567322951680 nn_components.py:332] mlp: final = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:42.001397 140567322951680 nn_components.py:261] mlp: residual
I0123 17:55:42.001690 140567322951680 transformer_base.py:450] tbase: ys = Traced<ShapedArray(bfloat16[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:42.001772 140567322951680 decoder_stack.py:344] dstack: Final layernorm.
I0123 17:55:42.004536 140567322951680 decoder_stack.py:365] dstack: logits = Traced<ShapedArray(float32[32,1,1024])>with<DynamicJaxprTrace(level=2/0)>
I0123 17:55:55.825471 140567322951680 alphageometry.py:566] LM output (score=-1.632885): "l : D a b a l 16 D a b b l 17 ;"
I0123 17:55:55.825809 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a b, on_circle l b a"

I0123 17:55:55.825874 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a ? perp a c c k"
I0123 17:55:55.826034 140567322951680 graph.py:498] 
I0123 17:55:55.826095 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a ? perp a c c k
I0123 17:55:56.760447 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9053113460540771
I0123 17:56:00.338922 140567322951680 ddar.py:60] Depth 2/1000 time = 3.578308343887329
I0123 17:56:04.113318 140567322951680 ddar.py:60] Depth 3/1000 time = 3.7742156982421875
I0123 17:56:08.065456 140567322951680 ddar.py:60] Depth 4/1000 time = 3.951953649520874
I0123 17:56:11.767484 140567322951680 ddar.py:60] Depth 5/1000 time = 3.7014927864074707
I0123 17:56:15.707868 140567322951680 ddar.py:60] Depth 6/1000 time = 3.9387834072113037
I0123 17:56:19.777796 140567322951680 ddar.py:60] Depth 7/1000 time = 4.045592784881592
I0123 17:56:19.778000 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:56:19.778092 140567322951680 alphageometry.py:566] LM output (score=-1.912798): "l : C a b l 16 D a l b l 17 ;"
I0123 17:56:19.778132 140567322951680 alphageometry.py:567] Translation: "l = on_line l a b, on_bline l b a"

I0123 17:56:19.778171 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a ? perp a c c k"
I0123 17:56:19.778319 140567322951680 graph.py:498] 
I0123 17:56:19.778375 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a ? perp a c c k
I0123 17:56:20.613891 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8079495429992676
I0123 17:56:26.810547 140567322951680 ddar.py:60] Depth 2/1000 time = 6.196493625640869
I0123 17:56:34.965600 140567322951680 ddar.py:60] Depth 3/1000 time = 8.154852151870728
I0123 17:56:42.891934 140567322951680 ddar.py:60] Depth 4/1000 time = 7.926127672195435
I0123 17:56:50.926035 140567322951680 ddar.py:60] Depth 5/1000 time = 8.033880949020386
I0123 17:56:59.294603 140567322951680 ddar.py:60] Depth 6/1000 time = 8.367820739746094
I0123 17:56:59.332756 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:56:59.332895 140567322951680 alphageometry.py:566] LM output (score=-2.135823): "l : P a b c l 16 ;"
I0123 17:56:59.332936 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c a b"

I0123 17:56:59.332991 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b ? perp a c c k"
I0123 17:56:59.333156 140567322951680 graph.py:498] 
I0123 17:56:59.333215 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b ? perp a c c k
I0123 17:56:59.944518 140567322951680 ddar.py:60] Depth 1/1000 time = 0.5824675559997559
I0123 17:57:03.195292 140567322951680 ddar.py:60] Depth 2/1000 time = 3.250627279281616
I0123 17:57:07.403111 140567322951680 ddar.py:60] Depth 3/1000 time = 4.207646369934082
I0123 17:57:11.223700 140567322951680 ddar.py:60] Depth 4/1000 time = 3.8203916549682617
I0123 17:57:15.024884 140567322951680 ddar.py:60] Depth 5/1000 time = 3.8006374835968018
I0123 17:57:19.134235 140567322951680 ddar.py:60] Depth 6/1000 time = 4.08539891242981
I0123 17:57:19.134678 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:57:19.134818 140567322951680 alphageometry.py:566] LM output (score=-2.163912): "l : D b c b l 16 D b c c l 17 ;"
I0123 17:57:19.134859 140567322951680 alphageometry.py:567] Translation: "l = on_circle l b c, on_circle l c b"

I0123 17:57:19.134918 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l b c, on_circle l c b ? perp a c c k"
I0123 17:57:19.135107 140567322951680 graph.py:498] 
I0123 17:57:19.135167 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l b c, on_circle l c b ? perp a c c k
I0123 17:57:19.835554 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6699142456054688
I0123 17:57:25.354139 140567322951680 ddar.py:60] Depth 2/1000 time = 5.518450736999512
I0123 17:57:30.659949 140567322951680 ddar.py:60] Depth 3/1000 time = 5.305627346038818
I0123 17:57:36.374906 140567322951680 ddar.py:60] Depth 4/1000 time = 5.7147603034973145
I0123 17:57:42.126548 140567322951680 ddar.py:60] Depth 5/1000 time = 5.751072645187378
I0123 17:57:47.852231 140567322951680 ddar.py:60] Depth 6/1000 time = 5.724172353744507
I0123 17:57:53.775881 140567322951680 ddar.py:60] Depth 7/1000 time = 5.896474838256836
I0123 17:57:53.776184 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:57:53.776289 140567322951680 alphageometry.py:566] LM output (score=-2.669654): "l : C e h l 16 D e h e l 17 ;"
I0123 17:57:53.776329 140567322951680 alphageometry.py:567] Translation: "l = on_line l e h, on_circle l e h"

I0123 17:57:53.776366 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e h, on_circle l e h ? perp a c c k"
I0123 17:57:53.776520 140567322951680 graph.py:498] 
I0123 17:57:53.776581 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e h, on_circle l e h ? perp a c c k
I0123 17:57:54.680784 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8766064643859863
I0123 17:58:01.413991 140567322951680 ddar.py:60] Depth 2/1000 time = 6.733080863952637
I0123 17:58:08.561116 140567322951680 ddar.py:60] Depth 3/1000 time = 7.146935939788818
I0123 17:58:15.935431 140567322951680 ddar.py:60] Depth 4/1000 time = 7.374110460281372
I0123 17:58:23.229330 140567322951680 ddar.py:60] Depth 5/1000 time = 7.293323993682861
I0123 17:58:30.317291 140567322951680 ddar.py:60] Depth 6/1000 time = 7.06236720085144
I0123 17:58:37.680243 140567322951680 ddar.py:60] Depth 7/1000 time = 7.3514533042907715
I0123 17:58:37.680444 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:58:37.680534 140567322951680 alphageometry.py:566] LM output (score=-2.697631): "l : D c j f l 16 P c j f l 17 ;"
I0123 17:58:37.680571 140567322951680 alphageometry.py:567] Translation: "l = eqdistance l f c j, on_pline l f c j"

I0123 17:58:37.680608 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l f c j, on_pline l f c j ? perp a c c k"
I0123 17:58:37.680776 140567322951680 graph.py:498] 
I0123 17:58:37.680838 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l f c j, on_pline l f c j ? perp a c c k
I0123 17:58:38.396418 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6818759441375732
I0123 17:58:42.267237 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8707027435302734
I0123 17:58:46.808473 140567322951680 ddar.py:60] Depth 3/1000 time = 4.541051149368286
I0123 17:58:51.072778 140567322951680 ddar.py:60] Depth 4/1000 time = 4.264085531234741
I0123 17:58:55.314115 140567322951680 ddar.py:60] Depth 5/1000 time = 4.240759611129761
I0123 17:58:59.871999 140567322951680 ddar.py:60] Depth 6/1000 time = 4.530896902084351
I0123 17:58:59.872341 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:58:59.872457 140567322951680 alphageometry.py:566] LM output (score=-2.717309): "l : P a b c l 16 T a b a l 17 ;"
I0123 17:58:59.872496 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c a b, on_tline l a a b"

I0123 17:58:59.872534 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_tline l a a b ? perp a c c k"
I0123 17:58:59.872693 140567322951680 graph.py:498] 
I0123 17:58:59.872756 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_tline l a a b ? perp a c c k
I0123 17:59:00.589203 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6803946495056152
I0123 17:59:05.914471 140567322951680 ddar.py:60] Depth 2/1000 time = 5.325095176696777
I0123 17:59:11.807289 140567322951680 ddar.py:60] Depth 3/1000 time = 5.892617702484131
I0123 17:59:18.490642 140567322951680 ddar.py:60] Depth 4/1000 time = 6.683155536651611
I0123 17:59:25.001155 140567322951680 ddar.py:60] Depth 5/1000 time = 6.5103349685668945
I0123 17:59:31.543920 140567322951680 ddar.py:60] Depth 6/1000 time = 6.5419816970825195
I0123 17:59:38.361631 140567322951680 ddar.py:60] Depth 7/1000 time = 6.781095504760742
I0123 17:59:45.193159 140567322951680 ddar.py:60] Depth 8/1000 time = 6.831335544586182
I0123 17:59:51.517326 140567322951680 ddar.py:60] Depth 9/1000 time = 6.313077926635742
I0123 17:59:51.517796 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 17:59:51.517919 140567322951680 alphageometry.py:566] LM output (score=-2.720055): "l : P a e c l 16 P a l c e 17 ;"
I0123 17:59:51.517955 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c a e, on_pline l a c e"

I0123 17:59:51.518009 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a e, on_pline l a c e ? perp a c c k"
I0123 17:59:51.518177 140567322951680 graph.py:498] 
I0123 17:59:51.518236 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a e, on_pline l a c e ? perp a c c k
I0123 17:59:52.528216 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9732792377471924
I0123 17:59:57.665736 140567322951680 ddar.py:60] Depth 2/1000 time = 5.137346982955933
I0123 18:00:02.742080 140567322951680 ddar.py:60] Depth 3/1000 time = 5.0761637687683105
I0123 18:00:08.882606 140567322951680 ddar.py:60] Depth 4/1000 time = 6.140354156494141
I0123 18:00:14.302251 140567322951680 ddar.py:60] Depth 5/1000 time = 5.4194324016571045
I0123 18:00:20.206780 140567322951680 ddar.py:60] Depth 6/1000 time = 5.903863191604614
I0123 18:00:26.208781 140567322951680 ddar.py:60] Depth 7/1000 time = 5.970021963119507
I0123 18:00:26.213308 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:00:26.213409 140567322951680 alphageometry.py:566] LM output (score=-2.730768): "l : D a c a l 16 D a c c l 17 ;"
I0123 18:00:26.213446 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a c, on_circle l c a"

I0123 18:00:26.213485 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a c, on_circle l c a ? perp a c c k"
I0123 18:00:26.213648 140567322951680 graph.py:498] 
I0123 18:00:26.213710 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a c, on_circle l c a ? perp a c c k
I0123 18:00:26.924309 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6799478530883789
I0123 18:00:31.753677 140567322951680 ddar.py:60] Depth 2/1000 time = 4.829240083694458
I0123 18:00:37.322509 140567322951680 ddar.py:60] Depth 3/1000 time = 5.568637847900391
I0123 18:00:42.624286 140567322951680 ddar.py:60] Depth 4/1000 time = 5.301589727401733
I0123 18:00:47.911114 140567322951680 ddar.py:60] Depth 5/1000 time = 5.286256790161133
I0123 18:00:53.529037 140567322951680 ddar.py:60] Depth 6/1000 time = 5.6167144775390625
I0123 18:00:58.723678 140567322951680 ddar.py:60] Depth 7/1000 time = 5.167928218841553
I0123 18:00:58.723898 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:00:58.724000 140567322951680 alphageometry.py:566] LM output (score=-2.793086): "l : T a c c l 16 ;"
I0123 18:00:58.724038 140567322951680 alphageometry.py:567] Translation: "l = on_tline l c a c"

I0123 18:00:58.724075 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_tline l c a c ? perp a c c k"
I0123 18:00:58.724228 140567322951680 graph.py:498] 
I0123 18:00:58.724289 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_tline l c a c ? perp a c c k
I0123 18:00:59.565567 140567322951680 ddar.py:60] Depth 1/1000 time = 0.812746524810791
I0123 18:01:03.085769 140567322951680 ddar.py:60] Depth 2/1000 time = 3.5200226306915283
I0123 18:01:07.290181 140567322951680 ddar.py:60] Depth 3/1000 time = 4.204224586486816
I0123 18:01:11.265742 140567322951680 ddar.py:60] Depth 4/1000 time = 3.975358247756958
I0123 18:01:15.261033 140567322951680 ddar.py:60] Depth 5/1000 time = 3.994720458984375
I0123 18:01:19.383318 140567322951680 ddar.py:60] Depth 6/1000 time = 4.100567579269409
I0123 18:01:19.383525 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:01:19.383634 140567322951680 alphageometry.py:566] LM output (score=-2.809658): "l : D b c g l 16 D b g c l 17 ;"
I0123 18:01:19.383673 140567322951680 alphageometry.py:567] Translation: "l = eqdistance l g b c, eqdistance l c b g"

I0123 18:01:19.383713 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l g b c, eqdistance l c b g ? perp a c c k"
I0123 18:01:19.383873 140567322951680 graph.py:498] 
I0123 18:01:19.383936 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l g b c, eqdistance l c b g ? perp a c c k
I0123 18:01:20.068015 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6498019695281982
I0123 18:01:24.178171 140567322951680 ddar.py:60] Depth 2/1000 time = 4.110034465789795
I0123 18:01:28.897926 140567322951680 ddar.py:60] Depth 3/1000 time = 4.719574928283691
I0123 18:01:33.663805 140567322951680 ddar.py:60] Depth 4/1000 time = 4.76568078994751
I0123 18:01:38.463800 140567322951680 ddar.py:60] Depth 5/1000 time = 4.799363136291504
I0123 18:01:43.711114 140567322951680 ddar.py:60] Depth 6/1000 time = 5.221821546554565
I0123 18:01:43.711342 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:01:43.711457 140567322951680 alphageometry.py:566] LM output (score=-2.846479): "l : P a b c l 16 P a c b l 17 ;"
I0123 18:01:43.711498 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c a b, on_pline l b a c"

I0123 18:01:43.711539 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_pline l b a c ? perp a c c k"
I0123 18:01:43.711701 140567322951680 graph.py:498] 
I0123 18:01:43.711767 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_pline l b a c ? perp a c c k
I0123 18:01:44.385524 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6380796432495117
I0123 18:01:48.568957 140567322951680 ddar.py:60] Depth 2/1000 time = 4.183312177658081
I0123 18:01:53.539397 140567322951680 ddar.py:60] Depth 3/1000 time = 4.970262050628662
I0123 18:01:58.640695 140567322951680 ddar.py:60] Depth 4/1000 time = 5.101044654846191
I0123 18:02:03.499800 140567322951680 ddar.py:60] Depth 5/1000 time = 4.85830545425415
I0123 18:02:08.440782 140567322951680 ddar.py:60] Depth 6/1000 time = 4.911218881607056
I0123 18:02:08.441066 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:02:08.441167 140567322951680 alphageometry.py:566] LM output (score=-2.874117): "l : C e f l 16 D e l f l 17 ;"
I0123 18:02:08.441207 140567322951680 alphageometry.py:567] Translation: "l = on_line l e f, on_bline l f e"

I0123 18:02:08.441244 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e f, on_bline l f e ? perp a c c k"
I0123 18:02:08.441399 140567322951680 graph.py:498] 
I0123 18:02:08.441460 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e f, on_bline l f e ? perp a c c k
I0123 18:02:09.291806 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8226370811462402
I0123 18:02:14.806479 140567322951680 ddar.py:60] Depth 2/1000 time = 5.514552116394043
I0123 18:02:20.807957 140567322951680 ddar.py:60] Depth 3/1000 time = 6.001249313354492
I0123 18:02:26.603838 140567322951680 ddar.py:60] Depth 4/1000 time = 5.795587062835693
I0123 18:02:32.379571 140567322951680 ddar.py:60] Depth 5/1000 time = 5.775132179260254
I0123 18:02:38.216080 140567322951680 ddar.py:60] Depth 6/1000 time = 5.80701470375061
I0123 18:02:38.216286 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:02:38.216392 140567322951680 alphageometry.py:566] LM output (score=-2.893351): "l : D a e a l 16 D e f f l 17 ;"
I0123 18:02:38.216432 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a e, on_circle l f e"

I0123 18:02:38.216471 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l f e ? perp a c c k"
I0123 18:02:38.216632 140567322951680 graph.py:498] 
I0123 18:02:38.216694 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l f e ? perp a c c k
I0123 18:02:38.946784 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6965644359588623
I0123 18:02:43.517250 140567322951680 ddar.py:60] Depth 2/1000 time = 4.570278882980347
I0123 18:02:49.760977 140567322951680 ddar.py:60] Depth 3/1000 time = 6.243517637252808
I0123 18:02:55.626662 140567322951680 ddar.py:60] Depth 4/1000 time = 5.865512847900391
I0123 18:03:01.686811 140567322951680 ddar.py:60] Depth 5/1000 time = 6.059957027435303
I0123 18:03:07.871131 140567322951680 ddar.py:60] Depth 6/1000 time = 6.183723211288452
I0123 18:03:13.837475 140567322951680 ddar.py:60] Depth 7/1000 time = 5.915274620056152
I0123 18:03:13.837701 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:03:13.837803 140567322951680 alphageometry.py:566] LM output (score=-2.921150): "l : D a e a l 16 D b e b l 17 ;"
I0123 18:03:13.837841 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a e, on_circle l b e"

I0123 18:03:13.837880 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l b e ? perp a c c k"
I0123 18:03:13.838038 140567322951680 graph.py:498] 
I0123 18:03:13.838099 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l b e ? perp a c c k
I0123 18:03:14.589707 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7204594612121582
I0123 18:03:19.161901 140567322951680 ddar.py:60] Depth 2/1000 time = 4.572070598602295
I0123 18:03:25.177260 140567322951680 ddar.py:60] Depth 3/1000 time = 6.0151143074035645
I0123 18:03:31.439404 140567322951680 ddar.py:60] Depth 4/1000 time = 6.261825799942017
I0123 18:03:37.702866 140567322951680 ddar.py:60] Depth 5/1000 time = 6.263269662857056
I0123 18:03:43.657045 140567322951680 ddar.py:60] Depth 6/1000 time = 5.953519105911255
I0123 18:03:49.731098 140567322951680 ddar.py:60] Depth 7/1000 time = 6.026995420455933
I0123 18:03:49.731495 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:03:49.731606 140567322951680 alphageometry.py:566] LM output (score=-2.961486): "l : D b e e l 16 T b e e l 17 ;"
I0123 18:03:49.731644 140567322951680 alphageometry.py:567] Translation: "l = on_circle l e b, on_tline l e b e"

I0123 18:03:49.731686 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l e b, on_tline l e b e ? perp a c c k"
I0123 18:03:49.731842 140567322951680 graph.py:498] 
I0123 18:03:49.731903 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l e b, on_tline l e b e ? perp a c c k
I0123 18:03:52.509174 140567322951680 ddar.py:60] Depth 1/1000 time = 2.750823974609375
I0123 18:03:58.341549 140567322951680 ddar.py:60] Depth 2/1000 time = 5.832202672958374
I0123 18:04:04.836698 140567322951680 ddar.py:60] Depth 3/1000 time = 6.494954347610474
I0123 18:04:10.656913 140567322951680 ddar.py:60] Depth 4/1000 time = 5.81999135017395
I0123 18:04:17.011809 140567322951680 ddar.py:60] Depth 5/1000 time = 6.3542187213897705
I0123 18:04:23.396320 140567322951680 ddar.py:60] Depth 6/1000 time = 6.383457899093628
I0123 18:04:29.625706 140567322951680 ddar.py:60] Depth 7/1000 time = 6.198427200317383
I0123 18:04:29.626045 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:04:29.626168 140567322951680 alphageometry.py:566] LM output (score=-3.001145): "l : C e g l 16 D e l g l 17 ;"
I0123 18:04:29.626205 140567322951680 alphageometry.py:567] Translation: "l = on_line l e g, on_bline l g e"

I0123 18:04:29.626255 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e g, on_bline l g e ? perp a c c k"
I0123 18:04:29.626424 140567322951680 graph.py:498] 
I0123 18:04:29.626484 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l e g, on_bline l g e ? perp a c c k
I0123 18:04:30.314700 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6602427959442139
I0123 18:04:34.183177 140567322951680 ddar.py:60] Depth 2/1000 time = 3.868326187133789
I0123 18:04:37.985501 140567322951680 ddar.py:60] Depth 3/1000 time = 3.802152156829834
I0123 18:04:42.381903 140567322951680 ddar.py:60] Depth 4/1000 time = 4.396198272705078
I0123 18:04:46.183547 140567322951680 ddar.py:60] Depth 5/1000 time = 3.801021099090576
I0123 18:04:50.432651 140567322951680 ddar.py:60] Depth 6/1000 time = 4.224352598190308
I0123 18:04:50.432980 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:04:50.433103 140567322951680 alphageometry.py:566] LM output (score=-3.006162): "l : D b c c l 16 D b g g l 17 ;"
I0123 18:04:50.433143 140567322951680 alphageometry.py:567] Translation: "l = on_circle l c b, on_circle l g b"

I0123 18:04:50.433196 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c b, on_circle l g b ? perp a c c k"
I0123 18:04:50.433380 140567322951680 graph.py:498] 
I0123 18:04:50.433441 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c b, on_circle l g b ? perp a c c k
I0123 18:04:51.134144 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6678261756896973
I0123 18:04:54.731106 140567322951680 ddar.py:60] Depth 2/1000 time = 3.596825122833252
I0123 18:04:59.462959 140567322951680 ddar.py:60] Depth 3/1000 time = 4.731672525405884
I0123 18:05:03.559104 140567322951680 ddar.py:60] Depth 4/1000 time = 4.095941781997681
I0123 18:05:07.993914 140567322951680 ddar.py:60] Depth 5/1000 time = 4.434251308441162
I0123 18:05:12.273948 140567322951680 ddar.py:60] Depth 6/1000 time = 4.251145124435425
I0123 18:05:12.274289 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:05:12.274404 140567322951680 alphageometry.py:566] LM output (score=-3.011039): "l : D b c g l 16 D b l c g 17 ;"
I0123 18:05:12.274442 140567322951680 alphageometry.py:567] Translation: "l = eqdistance l g b c, eqdistance l b c g"

I0123 18:05:12.274492 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l g b c, eqdistance l b c g ? perp a c c k"
I0123 18:05:12.274662 140567322951680 graph.py:498] 
I0123 18:05:12.274725 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l g b c, eqdistance l b c g ? perp a c c k
I0123 18:05:12.953466 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6461174488067627
I0123 18:05:17.461887 140567322951680 ddar.py:60] Depth 2/1000 time = 4.508293151855469
I0123 18:05:21.712994 140567322951680 ddar.py:60] Depth 3/1000 time = 4.250932931900024
I0123 18:05:26.661216 140567322951680 ddar.py:60] Depth 4/1000 time = 4.9480414390563965
I0123 18:05:30.939795 140567322951680 ddar.py:60] Depth 5/1000 time = 4.278050899505615
I0123 18:05:35.649232 140567322951680 ddar.py:60] Depth 6/1000 time = 4.682104110717773
I0123 18:05:35.649472 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:05:35.649574 140567322951680 alphageometry.py:566] LM output (score=-3.028040): "l : D a e a l 16 D e g g l 17 ;"
I0123 18:05:35.649612 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a e, on_circle l g e"

I0123 18:05:35.649659 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l g e ? perp a c c k"
I0123 18:05:35.649819 140567322951680 graph.py:498] 
I0123 18:05:35.649881 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l g e ? perp a c c k
I0123 18:05:36.394387 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7114372253417969
I0123 18:05:40.812684 140567322951680 ddar.py:60] Depth 2/1000 time = 4.418170928955078
I0123 18:05:46.905154 140567322951680 ddar.py:60] Depth 3/1000 time = 6.092306852340698
I0123 18:05:52.915644 140567322951680 ddar.py:60] Depth 4/1000 time = 6.010303497314453
I0123 18:05:58.989329 140567322951680 ddar.py:60] Depth 5/1000 time = 6.073488473892212
I0123 18:06:04.621079 140567322951680 ddar.py:60] Depth 6/1000 time = 5.631549835205078
I0123 18:06:10.957803 140567322951680 ddar.py:60] Depth 7/1000 time = 6.336543083190918
I0123 18:06:17.045023 140567322951680 ddar.py:60] Depth 8/1000 time = 6.086577653884888
I0123 18:06:22.859913 140567322951680 ddar.py:60] Depth 9/1000 time = 5.766979932785034
I0123 18:06:29.264546 140567322951680 ddar.py:60] Depth 10/1000 time = 6.404436826705933
I0123 18:06:29.267040 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:06:29.267153 140567322951680 alphageometry.py:566] LM output (score=-3.030393): "l : D c e c l 16 D e g g l 17 ;"
I0123 18:06:29.267194 140567322951680 alphageometry.py:567] Translation: "l = on_circle l c e, on_circle l g e"

I0123 18:06:29.267235 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c e, on_circle l g e ? perp a c c k"
I0123 18:06:29.267394 140567322951680 graph.py:498] 
I0123 18:06:29.267456 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c e, on_circle l g e ? perp a c c k
I0123 18:06:29.963812 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6652750968933105
I0123 18:06:33.959873 140567322951680 ddar.py:60] Depth 2/1000 time = 3.9959399700164795
I0123 18:06:38.166517 140567322951680 ddar.py:60] Depth 3/1000 time = 4.206406831741333
I0123 18:06:42.789927 140567322951680 ddar.py:60] Depth 4/1000 time = 4.623074531555176
I0123 18:06:47.009525 140567322951680 ddar.py:60] Depth 5/1000 time = 4.219055414199829
I0123 18:06:51.711512 140567322951680 ddar.py:60] Depth 6/1000 time = 4.673970937728882
I0123 18:06:51.711726 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:06:51.711829 140567322951680 alphageometry.py:566] LM output (score=-3.054105): "l : P b g c l 16 P b l c g 17 ;"
I0123 18:06:51.711869 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c b g, on_pline l b c g"

I0123 18:06:51.711909 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c b g, on_pline l b c g ? perp a c c k"
I0123 18:06:51.712071 140567322951680 graph.py:498] 
I0123 18:06:51.712137 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c b g, on_pline l b c g ? perp a c c k
I0123 18:06:52.446114 140567322951680 ddar.py:60] Depth 1/1000 time = 0.69529128074646
I0123 18:06:56.585045 140567322951680 ddar.py:60] Depth 2/1000 time = 4.138807058334351
I0123 18:07:01.506976 140567322951680 ddar.py:60] Depth 3/1000 time = 4.921726226806641
I0123 18:07:06.801543 140567322951680 ddar.py:60] Depth 4/1000 time = 5.294335603713989
I0123 18:07:11.384460 140567322951680 ddar.py:60] Depth 5/1000 time = 4.582192420959473
I0123 18:07:16.303552 140567322951680 ddar.py:60] Depth 6/1000 time = 4.890864849090576
I0123 18:07:16.303768 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:07:16.303874 140567322951680 alphageometry.py:566] LM output (score=-3.136540): "l : P a b c l 16 P a l b c 17 ;"
I0123 18:07:16.303914 140567322951680 alphageometry.py:567] Translation: "l = on_pline l c a b, on_pline l a b c"

I0123 18:07:16.303953 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_pline l a b c ? perp a c c k"
I0123 18:07:16.304115 140567322951680 graph.py:498] 
I0123 18:07:16.304178 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b, on_pline l a b c ? perp a c c k
I0123 18:07:17.322443 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9825260639190674
I0123 18:07:22.027525 140567322951680 ddar.py:60] Depth 2/1000 time = 4.704880475997925
I0123 18:07:27.165259 140567322951680 ddar.py:60] Depth 3/1000 time = 5.137507677078247
I0123 18:07:32.746510 140567322951680 ddar.py:60] Depth 4/1000 time = 5.5810627937316895
I0123 18:07:37.621563 140567322951680 ddar.py:60] Depth 5/1000 time = 4.874324798583984
I0123 18:07:42.944221 140567322951680 ddar.py:60] Depth 6/1000 time = 5.2903337478637695
I0123 18:07:42.944591 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:07:42.944717 140567322951680 alphageometry.py:566] LM output (score=-3.137394): "l : P b f d l 16 ;"
I0123 18:07:42.944755 140567322951680 alphageometry.py:567] Translation: "l = on_pline l d b f"

I0123 18:07:42.944806 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l d b f ? perp a c c k"
I0123 18:07:42.944973 140567322951680 graph.py:498] 
I0123 18:07:42.945033 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l d b f ? perp a c c k
I0123 18:07:43.558680 140567322951680 ddar.py:60] Depth 1/1000 time = 0.5839028358459473
I0123 18:07:47.492175 140567322951680 ddar.py:60] Depth 2/1000 time = 3.933353900909424
I0123 18:07:52.372087 140567322951680 ddar.py:60] Depth 3/1000 time = 4.879727125167847
I0123 18:07:56.550011 140567322951680 ddar.py:60] Depth 4/1000 time = 4.177725315093994
I0123 18:08:01.097571 140567322951680 ddar.py:60] Depth 5/1000 time = 4.5470006465911865
I0123 18:08:05.762573 140567322951680 ddar.py:60] Depth 6/1000 time = 4.6412200927734375
I0123 18:08:05.762815 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:08:05.762919 140567322951680 alphageometry.py:566] LM output (score=-3.138455): "l : D b c c l 16 D b d d l 17 ;"
I0123 18:08:05.762959 140567322951680 alphageometry.py:567] Translation: "l = on_circle l c b, on_circle l d b"

I0123 18:08:05.763002 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c b, on_circle l d b ? perp a c c k"
I0123 18:08:05.763177 140567322951680 graph.py:498] 
I0123 18:08:05.763240 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l c b, on_circle l d b ? perp a c c k
I0123 18:08:06.462069 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6655778884887695
I0123 18:08:10.852374 140567322951680 ddar.py:60] Depth 2/1000 time = 4.390177488327026
I0123 18:08:15.920564 140567322951680 ddar.py:60] Depth 3/1000 time = 5.0680131912231445
I0123 18:08:21.289454 140567322951680 ddar.py:60] Depth 4/1000 time = 5.368713855743408
I0123 18:08:26.321351 140567322951680 ddar.py:60] Depth 5/1000 time = 5.03167200088501
I0123 18:08:31.728456 140567322951680 ddar.py:60] Depth 6/1000 time = 5.406423330307007
I0123 18:08:36.744988 140567322951680 ddar.py:60] Depth 7/1000 time = 4.99148416519165
I0123 18:08:42.145096 140567322951680 ddar.py:60] Depth 8/1000 time = 5.385410308837891
I0123 18:08:42.146585 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:08:42.146699 140567322951680 alphageometry.py:566] LM output (score=-3.151238): "l : D a e a l 16 D c e c l 17 ;"
I0123 18:08:42.146739 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a e, on_circle l c e"

I0123 18:08:42.146777 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l c e ? perp a c c k"
I0123 18:08:42.146931 140567322951680 graph.py:498] 
I0123 18:08:42.146994 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a e, on_circle l c e ? perp a c c k
I0123 18:08:42.882272 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7045896053314209
I0123 18:08:46.991848 140567322951680 ddar.py:60] Depth 2/1000 time = 4.109395980834961
I0123 18:08:52.139886 140567322951680 ddar.py:60] Depth 3/1000 time = 5.147736549377441
I0123 18:08:57.092844 140567322951680 ddar.py:60] Depth 4/1000 time = 4.952761888504028
I0123 18:09:02.438566 140567322951680 ddar.py:60] Depth 5/1000 time = 5.34553337097168
I0123 18:09:07.852004 140567322951680 ddar.py:60] Depth 6/1000 time = 5.412808895111084
I0123 18:09:12.895605 140567322951680 ddar.py:60] Depth 7/1000 time = 5.017028331756592
I0123 18:09:18.224004 140567322951680 ddar.py:60] Depth 8/1000 time = 5.31682276725769
I0123 18:09:23.570548 140567322951680 ddar.py:60] Depth 9/1000 time = 5.344300746917725
I0123 18:09:29.002954 140567322951680 ddar.py:60] Depth 10/1000 time = 5.430166959762573
I0123 18:09:29.003289 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:09:29.003415 140567322951680 alphageometry.py:566] LM output (score=-3.174311): "l : P b e f l 16 P b f e l 17 ;"
I0123 18:09:29.003454 140567322951680 alphageometry.py:567] Translation: "l = on_pline l f b e, on_pline l e b f"

I0123 18:09:29.003505 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l f b e, on_pline l e b f ? perp a c c k"
I0123 18:09:29.003677 140567322951680 graph.py:498] 
I0123 18:09:29.003738 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l f b e, on_pline l e b f ? perp a c c k
I0123 18:09:29.742167 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7023956775665283
I0123 18:09:34.613630 140567322951680 ddar.py:60] Depth 2/1000 time = 4.8713297843933105
I0123 18:09:41.108350 140567322951680 ddar.py:60] Depth 3/1000 time = 6.494519233703613
I0123 18:09:47.308953 140567322951680 ddar.py:60] Depth 4/1000 time = 6.2004075050354
I0123 18:09:53.604563 140567322951680 ddar.py:60] Depth 5/1000 time = 6.294811487197876
I0123 18:09:59.443583 140567322951680 ddar.py:60] Depth 6/1000 time = 5.806138277053833
I0123 18:09:59.443799 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:09:59.443907 140567322951680 alphageometry.py:566] LM output (score=-3.194063): "l : D a b a l 16 D b c c l 17 ;"
I0123 18:09:59.443945 140567322951680 alphageometry.py:567] Translation: "l = on_circle l a b, on_circle l c b"

I0123 18:09:59.443982 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l c b ? perp a c c k"
I0123 18:09:59.444138 140567322951680 graph.py:498] 
I0123 18:09:59.444200 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l c b ? perp a c c k
I0123 18:10:00.167352 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6874361038208008
I0123 18:10:04.764083 140567322951680 ddar.py:60] Depth 2/1000 time = 4.596605062484741
I0123 18:10:10.060825 140567322951680 ddar.py:60] Depth 3/1000 time = 5.296553373336792
I0123 18:10:15.490506 140567322951680 ddar.py:60] Depth 4/1000 time = 5.429467678070068
I0123 18:10:20.493833 140567322951680 ddar.py:60] Depth 5/1000 time = 5.003103733062744
I0123 18:10:25.907372 140567322951680 ddar.py:60] Depth 6/1000 time = 5.412952184677124
I0123 18:10:30.995584 140567322951680 ddar.py:60] Depth 7/1000 time = 5.051443815231323
I0123 18:10:30.996200 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:10:30.996310 140567322951680 alphageometry.py:566] LM output (score=-3.200553): "l : P e f k l 16 ;"
I0123 18:10:30.996351 140567322951680 alphageometry.py:567] Translation: "l = on_pline l k e f"

I0123 18:10:30.996389 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l k e f ? perp a c c k"
I0123 18:10:30.996545 140567322951680 graph.py:498] 
I0123 18:10:30.996607 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l k e f ? perp a c c k
I0123 18:10:31.616045 140567322951680 ddar.py:60] Depth 1/1000 time = 0.5909955501556396
I0123 18:10:36.768846 140567322951680 ddar.py:60] Depth 2/1000 time = 5.152660369873047
I0123 18:10:42.682986 140567322951680 ddar.py:60] Depth 3/1000 time = 5.913956642150879
I0123 18:10:48.585832 140567322951680 ddar.py:60] Depth 4/1000 time = 5.9026453495025635
I0123 18:10:54.140478 140567322951680 ddar.py:60] Depth 5/1000 time = 5.554035663604736
I0123 18:11:00.221106 140567322951680 ddar.py:60] Depth 6/1000 time = 6.05824089050293
I0123 18:11:00.221340 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:11:00.221443 140567322951680 alphageometry.py:566] LM output (score=-3.241525): "l : D b e b l 16 D e g g l 17 ;"
I0123 18:11:00.221481 140567322951680 alphageometry.py:567] Translation: "l = on_circle l b e, on_circle l g e"

I0123 18:11:00.221519 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l b e, on_circle l g e ? perp a c c k"
I0123 18:11:00.221685 140567322951680 graph.py:498] 
I0123 18:11:00.221753 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l b e, on_circle l g e ? perp a c c k
I0123 18:11:00.995674 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7432622909545898
I0123 18:11:05.589214 140567322951680 ddar.py:60] Depth 2/1000 time = 4.593416213989258
I0123 18:11:11.787764 140567322951680 ddar.py:60] Depth 3/1000 time = 6.1983747482299805
I0123 18:11:18.025339 140567322951680 ddar.py:60] Depth 4/1000 time = 6.237315654754639
I0123 18:11:24.293445 140567322951680 ddar.py:60] Depth 5/1000 time = 6.26777458190918
I0123 18:11:30.581540 140567322951680 ddar.py:60] Depth 6/1000 time = 6.287451982498169
I0123 18:11:36.516520 140567322951680 ddar.py:60] Depth 7/1000 time = 5.886807203292847
I0123 18:11:36.516733 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:11:36.516836 140567322951680 alphageometry.py:566] LM output (score=-3.241935): "l : D c j f l 16 D c l f j 17 ;"
I0123 18:11:36.516874 140567322951680 alphageometry.py:567] Translation: "l = eqdistance l f c j, eqdistance l c f j"

I0123 18:11:36.516911 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l f c j, eqdistance l c f j ? perp a c c k"
I0123 18:11:36.517073 140567322951680 graph.py:498] 
I0123 18:11:36.517135 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = eqdistance l f c j, eqdistance l c f j ? perp a c c k
I0123 18:11:37.644703 140567322951680 ddar.py:60] Depth 1/1000 time = 1.0947527885437012
I0123 18:11:41.568895 140567322951680 ddar.py:60] Depth 2/1000 time = 3.9239799976348877
I0123 18:11:45.790817 140567322951680 ddar.py:60] Depth 3/1000 time = 4.221735000610352
I0123 18:11:50.636926 140567322951680 ddar.py:60] Depth 4/1000 time = 4.845909833908081
I0123 18:11:55.141307 140567322951680 ddar.py:60] Depth 5/1000 time = 4.504184246063232
I0123 18:11:59.695037 140567322951680 ddar.py:60] Depth 6/1000 time = 4.5531415939331055
I0123 18:12:04.679349 140567322951680 ddar.py:60] Depth 7/1000 time = 4.962022066116333
I0123 18:12:09.320521 140567322951680 ddar.py:60] Depth 8/1000 time = 4.633968114852905
I0123 18:12:09.320745 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:12:09.320857 140567322951680 alphageometry.py:566] LM output (score=-3.243212): "l : D c e e l 16 ;"
I0123 18:12:09.320896 140567322951680 alphageometry.py:567] Translation: "l = on_circle l e c"

I0123 18:12:09.320935 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l e c ? perp a c c k"
I0123 18:12:09.321105 140567322951680 graph.py:498] 
I0123 18:12:09.321170 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l e c ? perp a c c k
I0123 18:12:10.786479 140567322951680 ddar.py:60] Depth 1/1000 time = 1.4394142627716064
I0123 18:12:14.950709 140567322951680 ddar.py:60] Depth 2/1000 time = 4.1640520095825195
I0123 18:12:19.207380 140567322951680 ddar.py:60] Depth 3/1000 time = 4.256488084793091
I0123 18:12:23.547507 140567322951680 ddar.py:60] Depth 4/1000 time = 4.339904546737671
I0123 18:12:27.355095 140567322951680 ddar.py:60] Depth 5/1000 time = 3.806971311569214
I0123 18:12:32.108923 140567322951680 ddar.py:60] Depth 6/1000 time = 4.722876310348511
I0123 18:12:32.109139 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:12:32.109258 140567322951680 alphageometry.py:540] Depth 1. There are 32 nodes to expand:
I0123 18:12:32.109298 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a b a l 16 D a b b l 17 ; x00
I0123 18:12:32.109331 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : C a b l 16 D a l b l 17 ; x00
I0123 18:12:32.109358 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a b c l 16 ; x00
I0123 18:12:32.109384 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b c b l 16 D b c c l 17 ; x00
I0123 18:12:32.109408 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : C e h l 16 D e h e l 17 ; x00
I0123 18:12:32.109432 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D c j f l 16 P c j f l 17 ; x00
I0123 18:12:32.109456 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a b c l 16 T a b a l 17 ; x00
I0123 18:12:32.109481 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a e c l 16 P a l c e 17 ; x00
I0123 18:12:32.109520 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a c a l 16 D a c c l 17 ; x00
I0123 18:12:32.109548 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : T a c c l 16 ; x00
I0123 18:12:32.109574 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b c g l 16 D b g c l 17 ; x00
I0123 18:12:32.109598 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a b c l 16 P a c b l 17 ; x00
I0123 18:12:32.109623 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : C e f l 16 D e l f l 17 ; x00
I0123 18:12:32.109655 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a e a l 16 D e f f l 17 ; x00
I0123 18:12:32.109681 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a e a l 16 D b e b l 17 ; x00
I0123 18:12:32.109707 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b e e l 16 T b e e l 17 ; x00
I0123 18:12:32.109731 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : C e g l 16 D e l g l 17 ; x00
I0123 18:12:32.109754 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b c c l 16 D b g g l 17 ; x00
I0123 18:12:32.109778 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b c g l 16 D b l c g 17 ; x00
I0123 18:12:32.109806 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a e a l 16 D e g g l 17 ; x00
I0123 18:12:32.109832 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D c e c l 16 D e g g l 17 ; x00
I0123 18:12:32.109857 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P b g c l 16 P b l c g 17 ; x00
I0123 18:12:32.109881 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a b c l 16 P a l b c 17 ; x00
I0123 18:12:32.109906 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P b f d l 16 ; x00
I0123 18:12:32.109930 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b c c l 16 D b d d l 17 ; x00
I0123 18:12:32.109953 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a e a l 16 D c e c l 17 ; x00
I0123 18:12:32.109976 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P b e f l 16 P b f e l 17 ; x00
I0123 18:12:32.109999 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a b a l 16 D b c c l 17 ; x00
I0123 18:12:32.110022 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P e f k l 16 ; x00
I0123 18:12:32.110044 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D b e b l 16 D e g g l 17 ; x00
I0123 18:12:32.110070 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D c j f l 16 D c l f j 17 ; x00
I0123 18:12:32.110095 140567322951680 alphageometry.py:544] {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D c e e l 16 ; x00
I0123 18:12:32.110121 140567322951680 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : D a b a l 16 D a b b l 17 ; x00
I0123 18:12:39.421548 140567322951680 alphageometry.py:566] LM output (score=-2.035407): "m : D c e c m 18 D c e e m 19 ;"
I0123 18:12:39.421711 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_circle m e c"

I0123 18:12:39.421757 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e, on_circle m e c ? perp a c c k"
I0123 18:12:39.421922 140567322951680 graph.py:498] 
I0123 18:12:39.421983 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e, on_circle m e c ? perp a c c k
I0123 18:12:41.235917 140567322951680 ddar.py:60] Depth 1/1000 time = 1.7745909690856934
I0123 18:12:45.720751 140567322951680 ddar.py:60] Depth 2/1000 time = 4.4846131801605225
I0123 18:12:51.313233 140567322951680 ddar.py:60] Depth 3/1000 time = 5.592286109924316
I0123 18:12:57.200921 140567322951680 ddar.py:60] Depth 4/1000 time = 5.887499809265137
I0123 18:13:02.689854 140567322951680 ddar.py:60] Depth 5/1000 time = 5.48874306678772
I0123 18:13:08.194172 140567322951680 ddar.py:60] Depth 6/1000 time = 5.50368857383728
I0123 18:13:13.715024 140567322951680 ddar.py:60] Depth 7/1000 time = 5.5176661014556885
I0123 18:13:19.348526 140567322951680 ddar.py:60] Depth 8/1000 time = 5.587817430496216
I0123 18:13:25.291891 140567322951680 ddar.py:60] Depth 9/1000 time = 5.93503737449646
I0123 18:13:25.292097 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:13:25.292166 140567322951680 alphageometry.py:566] LM output (score=-2.342225): "m : D c h c m 18 D c h h m 19 ;"
I0123 18:13:25.292204 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m h c"

I0123 18:13:25.292243 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m h c ? perp a c c k"
I0123 18:13:25.292413 140567322951680 graph.py:498] 
I0123 18:13:25.292497 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m h c ? perp a c c k
I0123 18:13:26.161316 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8260490894317627
I0123 18:13:30.494614 140567322951680 ddar.py:60] Depth 2/1000 time = 4.333124399185181
I0123 18:13:35.505077 140567322951680 ddar.py:60] Depth 3/1000 time = 5.010181903839111
I0123 18:13:40.944747 140567322951680 ddar.py:60] Depth 4/1000 time = 5.439481019973755
I0123 18:13:46.013733 140567322951680 ddar.py:60] Depth 5/1000 time = 5.068799257278442
I0123 18:13:51.093954 140567322951680 ddar.py:60] Depth 6/1000 time = 5.0799736976623535
I0123 18:13:56.202700 140567322951680 ddar.py:60] Depth 7/1000 time = 5.108059883117676
I0123 18:14:01.285525 140567322951680 ddar.py:60] Depth 8/1000 time = 5.080333471298218
I0123 18:14:06.520471 140567322951680 ddar.py:60] Depth 9/1000 time = 5.188293933868408
I0123 18:14:06.520699 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:14:06.520762 140567322951680 alphageometry.py:566] LM output (score=-2.444282): "m : D a c a m 18 D a c c m 19 ;"
I0123 18:14:06.520797 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a c, on_circle m c a"

I0123 18:14:06.520835 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a c, on_circle m c a ? perp a c c k"
I0123 18:14:06.521007 140567322951680 graph.py:498] 
I0123 18:14:06.521071 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a c, on_circle m c a ? perp a c c k
I0123 18:14:07.404794 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8400483131408691
I0123 18:14:12.955721 140567322951680 ddar.py:60] Depth 2/1000 time = 5.550778150558472
I0123 18:14:19.440099 140567322951680 ddar.py:60] Depth 3/1000 time = 6.484191656112671
I0123 18:14:26.096717 140567322951680 ddar.py:60] Depth 4/1000 time = 6.656437158584595
I0123 18:14:32.318502 140567322951680 ddar.py:60] Depth 5/1000 time = 6.221200466156006
I0123 18:14:38.909620 140567322951680 ddar.py:60] Depth 6/1000 time = 6.588810682296753
I0123 18:14:45.707550 140567322951680 ddar.py:60] Depth 7/1000 time = 6.756203889846802
I0123 18:14:45.707770 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:14:45.707835 140567322951680 alphageometry.py:566] LM output (score=-2.496246): "m : D b e b m 18 D e l l m 19 ;"
I0123 18:14:45.707871 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m l e"

I0123 18:14:45.707910 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m l e ? perp a c c k"
I0123 18:14:45.708079 140567322951680 graph.py:498] 
I0123 18:14:45.708146 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m l e ? perp a c c k
I0123 18:14:46.674270 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9183201789855957
I0123 18:14:51.329015 140567322951680 ddar.py:60] Depth 2/1000 time = 4.654512166976929
I0123 18:14:56.145792 140567322951680 ddar.py:60] Depth 3/1000 time = 4.816610813140869
I0123 18:15:01.012209 140567322951680 ddar.py:60] Depth 4/1000 time = 4.866241931915283
I0123 18:15:05.911501 140567322951680 ddar.py:60] Depth 5/1000 time = 4.898636102676392
I0123 18:15:10.852103 140567322951680 ddar.py:60] Depth 6/1000 time = 4.938178300857544
I0123 18:15:15.782147 140567322951680 ddar.py:60] Depth 7/1000 time = 4.898320198059082
I0123 18:15:20.815257 140567322951680 ddar.py:60] Depth 8/1000 time = 5.0329272747039795
I0123 18:15:25.926663 140567322951680 ddar.py:60] Depth 9/1000 time = 5.111182689666748
I0123 18:15:31.080062 140567322951680 ddar.py:60] Depth 10/1000 time = 5.143812656402588
I0123 18:15:36.259604 140567322951680 ddar.py:60] Depth 11/1000 time = 5.174114942550659
I0123 18:15:36.259815 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:15:36.259884 140567322951680 alphageometry.py:566] LM output (score=-2.587635): "m : D b e b m 18 D b e e m 19 ;"
I0123 18:15:36.259922 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m e b"

I0123 18:15:36.259960 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m e b ? perp a c c k"
I0123 18:15:36.260124 140567322951680 graph.py:498] 
I0123 18:15:36.260188 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m e b ? perp a c c k
I0123 18:15:38.314047 140567322951680 ddar.py:60] Depth 1/1000 time = 2.0142242908477783
I0123 18:15:42.950399 140567322951680 ddar.py:60] Depth 2/1000 time = 4.636124610900879
I0123 18:15:49.317250 140567322951680 ddar.py:60] Depth 3/1000 time = 6.366546154022217
I0123 18:15:55.227531 140567322951680 ddar.py:60] Depth 4/1000 time = 5.910085439682007
I0123 18:16:01.141825 140567322951680 ddar.py:60] Depth 5/1000 time = 5.9136340618133545
I0123 18:16:07.187285 140567322951680 ddar.py:60] Depth 6/1000 time = 6.041994571685791
I0123 18:16:13.679353 140567322951680 ddar.py:60] Depth 7/1000 time = 6.431719779968262
I0123 18:16:13.679577 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:16:13.679635 140567322951680 alphageometry.py:566] LM output (score=-2.605293): "m : T c h c m 18 ;"
I0123 18:16:13.679669 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c h"

I0123 18:16:13.679704 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_tline m c c h ? perp a c c k"
I0123 18:16:13.679872 140567322951680 graph.py:498] 
I0123 18:16:13.679940 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_tline m c c h ? perp a c c k
I0123 18:16:14.427876 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7107417583465576
I0123 18:16:18.596808 140567322951680 ddar.py:60] Depth 2/1000 time = 4.168814182281494
I0123 18:16:23.265464 140567322951680 ddar.py:60] Depth 3/1000 time = 4.668445587158203
I0123 18:16:28.361232 140567322951680 ddar.py:60] Depth 4/1000 time = 5.0955352783203125
I0123 18:16:33.029491 140567322951680 ddar.py:60] Depth 5/1000 time = 4.6677117347717285
I0123 18:16:37.672206 140567322951680 ddar.py:60] Depth 6/1000 time = 4.641092538833618
I0123 18:16:42.895567 140567322951680 ddar.py:60] Depth 7/1000 time = 5.196322679519653
I0123 18:16:42.895810 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:16:42.895872 140567322951680 alphageometry.py:566] LM output (score=-2.647611): "m : D b h b m 18 D b h h m 19 ;"
I0123 18:16:42.895908 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b h, on_circle m h b"

I0123 18:16:42.895956 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b h, on_circle m h b ? perp a c c k"
I0123 18:16:42.896123 140567322951680 graph.py:498] 
I0123 18:16:42.896186 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b h, on_circle m h b ? perp a c c k
I0123 18:16:43.777360 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8377304077148438
I0123 18:16:48.285386 140567322951680 ddar.py:60] Depth 2/1000 time = 4.507894277572632
I0123 18:16:54.363267 140567322951680 ddar.py:60] Depth 3/1000 time = 6.077715158462524
I0123 18:16:59.699074 140567322951680 ddar.py:60] Depth 4/1000 time = 5.3355677127838135
I0123 18:17:06.015862 140567322951680 ddar.py:60] Depth 5/1000 time = 6.316459894180298
I0123 18:17:11.873499 140567322951680 ddar.py:60] Depth 6/1000 time = 5.857037544250488
I0123 18:17:17.828463 140567322951680 ddar.py:60] Depth 7/1000 time = 5.951587200164795
I0123 18:17:23.947257 140567322951680 ddar.py:60] Depth 8/1000 time = 6.067982912063599
I0123 18:17:30.010623 140567322951680 ddar.py:60] Depth 9/1000 time = 6.0564961433410645
I0123 18:17:30.010854 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:17:30.010921 140567322951680 alphageometry.py:566] LM output (score=-2.656122): "m : D c h c m 18 D f h f m 19 ;"
I0123 18:17:30.010959 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m f h"

I0123 18:17:30.010998 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m f h ? perp a c c k"
I0123 18:17:30.011165 140567322951680 graph.py:498] 
I0123 18:17:30.011231 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m f h ? perp a c c k
I0123 18:17:30.869177 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8115284442901611
I0123 18:17:34.851016 140567322951680 ddar.py:60] Depth 2/1000 time = 3.981708526611328
I0123 18:17:40.857259 140567322951680 ddar.py:60] Depth 3/1000 time = 6.006036043167114
I0123 18:17:46.294159 140567322951680 ddar.py:60] Depth 4/1000 time = 5.436687707901001
I0123 18:17:52.182609 140567322951680 ddar.py:60] Depth 5/1000 time = 5.888251781463623
I0123 18:17:58.217480 140567322951680 ddar.py:60] Depth 6/1000 time = 6.03464674949646
I0123 18:18:03.725558 140567322951680 ddar.py:60] Depth 7/1000 time = 5.507403373718262
I0123 18:18:09.175408 140567322951680 ddar.py:60] Depth 8/1000 time = 5.448050260543823
I0123 18:18:15.495188 140567322951680 ddar.py:60] Depth 9/1000 time = 6.286225080490112
I0123 18:18:21.181085 140567322951680 ddar.py:60] Depth 10/1000 time = 5.685657978057861
I0123 18:18:21.183648 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:18:21.183742 140567322951680 alphageometry.py:566] LM output (score=-2.662954): "m : D c e c m 18 D e g g m 19 ;"
I0123 18:18:21.183783 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_circle m g e"

I0123 18:18:21.183824 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e, on_circle m g e ? perp a c c k"
I0123 18:18:21.183990 140567322951680 graph.py:498] 
I0123 18:18:21.184056 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e, on_circle m g e ? perp a c c k
I0123 18:18:22.060728 140567322951680 ddar.py:60] Depth 1/1000 time = 0.833345890045166
I0123 18:18:25.978304 140567322951680 ddar.py:60] Depth 2/1000 time = 3.917435646057129
I0123 18:18:31.359101 140567322951680 ddar.py:60] Depth 3/1000 time = 5.380600929260254
I0123 18:18:35.856118 140567322951680 ddar.py:60] Depth 4/1000 time = 4.496785879135132
I0123 18:18:41.264082 140567322951680 ddar.py:60] Depth 5/1000 time = 5.407316207885742
I0123 18:18:45.697699 140567322951680 ddar.py:60] Depth 6/1000 time = 4.431870460510254
I0123 18:18:50.765542 140567322951680 ddar.py:60] Depth 7/1000 time = 5.03732967376709
I0123 18:18:50.765895 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:18:50.765983 140567322951680 alphageometry.py:566] LM output (score=-2.682937): "m : P a e c m 18 P a m c e 19 ;"
I0123 18:18:50.766022 140567322951680 alphageometry.py:567] Translation: "m = on_pline m c a e, on_pline m a c e"

I0123 18:18:50.766074 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_pline m c a e, on_pline m a c e ? perp a c c k"
I0123 18:18:50.766265 140567322951680 graph.py:498] 
I0123 18:18:50.766328 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_pline m c a e, on_pline m a c e ? perp a c c k
I0123 18:18:52.188289 140567322951680 ddar.py:60] Depth 1/1000 time = 1.3771989345550537
I0123 18:18:57.460314 140567322951680 ddar.py:60] Depth 2/1000 time = 5.2718117237091064
I0123 18:19:04.385441 140567322951680 ddar.py:60] Depth 3/1000 time = 6.924931287765503
I0123 18:19:10.670824 140567322951680 ddar.py:60] Depth 4/1000 time = 6.285123586654663
I0123 18:19:16.959128 140567322951680 ddar.py:60] Depth 5/1000 time = 6.287952423095703
I0123 18:19:23.640178 140567322951680 ddar.py:60] Depth 6/1000 time = 6.680398225784302
I0123 18:19:30.490684 140567322951680 ddar.py:60] Depth 7/1000 time = 6.848790168762207
I0123 18:19:36.879238 140567322951680 ddar.py:60] Depth 8/1000 time = 6.354217529296875
I0123 18:19:36.884509 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:19:36.884588 140567322951680 alphageometry.py:566] LM output (score=-2.689792): "m : D b h b m 18 ;"
I0123 18:19:36.884628 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b h"

I0123 18:19:36.884667 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b h ? perp a c c k"
I0123 18:19:36.884833 140567322951680 graph.py:498] 
I0123 18:19:36.884900 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b h ? perp a c c k
I0123 18:19:37.664762 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7393031120300293
I0123 18:19:41.778444 140567322951680 ddar.py:60] Depth 2/1000 time = 4.113553047180176
I0123 18:19:46.348179 140567322951680 ddar.py:60] Depth 3/1000 time = 4.569479703903198
I0123 18:19:51.003879 140567322951680 ddar.py:60] Depth 4/1000 time = 4.655361652374268
I0123 18:19:55.079495 140567322951680 ddar.py:60] Depth 5/1000 time = 4.075071573257446
I0123 18:19:59.658203 140567322951680 ddar.py:60] Depth 6/1000 time = 4.577124118804932
I0123 18:20:04.425363 140567322951680 ddar.py:60] Depth 7/1000 time = 4.739041328430176
I0123 18:20:04.425731 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:20:04.425824 140567322951680 alphageometry.py:566] LM output (score=-2.702691): "m : D f g f m 18 D f g g m 19 ;"
I0123 18:20:04.425864 140567322951680 alphageometry.py:567] Translation: "m = on_circle m f g, on_circle m g f"

I0123 18:20:04.425916 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m f g, on_circle m g f ? perp a c c k"
I0123 18:20:04.426101 140567322951680 graph.py:498] 
I0123 18:20:04.426167 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m f g, on_circle m g f ? perp a c c k
I0123 18:20:05.310813 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8392612934112549
I0123 18:20:09.202530 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8915748596191406
I0123 18:20:13.899085 140567322951680 ddar.py:60] Depth 3/1000 time = 4.696349859237671
I0123 18:20:18.630976 140567322951680 ddar.py:60] Depth 4/1000 time = 4.7316672801971436
I0123 18:20:22.871403 140567322951680 ddar.py:60] Depth 5/1000 time = 4.239800453186035
I0123 18:20:27.599780 140567322951680 ddar.py:60] Depth 6/1000 time = 4.725393056869507
I0123 18:20:32.955605 140567322951680 ddar.py:60] Depth 7/1000 time = 5.327595949172974
I0123 18:20:32.955822 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:20:32.955892 140567322951680 alphageometry.py:566] LM output (score=-2.719366): "m : D e m k m 18 D h m k m 19 ;"
I0123 18:20:32.955945 140567322951680 alphageometry.py:567] Translation: "m = on_bline m k e, on_bline m k h"

I0123 18:20:32.955985 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_bline m k e, on_bline m k h ? perp a c c k"
I0123 18:20:32.956149 140567322951680 graph.py:498] 
I0123 18:20:32.956215 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_bline m k e, on_bline m k h ? perp a c c k
I0123 18:20:34.872815 140567322951680 ddar.py:60] Depth 1/1000 time = 1.865494728088379
I0123 18:20:38.847660 140567322951680 ddar.py:60] Depth 2/1000 time = 3.974656581878662
I0123 18:20:43.596888 140567322951680 ddar.py:60] Depth 3/1000 time = 4.749011754989624
I0123 18:20:48.333693 140567322951680 ddar.py:60] Depth 4/1000 time = 4.736571550369263
I0123 18:20:53.052641 140567322951680 ddar.py:60] Depth 5/1000 time = 4.718401908874512
I0123 18:20:57.814191 140567322951680 ddar.py:60] Depth 6/1000 time = 4.75990104675293
I0123 18:21:02.710216 140567322951680 ddar.py:60] Depth 7/1000 time = 4.872241973876953
I0123 18:21:07.657633 140567322951680 ddar.py:60] Depth 8/1000 time = 4.938236236572266
I0123 18:21:07.657863 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:21:07.657928 140567322951680 alphageometry.py:566] LM output (score=-2.776192): "m : D b e b m 18 D e g g m 19 ;"
I0123 18:21:07.657967 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m g e"

I0123 18:21:07.658007 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m g e ? perp a c c k"
I0123 18:21:07.658175 140567322951680 graph.py:498] 
I0123 18:21:07.658243 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m g e ? perp a c c k
I0123 18:21:08.600357 140567322951680 ddar.py:60] Depth 1/1000 time = 0.898463249206543
I0123 18:21:14.411197 140567322951680 ddar.py:60] Depth 2/1000 time = 5.810701847076416
I0123 18:21:21.352169 140567322951680 ddar.py:60] Depth 3/1000 time = 6.9407689571380615
I0123 18:21:27.466140 140567322951680 ddar.py:60] Depth 4/1000 time = 6.113724708557129
I0123 18:21:34.571975 140567322951680 ddar.py:60] Depth 5/1000 time = 7.105648040771484
I0123 18:21:41.291810 140567322951680 ddar.py:60] Depth 6/1000 time = 6.719236612319946
I0123 18:21:48.503273 140567322951680 ddar.py:60] Depth 7/1000 time = 7.208796739578247
I0123 18:21:55.337894 140567322951680 ddar.py:60] Depth 8/1000 time = 6.804856777191162
I0123 18:22:02.260579 140567322951680 ddar.py:60] Depth 9/1000 time = 6.89341139793396
I0123 18:22:02.260809 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:22:02.260874 140567322951680 alphageometry.py:566] LM output (score=-2.817712): "m : D a e a m 18 D e f f m 19 ;"
I0123 18:22:02.260911 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a e, on_circle m f e"

I0123 18:22:02.260949 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m f e ? perp a c c k"
I0123 18:22:02.261126 140567322951680 graph.py:498] 
I0123 18:22:02.261196 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m f e ? perp a c c k
I0123 18:22:03.159009 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8514754772186279
I0123 18:22:08.392866 140567322951680 ddar.py:60] Depth 2/1000 time = 5.233712673187256
I0123 18:22:15.147715 140567322951680 ddar.py:60] Depth 3/1000 time = 6.754607439041138
I0123 18:22:21.252102 140567322951680 ddar.py:60] Depth 4/1000 time = 6.104065418243408
I0123 18:22:28.365286 140567322951680 ddar.py:60] Depth 5/1000 time = 7.1129865646362305
I0123 18:22:35.029372 140567322951680 ddar.py:60] Depth 6/1000 time = 6.663392066955566
I0123 18:22:41.639143 140567322951680 ddar.py:60] Depth 7/1000 time = 6.606997966766357
I0123 18:22:48.808853 140567322951680 ddar.py:60] Depth 8/1000 time = 7.137330770492554
I0123 18:22:55.749319 140567322951680 ddar.py:60] Depth 9/1000 time = 6.912770509719849
I0123 18:22:55.749575 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:22:55.749634 140567322951680 alphageometry.py:566] LM output (score=-2.830676): "m : D c h c m 18 D e h e m 19 ;"
I0123 18:22:55.749678 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m e h"

I0123 18:22:55.749720 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m e h ? perp a c c k"
I0123 18:22:55.749883 140567322951680 graph.py:498] 
I0123 18:22:55.749948 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h, on_circle m e h ? perp a c c k
I0123 18:22:56.629398 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8328025341033936
I0123 18:23:03.372426 140567322951680 ddar.py:60] Depth 2/1000 time = 6.742899656295776
I0123 18:23:11.894517 140567322951680 ddar.py:60] Depth 3/1000 time = 8.52184009552002
I0123 18:23:20.329292 140567322951680 ddar.py:60] Depth 4/1000 time = 8.434425592422485
I0123 18:23:28.825626 140567322951680 ddar.py:60] Depth 5/1000 time = 8.495652914047241
I0123 18:23:37.343982 140567322951680 ddar.py:60] Depth 6/1000 time = 8.51599407196045
I0123 18:23:45.950520 140567322951680 ddar.py:60] Depth 7/1000 time = 8.560231924057007
I0123 18:23:45.950840 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:23:45.950918 140567322951680 alphageometry.py:566] LM output (score=-2.872835): "m : D g i g m 18 ;"
I0123 18:23:45.950957 140567322951680 alphageometry.py:567] Translation: "m = on_circle m g i"

I0123 18:23:45.950999 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m g i ? perp a c c k"
I0123 18:23:45.951181 140567322951680 graph.py:498] 
I0123 18:23:45.951260 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m g i ? perp a c c k
I0123 18:23:46.725015 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7355086803436279
I0123 18:23:51.070756 140567322951680 ddar.py:60] Depth 2/1000 time = 4.345489025115967
I0123 18:23:55.123357 140567322951680 ddar.py:60] Depth 3/1000 time = 4.052411317825317
I0123 18:23:59.704257 140567322951680 ddar.py:60] Depth 4/1000 time = 4.580686330795288
I0123 18:24:04.351191 140567322951680 ddar.py:60] Depth 5/1000 time = 4.646406650543213
I0123 18:24:08.989182 140567322951680 ddar.py:60] Depth 6/1000 time = 4.6363654136657715
I0123 18:24:13.195972 140567322951680 ddar.py:60] Depth 7/1000 time = 4.180846691131592
I0123 18:24:13.196210 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:24:13.196279 140567322951680 alphageometry.py:566] LM output (score=-2.942909): "m : D b l g m 18 D b m l g 19 ;"
I0123 18:24:13.196317 140567322951680 alphageometry.py:567] Translation: "m = eqdistance m g b l, eqdistance m b l g"

I0123 18:24:13.196357 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = eqdistance m g b l, eqdistance m b l g ? perp a c c k"
I0123 18:24:13.196535 140567322951680 graph.py:498] 
I0123 18:24:13.196605 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = eqdistance m g b l, eqdistance m b l g ? perp a c c k
I0123 18:24:14.212464 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9718461036682129
I0123 18:24:18.744740 140567322951680 ddar.py:60] Depth 2/1000 time = 4.532140731811523
I0123 18:24:23.769434 140567322951680 ddar.py:60] Depth 3/1000 time = 5.024454832077026
I0123 18:24:28.910862 140567322951680 ddar.py:60] Depth 4/1000 time = 5.141092538833618
I0123 18:24:33.422649 140567322951680 ddar.py:60] Depth 5/1000 time = 4.511193752288818
I0123 18:24:37.890535 140567322951680 ddar.py:60] Depth 6/1000 time = 4.465816497802734
I0123 18:24:42.866821 140567322951680 ddar.py:60] Depth 7/1000 time = 4.948859453201294
I0123 18:24:42.867171 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:24:42.867255 140567322951680 alphageometry.py:566] LM output (score=-2.977219): "m : T c g c m 18 ;"
I0123 18:24:42.867293 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c g"

I0123 18:24:42.867346 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_tline m c c g ? perp a c c k"
I0123 18:24:42.867528 140567322951680 graph.py:498] 
I0123 18:24:42.867592 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_tline m c c g ? perp a c c k
I0123 18:24:43.634177 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7279267311096191
I0123 18:24:47.957895 140567322951680 ddar.py:60] Depth 2/1000 time = 4.323570489883423
I0123 18:24:52.643848 140567322951680 ddar.py:60] Depth 3/1000 time = 4.68577766418457
I0123 18:24:56.900996 140567322951680 ddar.py:60] Depth 4/1000 time = 4.2569496631622314
I0123 18:25:01.696670 140567322951680 ddar.py:60] Depth 5/1000 time = 4.795092582702637
I0123 18:25:06.570136 140567322951680 ddar.py:60] Depth 6/1000 time = 4.8715925216674805
I0123 18:25:11.540675 140567322951680 ddar.py:60] Depth 7/1000 time = 4.944398403167725
I0123 18:25:11.540893 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:25:11.540962 140567322951680 alphageometry.py:566] LM output (score=-2.983436): "m : D a e a m 18 D e g g m 19 ;"
I0123 18:25:11.540999 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a e, on_circle m g e"

I0123 18:25:11.541038 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m g e ? perp a c c k"
I0123 18:25:11.541204 140567322951680 graph.py:498] 
I0123 18:25:11.541270 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m g e ? perp a c c k
I0123 18:25:12.446883 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8585336208343506
I0123 18:25:16.982082 140567322951680 ddar.py:60] Depth 2/1000 time = 4.535048246383667
I0123 18:25:23.461333 140567322951680 ddar.py:60] Depth 3/1000 time = 6.4790308475494385
I0123 18:25:30.070011 140567322951680 ddar.py:60] Depth 4/1000 time = 6.608440160751343
I0123 18:25:37.353597 140567322951680 ddar.py:60] Depth 5/1000 time = 7.2833850383758545
I0123 18:25:43.546380 140567322951680 ddar.py:60] Depth 6/1000 time = 6.192542314529419
I0123 18:25:50.762640 140567322951680 ddar.py:60] Depth 7/1000 time = 7.216030836105347
I0123 18:25:57.559645 140567322951680 ddar.py:60] Depth 8/1000 time = 6.796324968338013
I0123 18:26:04.395809 140567322951680 ddar.py:60] Depth 9/1000 time = 6.833340167999268
I0123 18:26:10.574392 140567322951680 ddar.py:60] Depth 10/1000 time = 6.147727966308594
I0123 18:26:18.061750 140567322951680 ddar.py:60] Depth 11/1000 time = 7.460944890975952
I0123 18:26:25.005775 140567322951680 ddar.py:60] Depth 12/1000 time = 6.943737506866455
I0123 18:26:25.008415 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:26:25.008492 140567322951680 alphageometry.py:566] LM output (score=-3.004077): "m : D c g c m 18 D c g g m 19 ;"
I0123 18:26:25.008531 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c g, on_circle m g c"

I0123 18:26:25.008573 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c g, on_circle m g c ? perp a c c k"
I0123 18:26:25.008744 140567322951680 graph.py:498] 
I0123 18:26:25.008813 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c g, on_circle m g c ? perp a c c k
I0123 18:26:25.889178 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8367331027984619
I0123 18:26:30.077687 140567322951680 ddar.py:60] Depth 2/1000 time = 4.188374757766724
I0123 18:26:35.304466 140567322951680 ddar.py:60] Depth 3/1000 time = 5.226561069488525
I0123 18:26:40.028352 140567322951680 ddar.py:60] Depth 4/1000 time = 4.7236504554748535
I0123 18:26:45.285320 140567322951680 ddar.py:60] Depth 5/1000 time = 5.2563254833221436
I0123 18:26:50.652991 140567322951680 ddar.py:60] Depth 6/1000 time = 5.365201950073242
I0123 18:26:55.469523 140567322951680 ddar.py:60] Depth 7/1000 time = 4.816305160522461
I0123 18:27:00.995701 140567322951680 ddar.py:60] Depth 8/1000 time = 5.484214544296265
I0123 18:27:00.995939 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:27:00.996006 140567322951680 alphageometry.py:566] LM output (score=-3.008742): "m : D e k e m 18 D e k k m 19 ;"
I0123 18:27:00.996044 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k, on_circle m k e"

I0123 18:27:00.996084 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e k, on_circle m k e ? perp a c c k"
I0123 18:27:00.996265 140567322951680 graph.py:498] 
I0123 18:27:00.996343 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e k, on_circle m k e ? perp a c c k
I0123 18:27:01.896612 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8566374778747559
I0123 18:27:05.951538 140567322951680 ddar.py:60] Depth 2/1000 time = 4.05478310585022
I0123 18:27:10.871760 140567322951680 ddar.py:60] Depth 3/1000 time = 4.920007228851318
I0123 18:27:15.279613 140567322951680 ddar.py:60] Depth 4/1000 time = 4.407612085342407
I0123 18:27:20.218295 140567322951680 ddar.py:60] Depth 5/1000 time = 4.93811821937561
I0123 18:27:24.600269 140567322951680 ddar.py:60] Depth 6/1000 time = 4.3799378871917725
I0123 18:27:29.655608 140567322951680 ddar.py:60] Depth 7/1000 time = 5.025938510894775
I0123 18:27:29.655938 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:27:29.656020 140567322951680 alphageometry.py:566] LM output (score=-3.028786): "m : D e m j m 18 D e m k m 19 ;"
I0123 18:27:29.656056 140567322951680 alphageometry.py:567] Translation: "m = on_bline m j e, on_bline m k e"

I0123 18:27:29.656106 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_bline m j e, on_bline m k e ? perp a c c k"
I0123 18:27:29.656283 140567322951680 graph.py:498] 
I0123 18:27:29.656354 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_bline m j e, on_bline m k e ? perp a c c k
I0123 18:27:31.617105 140567322951680 ddar.py:60] Depth 1/1000 time = 1.9107520580291748
I0123 18:27:36.230819 140567322951680 ddar.py:60] Depth 2/1000 time = 4.613493204116821
I0123 18:27:41.298753 140567322951680 ddar.py:60] Depth 3/1000 time = 5.0677430629730225
I0123 18:27:45.705622 140567322951680 ddar.py:60] Depth 4/1000 time = 4.40666127204895
I0123 18:27:50.174389 140567322951680 ddar.py:60] Depth 5/1000 time = 4.468130111694336
I0123 18:27:55.239276 140567322951680 ddar.py:60] Depth 6/1000 time = 5.063127040863037
I0123 18:27:59.733916 140567322951680 ddar.py:60] Depth 7/1000 time = 4.494434118270874
I0123 18:28:04.806110 140567322951680 ddar.py:60] Depth 8/1000 time = 5.072005271911621
I0123 18:28:09.966425 140567322951680 ddar.py:60] Depth 9/1000 time = 5.1600940227508545
I0123 18:28:14.563638 140567322951680 ddar.py:60] Depth 10/1000 time = 4.571673393249512
I0123 18:28:19.843966 140567322951680 ddar.py:60] Depth 11/1000 time = 5.271986246109009
I0123 18:28:19.845787 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:28:19.845865 140567322951680 alphageometry.py:566] LM output (score=-3.045488): "m : D e h e m 18 D e h h m 19 ;"
I0123 18:28:19.845906 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e h, on_circle m h e"

I0123 18:28:19.845946 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e h, on_circle m h e ? perp a c c k"
I0123 18:28:19.846117 140567322951680 graph.py:498] 
I0123 18:28:19.846184 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e h, on_circle m h e ? perp a c c k
I0123 18:28:20.710362 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8196835517883301
I0123 18:28:24.837253 140567322951680 ddar.py:60] Depth 2/1000 time = 4.126708507537842
I0123 18:28:29.362507 140567322951680 ddar.py:60] Depth 3/1000 time = 4.524941921234131
I0123 18:28:34.431825 140567322951680 ddar.py:60] Depth 4/1000 time = 5.069106578826904
I0123 18:28:38.925143 140567322951680 ddar.py:60] Depth 5/1000 time = 4.492760181427002
I0123 18:28:44.083472 140567322951680 ddar.py:60] Depth 6/1000 time = 5.156073570251465
I0123 18:28:48.674473 140567322951680 ddar.py:60] Depth 7/1000 time = 4.590665817260742
I0123 18:28:53.868266 140567322951680 ddar.py:60] Depth 8/1000 time = 5.193613529205322
I0123 18:28:58.486622 140567322951680 ddar.py:60] Depth 9/1000 time = 4.618178844451904
I0123 18:29:03.922838 140567322951680 ddar.py:60] Depth 10/1000 time = 5.40132999420166
I0123 18:29:03.926089 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:29:03.926169 140567322951680 alphageometry.py:566] LM output (score=-3.055489): "m : D c h c m 18 ;"
I0123 18:29:03.926209 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h"

I0123 18:29:03.926254 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h ? perp a c c k"
I0123 18:29:03.926424 140567322951680 graph.py:498] 
I0123 18:29:03.926488 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c h ? perp a c c k
I0123 18:29:04.712842 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7463750839233398
I0123 18:29:09.180068 140567322951680 ddar.py:60] Depth 2/1000 time = 4.467101097106934
I0123 18:29:13.451710 140567322951680 ddar.py:60] Depth 3/1000 time = 4.271450042724609
I0123 18:29:17.722455 140567322951680 ddar.py:60] Depth 4/1000 time = 4.270565509796143
I0123 18:29:22.675349 140567322951680 ddar.py:60] Depth 5/1000 time = 4.9523701667785645
I0123 18:29:26.988092 140567322951680 ddar.py:60] Depth 6/1000 time = 4.311131715774536
I0123 18:29:32.019870 140567322951680 ddar.py:60] Depth 7/1000 time = 5.004856586456299
I0123 18:29:32.020083 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:29:32.020151 140567322951680 alphageometry.py:566] LM output (score=-3.092805): "m : D b e b m 18 D e h h m 19 ;"
I0123 18:29:32.020188 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m h e"

I0123 18:29:32.020224 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m h e ? perp a c c k"
I0123 18:29:32.020396 140567322951680 graph.py:498] 
I0123 18:29:32.020460 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m b e, on_circle m h e ? perp a c c k
I0123 18:29:32.947201 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8834855556488037
I0123 18:29:38.126917 140567322951680 ddar.py:60] Depth 2/1000 time = 5.1795923709869385
I0123 18:29:44.908416 140567322951680 ddar.py:60] Depth 3/1000 time = 6.781296730041504
I0123 18:29:51.110136 140567322951680 ddar.py:60] Depth 4/1000 time = 6.201508283615112
I0123 18:29:56.636547 140567322951680 ddar.py:60] Depth 5/1000 time = 5.526228189468384
I0123 18:30:03.426352 140567322951680 ddar.py:60] Depth 6/1000 time = 6.789205312728882
I0123 18:30:08.925540 140567322951680 ddar.py:60] Depth 7/1000 time = 5.496956825256348
I0123 18:30:15.676603 140567322951680 ddar.py:60] Depth 8/1000 time = 6.723039627075195
I0123 18:30:22.005502 140567322951680 ddar.py:60] Depth 9/1000 time = 6.315373659133911
I0123 18:30:22.005722 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:30:22.005789 140567322951680 alphageometry.py:566] LM output (score=-3.096371): "m : D a e a m 18 D a e e m 19 ;"
I0123 18:30:22.005825 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a e, on_circle m e a"

I0123 18:30:22.005863 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m e a ? perp a c c k"
I0123 18:30:22.006024 140567322951680 graph.py:498] 
I0123 18:30:22.006088 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a e, on_circle m e a ? perp a c c k
I0123 18:30:22.916531 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8669288158416748
I0123 18:30:27.157248 140567322951680 ddar.py:60] Depth 2/1000 time = 4.240590572357178
I0123 18:30:32.676055 140567322951680 ddar.py:60] Depth 3/1000 time = 5.518625497817993
I0123 18:30:37.592202 140567322951680 ddar.py:60] Depth 4/1000 time = 4.915923118591309
I0123 18:30:43.124898 140567322951680 ddar.py:60] Depth 5/1000 time = 5.532062768936157
I0123 18:30:48.035786 140567322951680 ddar.py:60] Depth 6/1000 time = 4.908719778060913
I0123 18:30:52.961035 140567322951680 ddar.py:60] Depth 7/1000 time = 4.925004959106445
I0123 18:30:58.647499 140567322951680 ddar.py:60] Depth 8/1000 time = 5.6501100063323975
I0123 18:30:58.647715 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:30:58.647783 140567322951680 alphageometry.py:566] LM output (score=-3.108048): "m : D a d a m 18 D a d d m 19 ;"
I0123 18:30:58.647819 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a d, on_circle m d a"

I0123 18:30:58.647856 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a d, on_circle m d a ? perp a c c k"
I0123 18:30:58.648026 140567322951680 graph.py:498] 
I0123 18:30:58.648090 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m a d, on_circle m d a ? perp a c c k
I0123 18:31:00.833989 140567322951680 ddar.py:60] Depth 1/1000 time = 2.1457860469818115
I0123 18:31:05.486507 140567322951680 ddar.py:60] Depth 2/1000 time = 4.652350187301636
I0123 18:31:12.041084 140567322951680 ddar.py:60] Depth 3/1000 time = 6.554334402084351
I0123 18:31:18.401278 140567322951680 ddar.py:60] Depth 4/1000 time = 6.359879016876221
I0123 18:31:24.039015 140567322951680 ddar.py:60] Depth 5/1000 time = 5.637156248092651
I0123 18:31:30.447428 140567322951680 ddar.py:60] Depth 6/1000 time = 6.405417203903198
I0123 18:31:36.422336 140567322951680 ddar.py:60] Depth 7/1000 time = 5.920476198196411
I0123 18:31:36.422553 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:31:36.422618 140567322951680 alphageometry.py:566] LM output (score=-3.147592): "m : D e k e m 18 D h k h m 19 ;"
I0123 18:31:36.422655 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k, on_circle m h k"

I0123 18:31:36.422692 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e k, on_circle m h k ? perp a c c k"
I0123 18:31:36.422857 140567322951680 graph.py:498] 
I0123 18:31:36.422920 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m e k, on_circle m h k ? perp a c c k
I0123 18:31:37.317237 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8448054790496826
I0123 18:31:42.605873 140567322951680 ddar.py:60] Depth 2/1000 time = 5.288498878479004
I0123 18:31:48.997029 140567322951680 ddar.py:60] Depth 3/1000 time = 6.3908843994140625
I0123 18:31:55.063503 140567322951680 ddar.py:60] Depth 4/1000 time = 6.066072702407837
I0123 18:32:01.681821 140567322951680 ddar.py:60] Depth 5/1000 time = 6.617583513259888
I0123 18:32:08.411430 140567322951680 ddar.py:60] Depth 6/1000 time = 6.727019548416138
I0123 18:32:15.298377 140567322951680 ddar.py:60] Depth 7/1000 time = 6.8518853187561035
I0123 18:32:22.434852 140567322951680 ddar.py:60] Depth 8/1000 time = 7.090453147888184
I0123 18:32:22.435425 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:32:22.435494 140567322951680 alphageometry.py:566] LM output (score=-3.169603): "m : P b f d m 18 ;"
I0123 18:32:22.435529 140567322951680 alphageometry.py:567] Translation: "m = on_pline m d b f"

I0123 18:32:22.435568 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_pline m d b f ? perp a c c k"
I0123 18:32:22.435731 140567322951680 graph.py:498] 
I0123 18:32:22.435794 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_pline m d b f ? perp a c c k
I0123 18:32:23.199310 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7264578342437744
I0123 18:32:27.369720 140567322951680 ddar.py:60] Depth 2/1000 time = 4.1702516078948975
I0123 18:32:32.727219 140567322951680 ddar.py:60] Depth 3/1000 time = 5.357262134552002
I0123 18:32:37.363109 140567322951680 ddar.py:60] Depth 4/1000 time = 4.6356894969940186
I0123 18:32:42.649986 140567322951680 ddar.py:60] Depth 5/1000 time = 5.286245822906494
I0123 18:32:47.320464 140567322951680 ddar.py:60] Depth 6/1000 time = 4.668746471405029
I0123 18:32:52.665669 140567322951680 ddar.py:60] Depth 7/1000 time = 5.320225715637207
I0123 18:32:52.665890 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:32:52.665960 140567322951680 alphageometry.py:566] LM output (score=-3.184983): "m : D c e c m 18 ;"
I0123 18:32:52.665996 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e"

I0123 18:32:52.666035 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e ? perp a c c k"
I0123 18:32:52.666197 140567322951680 graph.py:498] 
I0123 18:32:52.666260 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = on_circle m c e ? perp a c c k
I0123 18:32:53.443431 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7413294315338135
I0123 18:32:57.313611 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8700482845306396
I0123 18:33:02.182079 140567322951680 ddar.py:60] Depth 3/1000 time = 4.868271350860596
I0123 18:33:06.555463 140567322951680 ddar.py:60] Depth 4/1000 time = 4.3731701374053955
I0123 18:33:11.508687 140567322951680 ddar.py:60] Depth 5/1000 time = 4.952712297439575
I0123 18:33:15.893544 140567322951680 ddar.py:60] Depth 6/1000 time = 4.383211135864258
I0123 18:33:20.364202 140567322951680 ddar.py:60] Depth 7/1000 time = 4.4415977001190186
I0123 18:33:20.364405 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:33:20.364469 140567322951680 alphageometry.py:566] LM output (score=-3.186874): "m : D b l g m 18 D b g l m 19 ;"
I0123 18:33:20.364506 140567322951680 alphageometry.py:567] Translation: "m = eqdistance m g b l, eqdistance m l b g"

I0123 18:33:20.364545 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = eqdistance m g b l, eqdistance m l b g ? perp a c c k"
I0123 18:33:20.364727 140567322951680 graph.py:498] 
I0123 18:33:20.364792 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_circle l a b, on_circle l b a; m = eqdistance m g b l, eqdistance m l b g ? perp a c c k
I0123 18:33:21.368166 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9593279361724854
I0123 18:33:26.082843 140567322951680 ddar.py:60] Depth 2/1000 time = 4.714415550231934
I0123 18:33:31.969902 140567322951680 ddar.py:60] Depth 3/1000 time = 5.886870622634888
I0123 18:33:37.172081 140567322951680 ddar.py:60] Depth 4/1000 time = 5.2019944190979
I0123 18:33:43.112368 140567322951680 ddar.py:60] Depth 5/1000 time = 5.93971586227417
I0123 18:33:48.321384 140567322951680 ddar.py:60] Depth 6/1000 time = 5.206594467163086
I0123 18:33:54.157266 140567322951680 ddar.py:60] Depth 7/1000 time = 5.800870180130005
I0123 18:33:54.157466 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:33:54.157534 140567322951680 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : C a b l 16 D a l b l 17 ; x00
I0123 18:34:01.323301 140567322951680 alphageometry.py:566] LM output (score=-1.413701): "m : D e m l m 18 D l m f m 19 ;"
I0123 18:34:01.323512 140567322951680 alphageometry.py:567] Translation: "m = on_bline m l e, on_bline m f l"

I0123 18:34:01.323571 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m l e, on_bline m f l ? perp a c c k"
I0123 18:34:01.323751 140567322951680 graph.py:498] 
I0123 18:34:01.323817 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m l e, on_bline m f l ? perp a c c k
I0123 18:34:04.592562 140567322951680 ddar.py:60] Depth 1/1000 time = 3.2208876609802246
I0123 18:34:11.943115 140567322951680 ddar.py:60] Depth 2/1000 time = 7.350371360778809
I0123 18:34:21.897197 140567322951680 ddar.py:60] Depth 3/1000 time = 9.95389461517334
I0123 18:34:31.207810 140567322951680 ddar.py:60] Depth 4/1000 time = 9.310408592224121
I0123 18:34:41.159344 140567322951680 ddar.py:60] Depth 5/1000 time = 9.951342344284058
I0123 18:34:50.505921 140567322951680 ddar.py:60] Depth 6/1000 time = 9.345864295959473
I0123 18:35:00.533151 140567322951680 ddar.py:60] Depth 7/1000 time = 10.02200984954834
I0123 18:35:12.046709 140567322951680 ddar.py:60] Depth 8/1000 time = 11.480977535247803
I0123 18:35:23.484932 140567322951680 ddar.py:60] Depth 9/1000 time = 11.43801999092102
I0123 18:35:35.216173 140567322951680 ddar.py:60] Depth 10/1000 time = 11.73103380203247
I0123 18:35:46.236306 140567322951680 ddar.py:60] Depth 11/1000 time = 11.019863367080688
I0123 18:35:57.962778 140567322951680 ddar.py:60] Depth 12/1000 time = 11.695923328399658
I0123 18:35:57.963008 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:35:57.963063 140567322951680 alphageometry.py:566] LM output (score=-1.893498): "m : D a b a m 18 D a b b m 19 ;"
I0123 18:35:57.963107 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a b, on_circle m b a"

I0123 18:35:57.963149 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m a b, on_circle m b a ? perp a c c k"
I0123 18:35:57.963317 140567322951680 graph.py:498] 
I0123 18:35:57.963378 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m a b, on_circle m b a ? perp a c c k
I0123 18:35:59.017400 140567322951680 ddar.py:60] Depth 1/1000 time = 1.0149471759796143
I0123 18:36:07.661198 140567322951680 ddar.py:60] Depth 2/1000 time = 8.643630266189575
I0123 18:36:18.199633 140567322951680 ddar.py:60] Depth 3/1000 time = 10.538257837295532
I0123 18:36:29.100655 140567322951680 ddar.py:60] Depth 4/1000 time = 10.900816202163696
I0123 18:36:39.211161 140567322951680 ddar.py:60] Depth 5/1000 time = 10.110275983810425
I0123 18:36:50.027103 140567322951680 ddar.py:60] Depth 6/1000 time = 10.815187931060791
I0123 18:37:00.112053 140567322951680 ddar.py:60] Depth 7/1000 time = 10.083317518234253
I0123 18:37:00.156066 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:37:00.156160 140567322951680 alphageometry.py:566] LM output (score=-2.256609): "m : D d m e m 18 D e m l m 19 ;"
I0123 18:37:00.156195 140567322951680 alphageometry.py:567] Translation: "m = on_bline m e d, on_bline m l e"

I0123 18:37:00.156250 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m e d, on_bline m l e ? perp a c c k"
I0123 18:37:00.156434 140567322951680 graph.py:498] 
I0123 18:37:00.156493 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m e d, on_bline m l e ? perp a c c k
I0123 18:37:04.088207 140567322951680 ddar.py:60] Depth 1/1000 time = 3.884991407394409
I0123 18:37:11.721927 140567322951680 ddar.py:60] Depth 2/1000 time = 7.63354229927063
I0123 18:37:21.213674 140567322951680 ddar.py:60] Depth 3/1000 time = 9.491529703140259
I0123 18:37:30.618388 140567322951680 ddar.py:60] Depth 4/1000 time = 9.404499530792236
I0123 18:37:40.732266 140567322951680 ddar.py:60] Depth 5/1000 time = 10.113664627075195
I0123 18:37:50.872791 140567322951680 ddar.py:60] Depth 6/1000 time = 10.139823913574219
I0123 18:38:01.782697 140567322951680 ddar.py:60] Depth 7/1000 time = 10.87308931350708
I0123 18:38:14.719948 140567322951680 ddar.py:60] Depth 8/1000 time = 12.936976909637451
I0123 18:38:26.174803 140567322951680 ddar.py:60] Depth 9/1000 time = 11.454515218734741
I0123 18:38:26.203498 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:38:26.203564 140567322951680 alphageometry.py:566] LM output (score=-2.278599): "m : C b d m 18 C c l m 19 ;"
I0123 18:38:26.203599 140567322951680 alphageometry.py:567] Translation: "m = on_line m b d, on_line m c l"

I0123 18:38:26.203636 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m b d, on_line m c l ? perp a c c k"
I0123 18:38:26.203813 140567322951680 graph.py:498] 
I0123 18:38:26.203877 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m b d, on_line m c l ? perp a c c k
I0123 18:38:27.820989 140567322951680 ddar.py:60] Depth 1/1000 time = 1.5897071361541748
I0123 18:38:35.349235 140567322951680 ddar.py:60] Depth 2/1000 time = 7.528051376342773
I0123 18:38:45.260279 140567322951680 ddar.py:60] Depth 3/1000 time = 9.910854578018188
I0123 18:38:55.421691 140567322951680 ddar.py:60] Depth 4/1000 time = 10.161188840866089
I0123 18:39:05.755302 140567322951680 ddar.py:60] Depth 5/1000 time = 10.333406925201416
I0123 18:39:16.350815 140567322951680 ddar.py:60] Depth 6/1000 time = 10.595295667648315
I0123 18:39:27.687567 140567322951680 ddar.py:60] Depth 7/1000 time = 11.336488246917725
I0123 18:39:37.947715 140567322951680 ddar.py:60] Depth 8/1000 time = 10.25918197631836
I0123 18:39:37.998165 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:39:37.998259 140567322951680 alphageometry.py:566] LM output (score=-2.299512): "m : C a e m 18 C b d m 19 ;"
I0123 18:39:37.998295 140567322951680 alphageometry.py:567] Translation: "m = on_line m a e, on_line m b d"

I0123 18:39:37.998349 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m a e, on_line m b d ? perp a c c k"
I0123 18:39:37.998535 140567322951680 graph.py:498] 
I0123 18:39:37.998598 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m a e, on_line m b d ? perp a c c k
I0123 18:39:39.002766 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9746870994567871
I0123 18:39:47.467207 140567322951680 ddar.py:60] Depth 2/1000 time = 8.464228868484497
I0123 18:39:57.048074 140567322951680 ddar.py:60] Depth 3/1000 time = 9.58049726486206
I0123 18:40:07.432934 140567322951680 ddar.py:60] Depth 4/1000 time = 10.384497880935669
I0123 18:40:17.337616 140567322951680 ddar.py:60] Depth 5/1000 time = 9.904463291168213
I0123 18:40:27.216767 140567322951680 ddar.py:60] Depth 6/1000 time = 9.878921508789062
I0123 18:40:38.344244 140567322951680 ddar.py:60] Depth 7/1000 time = 11.127241849899292
I0123 18:40:48.929681 140567322951680 ddar.py:60] Depth 8/1000 time = 10.584733724594116
I0123 18:40:48.979823 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:40:48.979894 140567322951680 alphageometry.py:566] LM output (score=-2.323643): "m : D l m d m 18 D d m e m 19 ;"
I0123 18:40:48.979930 140567322951680 alphageometry.py:567] Translation: "m = on_bline m d l, on_bline m e d"

I0123 18:40:48.979971 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m d l, on_bline m e d ? perp a c c k"
I0123 18:40:48.980149 140567322951680 graph.py:498] 
I0123 18:40:48.980214 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m d l, on_bline m e d ? perp a c c k
I0123 18:40:51.587227 140567322951680 ddar.py:60] Depth 1/1000 time = 2.5612127780914307
I0123 18:40:59.881313 140567322951680 ddar.py:60] Depth 2/1000 time = 8.29377818107605
I0123 18:41:09.310381 140567322951680 ddar.py:60] Depth 3/1000 time = 9.428836822509766
I0123 18:41:18.888297 140567322951680 ddar.py:60] Depth 4/1000 time = 9.57762336730957
I0123 18:41:28.357636 140567322951680 ddar.py:60] Depth 5/1000 time = 9.469091415405273
I0123 18:41:38.609516 140567322951680 ddar.py:60] Depth 6/1000 time = 10.251073360443115
I0123 18:41:49.743657 140567322951680 ddar.py:60] Depth 7/1000 time = 11.096757411956787
I0123 18:42:01.181972 140567322951680 ddar.py:60] Depth 8/1000 time = 11.437990665435791
I0123 18:42:14.203563 140567322951680 ddar.py:60] Depth 9/1000 time = 13.02137804031372
I0123 18:42:14.230983 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:42:14.231049 140567322951680 alphageometry.py:566] LM output (score=-2.393723): "m : C e g m 18 D e m g m 19 ;"
I0123 18:42:14.231086 140567322951680 alphageometry.py:567] Translation: "m = on_line m e g, on_bline m g e"

I0123 18:42:14.231123 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m e g, on_bline m g e ? perp a c c k"
I0123 18:42:14.231288 140567322951680 graph.py:498] 
I0123 18:42:14.231348 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m e g, on_bline m g e ? perp a c c k
I0123 18:42:15.244040 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9769587516784668
I0123 18:42:22.801802 140567322951680 ddar.py:60] Depth 2/1000 time = 7.557605504989624
I0123 18:42:32.349736 140567322951680 ddar.py:60] Depth 3/1000 time = 9.547721147537231
I0123 18:42:41.890551 140567322951680 ddar.py:60] Depth 4/1000 time = 9.54059624671936
I0123 18:42:51.494128 140567322951680 ddar.py:60] Depth 5/1000 time = 9.603357315063477
I0123 18:43:01.087261 140567322951680 ddar.py:60] Depth 6/1000 time = 9.592361688613892
I0123 18:43:01.129090 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:43:01.129199 140567322951680 alphageometry.py:566] LM output (score=-2.561687): "m : C a e m 18 C c l m 19 ;"
I0123 18:43:01.129240 140567322951680 alphageometry.py:567] Translation: "m = on_line m a e, on_line m c l"

I0123 18:43:01.129292 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m a e, on_line m c l ? perp a c c k"
I0123 18:43:01.129483 140567322951680 graph.py:498] 
I0123 18:43:01.129549 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m a e, on_line m c l ? perp a c c k
I0123 18:43:02.124162 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9659326076507568
I0123 18:43:10.635974 140567322951680 ddar.py:60] Depth 2/1000 time = 8.511641025543213
I0123 18:43:20.172806 140567322951680 ddar.py:60] Depth 3/1000 time = 9.53658938407898
I0123 18:43:30.669368 140567322951680 ddar.py:60] Depth 4/1000 time = 10.496234893798828
I0123 18:43:40.693069 140567322951680 ddar.py:60] Depth 5/1000 time = 10.023454189300537
I0123 18:43:50.805533 140567322951680 ddar.py:60] Depth 6/1000 time = 10.112133026123047
I0123 18:44:01.684197 140567322951680 ddar.py:60] Depth 7/1000 time = 10.878449440002441
I0123 18:44:11.768898 140567322951680 ddar.py:60] Depth 8/1000 time = 10.084009408950806
I0123 18:44:11.818012 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:44:11.818074 140567322951680 alphageometry.py:566] LM output (score=-2.589342): "m : D e m l m 18 ;"
I0123 18:44:11.818110 140567322951680 alphageometry.py:567] Translation: "m = on_bline m l e"

I0123 18:44:11.818145 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m l e ? perp a c c k"
I0123 18:44:11.818306 140567322951680 graph.py:498] 
I0123 18:44:11.818365 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m l e ? perp a c c k
I0123 18:44:12.792317 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9356687068939209
I0123 18:44:20.256625 140567322951680 ddar.py:60] Depth 2/1000 time = 7.4641499519348145
I0123 18:44:29.432632 140567322951680 ddar.py:60] Depth 3/1000 time = 9.1758131980896
I0123 18:44:39.584470 140567322951680 ddar.py:60] Depth 4/1000 time = 10.151620864868164
I0123 18:44:48.089454 140567322951680 ddar.py:60] Depth 5/1000 time = 8.504793167114258
I0123 18:44:58.204028 140567322951680 ddar.py:60] Depth 6/1000 time = 10.1139235496521
I0123 18:45:06.848047 140567322951680 ddar.py:60] Depth 7/1000 time = 8.617005348205566
I0123 18:45:06.864761 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:45:06.864860 140567322951680 alphageometry.py:566] LM output (score=-2.593908): "m : D c e l m 18 P c e l m 19 ;"
I0123 18:45:06.864899 140567322951680 alphageometry.py:567] Translation: "m = eqdistance m l c e, on_pline m l c e"

I0123 18:45:06.864938 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m l c e, on_pline m l c e ? perp a c c k"
I0123 18:45:06.865111 140567322951680 graph.py:498] 
I0123 18:45:06.865175 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m l c e, on_pline m l c e ? perp a c c k
I0123 18:45:08.622815 140567322951680 ddar.py:60] Depth 1/1000 time = 1.7190890312194824
I0123 18:45:17.362934 140567322951680 ddar.py:60] Depth 2/1000 time = 8.739930868148804
I0123 18:45:30.575381 140567322951680 ddar.py:60] Depth 3/1000 time = 13.212197303771973
I0123 18:45:44.013929 140567322951680 ddar.py:60] Depth 4/1000 time = 13.438246250152588
I0123 18:45:57.569744 140567322951680 ddar.py:60] Depth 5/1000 time = 13.555596351623535
I0123 18:46:11.033223 140567322951680 ddar.py:60] Depth 6/1000 time = 13.46268343925476
I0123 18:46:24.622741 140567322951680 ddar.py:60] Depth 7/1000 time = 13.533237934112549
I0123 18:46:24.624902 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:46:24.624988 140567322951680 alphageometry.py:566] LM output (score=-2.686713): "m : D e k e m 18 D f k f m 19 ;"
I0123 18:46:24.625024 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k, on_circle m f k"

I0123 18:46:24.625074 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m f k ? perp a c c k"
I0123 18:46:24.625264 140567322951680 graph.py:498] 
I0123 18:46:24.625327 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m f k ? perp a c c k
I0123 18:46:25.677609 140567322951680 ddar.py:60] Depth 1/1000 time = 1.01017427444458
I0123 18:46:34.143910 140567322951680 ddar.py:60] Depth 2/1000 time = 8.466135501861572
I0123 18:46:46.605290 140567322951680 ddar.py:60] Depth 3/1000 time = 12.461073160171509
I0123 18:46:58.856091 140567322951680 ddar.py:60] Depth 4/1000 time = 12.250359296798706
I0123 18:47:11.849029 140567322951680 ddar.py:60] Depth 5/1000 time = 12.992639541625977
I0123 18:47:24.088197 140567322951680 ddar.py:60] Depth 6/1000 time = 12.23822569847107
I0123 18:47:37.075066 140567322951680 ddar.py:60] Depth 7/1000 time = 12.950523614883423
I0123 18:47:50.430658 140567322951680 ddar.py:60] Depth 8/1000 time = 13.28917384147644
I0123 18:47:50.433255 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:47:50.433315 140567322951680 alphageometry.py:566] LM output (score=-2.686927): "m : D e j l m 18 D e l j m 19 ;"
I0123 18:47:50.433350 140567322951680 alphageometry.py:567] Translation: "m = eqdistance m l e j, eqdistance m j e l"

I0123 18:47:50.433388 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m l e j, eqdistance m j e l ? perp a c c k"
I0123 18:47:50.433555 140567322951680 graph.py:498] 
I0123 18:47:50.433615 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m l e j, eqdistance m j e l ? perp a c c k
I0123 18:47:51.444268 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9688878059387207
I0123 18:47:59.123898 140567322951680 ddar.py:60] Depth 2/1000 time = 7.679438352584839
I0123 18:48:08.726274 140567322951680 ddar.py:60] Depth 3/1000 time = 9.602086782455444
I0123 18:48:19.317892 140567322951680 ddar.py:60] Depth 4/1000 time = 10.591367959976196
I0123 18:48:31.356131 140567322951680 ddar.py:60] Depth 5/1000 time = 12.037927150726318
I0123 18:48:43.633555 140567322951680 ddar.py:60] Depth 6/1000 time = 12.277209520339966
I0123 18:48:55.124020 140567322951680 ddar.py:60] Depth 7/1000 time = 11.489713191986084
I0123 18:48:55.179576 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:48:55.179691 140567322951680 alphageometry.py:566] LM output (score=-2.755425): "m : D j k j m 18 ;"
I0123 18:48:55.179730 140567322951680 alphageometry.py:567] Translation: "m = on_circle m j k"

I0123 18:48:55.179781 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m j k ? perp a c c k"
I0123 18:48:55.179971 140567322951680 graph.py:498] 
I0123 18:48:55.180034 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m j k ? perp a c c k
I0123 18:48:56.123772 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9090468883514404
I0123 18:49:03.719470 140567322951680 ddar.py:60] Depth 2/1000 time = 7.595521450042725
I0123 18:49:12.032387 140567322951680 ddar.py:60] Depth 3/1000 time = 8.31273078918457
I0123 18:49:22.177075 140567322951680 ddar.py:60] Depth 4/1000 time = 10.144484758377075
I0123 18:49:30.756960 140567322951680 ddar.py:60] Depth 5/1000 time = 8.5796377658844
I0123 18:49:40.124671 140567322951680 ddar.py:60] Depth 6/1000 time = 9.366913318634033
I0123 18:49:40.163697 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:49:40.163777 140567322951680 alphageometry.py:566] LM output (score=-2.763999): "m : D l m e m 18 D e m f m 19 ;"
I0123 18:49:40.163815 140567322951680 alphageometry.py:567] Translation: "m = on_bline m e l, on_bline m f e"

I0123 18:49:40.163861 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m e l, on_bline m f e ? perp a c c k"
I0123 18:49:40.164040 140567322951680 graph.py:498] 
I0123 18:49:40.164106 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m e l, on_bline m f e ? perp a c c k
I0123 18:49:44.237573 140567322951680 ddar.py:60] Depth 1/1000 time = 4.028381586074829
I0123 18:49:51.266566 140567322951680 ddar.py:60] Depth 2/1000 time = 7.028728485107422
I0123 18:50:01.672822 140567322951680 ddar.py:60] Depth 3/1000 time = 10.405940771102905
I0123 18:50:10.629947 140567322951680 ddar.py:60] Depth 4/1000 time = 8.956872940063477
I0123 18:50:21.079393 140567322951680 ddar.py:60] Depth 5/1000 time = 10.449121475219727
I0123 18:50:29.975538 140567322951680 ddar.py:60] Depth 6/1000 time = 8.895394563674927
I0123 18:50:40.414529 140567322951680 ddar.py:60] Depth 7/1000 time = 10.43418025970459
I0123 18:50:51.752722 140567322951680 ddar.py:60] Depth 8/1000 time = 11.306254625320435
I0123 18:51:02.792640 140567322951680 ddar.py:60] Depth 9/1000 time = 11.039710283279419
I0123 18:51:14.839186 140567322951680 ddar.py:60] Depth 10/1000 time = 12.046329021453857
I0123 18:51:27.167100 140567322951680 ddar.py:60] Depth 11/1000 time = 12.327679634094238
I0123 18:51:38.775830 140567322951680 ddar.py:60] Depth 12/1000 time = 11.576714515686035
I0123 18:51:38.776075 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:51:38.776144 140567322951680 alphageometry.py:566] LM output (score=-2.771543): "m : D h k k m 18 ;"
I0123 18:51:38.776189 140567322951680 alphageometry.py:567] Translation: "m = on_circle m k h"

I0123 18:51:38.776229 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k h ? perp a c c k"
I0123 18:51:38.776408 140567322951680 graph.py:498] 
I0123 18:51:38.776469 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k h ? perp a c c k
I0123 18:51:39.705528 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8956623077392578
I0123 18:51:46.513879 140567322951680 ddar.py:60] Depth 2/1000 time = 6.808199644088745
I0123 18:51:55.793176 140567322951680 ddar.py:60] Depth 3/1000 time = 9.279099225997925
I0123 18:52:05.287394 140567322951680 ddar.py:60] Depth 4/1000 time = 9.494014263153076
I0123 18:52:14.732449 140567322951680 ddar.py:60] Depth 5/1000 time = 9.444851160049438
I0123 18:52:24.225888 140567322951680 ddar.py:60] Depth 6/1000 time = 9.492716312408447
I0123 18:52:24.265496 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:52:24.265582 140567322951680 alphageometry.py:566] LM output (score=-2.836575): "m : D e k g m 18 P e k g m 19 ;"
I0123 18:52:24.265621 140567322951680 alphageometry.py:567] Translation: "m = eqdistance m g e k, on_pline m g e k"

I0123 18:52:24.265666 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m g e k, on_pline m g e k ? perp a c c k"
I0123 18:52:24.265837 140567322951680 graph.py:498] 
I0123 18:52:24.265899 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = eqdistance m g e k, on_pline m g e k ? perp a c c k
I0123 18:52:25.268547 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9625692367553711
I0123 18:52:33.123772 140567322951680 ddar.py:60] Depth 2/1000 time = 7.855085611343384
I0123 18:52:43.059954 140567322951680 ddar.py:60] Depth 3/1000 time = 9.935976266860962
I0123 18:52:53.039989 140567322951680 ddar.py:60] Depth 4/1000 time = 9.979820013046265
I0123 18:53:03.072715 140567322951680 ddar.py:60] Depth 5/1000 time = 10.032509088516235
I0123 18:53:12.176626 140567322951680 ddar.py:60] Depth 6/1000 time = 9.103254318237305
I0123 18:53:12.219305 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:53:12.219398 140567322951680 alphageometry.py:566] LM output (score=-2.863454): "m : D e k k m 18 ;"
I0123 18:53:12.219437 140567322951680 alphageometry.py:567] Translation: "m = on_circle m k e"

I0123 18:53:12.219480 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k e ? perp a c c k"
I0123 18:53:12.219660 140567322951680 graph.py:498] 
I0123 18:53:12.219722 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k e ? perp a c c k
I0123 18:53:13.921917 140567322951680 ddar.py:60] Depth 1/1000 time = 1.6685025691986084
I0123 18:53:21.597887 140567322951680 ddar.py:60] Depth 2/1000 time = 7.675675392150879
I0123 18:53:31.241415 140567322951680 ddar.py:60] Depth 3/1000 time = 9.643354654312134
I0123 18:53:40.189343 140567322951680 ddar.py:60] Depth 4/1000 time = 8.947712898254395
I0123 18:53:49.750162 140567322951680 ddar.py:60] Depth 5/1000 time = 9.560625553131104
I0123 18:53:59.402533 140567322951680 ddar.py:60] Depth 6/1000 time = 9.65164041519165
I0123 18:53:59.442281 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:53:59.442344 140567322951680 alphageometry.py:566] LM output (score=-2.880162): "m : D e k e m 18 ;"
I0123 18:53:59.442380 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k"

I0123 18:53:59.442417 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k ? perp a c c k"
I0123 18:53:59.442578 140567322951680 graph.py:498] 
I0123 18:53:59.442639 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k ? perp a c c k
I0123 18:54:00.389875 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9132428169250488
I0123 18:54:08.048379 140567322951680 ddar.py:60] Depth 2/1000 time = 7.658364772796631
I0123 18:54:16.836090 140567322951680 ddar.py:60] Depth 3/1000 time = 8.787503480911255
I0123 18:54:27.309212 140567322951680 ddar.py:60] Depth 4/1000 time = 10.472901821136475
I0123 18:54:36.265699 140567322951680 ddar.py:60] Depth 5/1000 time = 8.95626163482666
I0123 18:54:45.939627 140567322951680 ddar.py:60] Depth 6/1000 time = 9.673187255859375
I0123 18:54:45.980478 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:54:45.980575 140567322951680 alphageometry.py:566] LM output (score=-2.921341): "m : D e k e m 18 D h k h m 19 ;"
I0123 18:54:45.980611 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k, on_circle m h k"

I0123 18:54:45.980659 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m h k ? perp a c c k"
I0123 18:54:45.980847 140567322951680 graph.py:498] 
I0123 18:54:45.980906 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m h k ? perp a c c k
I0123 18:54:47.020346 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9986593723297119
I0123 18:54:55.602072 140567322951680 ddar.py:60] Depth 2/1000 time = 8.581582307815552
I0123 18:55:07.461246 140567322951680 ddar.py:60] Depth 3/1000 time = 11.85886001586914
I0123 18:55:20.825462 140567322951680 ddar.py:60] Depth 4/1000 time = 13.363770723342896
I0123 18:55:33.405754 140567322951680 ddar.py:60] Depth 5/1000 time = 12.57992148399353
I0123 18:55:46.099018 140567322951680 ddar.py:60] Depth 6/1000 time = 12.69225287437439
I0123 18:55:57.874952 140567322951680 ddar.py:60] Depth 7/1000 time = 11.73721432685852
I0123 18:56:11.472110 140567322951680 ddar.py:60] Depth 8/1000 time = 13.533101320266724
I0123 18:56:11.474541 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:56:11.474613 140567322951680 alphageometry.py:566] LM output (score=-2.932472): "m : D e m k m 18 D f m k m 19 ;"
I0123 18:56:11.474652 140567322951680 alphageometry.py:567] Translation: "ERROR: Traceback (most recent call last):
  File "/home/chi/alphageometry-test/alphageometry.py", line 438, in try_translate_constrained_to_construct
    g.copy().add_clause(clause, 0, DEFINITIONS)
  File "/home/chi/alphageometry-test/graph.py", line 2637, in add_clause
    raise PointTooFarError()
graph.PointTooFarError
"

I0123 18:56:11.474691 140567322951680 alphageometry.py:566] LM output (score=-2.944305): "m : D e h e m 18 ;"
I0123 18:56:11.474719 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e h"

I0123 18:56:11.474750 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e h ? perp a c c k"
I0123 18:56:11.474909 140567322951680 graph.py:498] 
I0123 18:56:11.474975 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e h ? perp a c c k
I0123 18:56:12.424813 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9161086082458496
I0123 18:56:20.081478 140567322951680 ddar.py:60] Depth 2/1000 time = 7.656492471694946
I0123 18:56:29.444685 140567322951680 ddar.py:60] Depth 3/1000 time = 9.362975835800171
I0123 18:56:38.229366 140567322951680 ddar.py:60] Depth 4/1000 time = 8.784417867660522
I0123 18:56:47.743826 140567322951680 ddar.py:60] Depth 5/1000 time = 9.514133930206299
I0123 18:56:57.316250 140567322951680 ddar.py:60] Depth 6/1000 time = 9.571690320968628
I0123 18:56:57.355049 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:56:57.355117 140567322951680 alphageometry.py:566] LM output (score=-2.964815): "m : D b h b m 18 ;"
I0123 18:56:57.355153 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b h"

I0123 18:56:57.355193 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b h ? perp a c c k"
I0123 18:56:57.355353 140567322951680 graph.py:498] 
I0123 18:56:57.355413 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b h ? perp a c c k
I0123 18:56:59.004691 140567322951680 ddar.py:60] Depth 1/1000 time = 1.615400791168213
I0123 18:57:05.820282 140567322951680 ddar.py:60] Depth 2/1000 time = 6.815413236618042
I0123 18:57:15.236273 140567322951680 ddar.py:60] Depth 3/1000 time = 9.415785789489746
I0123 18:57:24.829381 140567322951680 ddar.py:60] Depth 4/1000 time = 9.592869758605957
I0123 18:57:35.439333 140567322951680 ddar.py:60] Depth 5/1000 time = 10.609742879867554
I0123 18:57:44.395789 140567322951680 ddar.py:60] Depth 6/1000 time = 8.955786228179932
I0123 18:57:44.437508 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:57:44.437575 140567322951680 alphageometry.py:566] LM output (score=-2.986841): "m : C e h m 18 D e h e m 19 ;"
I0123 18:57:44.437612 140567322951680 alphageometry.py:567] Translation: "m = on_line m e h, on_circle m e h"

I0123 18:57:44.437655 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m e h, on_circle m e h ? perp a c c k"
I0123 18:57:44.437829 140567322951680 graph.py:498] 
I0123 18:57:44.437891 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_line m e h, on_circle m e h ? perp a c c k
I0123 18:57:45.731797 140567322951680 ddar.py:60] Depth 1/1000 time = 1.2590827941894531
I0123 18:57:59.355972 140567322951680 ddar.py:60] Depth 2/1000 time = 13.624016761779785
I0123 18:58:15.100928 140567322951680 ddar.py:60] Depth 3/1000 time = 15.744744777679443
I0123 18:58:30.113734 140567322951680 ddar.py:60] Depth 4/1000 time = 15.01255464553833
I0123 18:58:46.708063 140567322951680 ddar.py:60] Depth 5/1000 time = 16.593985557556152
I0123 18:59:02.572039 140567322951680 ddar.py:60] Depth 6/1000 time = 15.863610982894897
I0123 18:59:18.381826 140567322951680 ddar.py:60] Depth 7/1000 time = 15.809040546417236
I0123 18:59:35.210387 140567322951680 ddar.py:60] Depth 8/1000 time = 16.794196844100952
I0123 18:59:50.264244 140567322951680 ddar.py:60] Depth 9/1000 time = 15.030324697494507
I0123 18:59:50.266835 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 18:59:50.266896 140567322951680 alphageometry.py:566] LM output (score=-3.022779): "m : T c h c m 18 ;"
I0123 18:59:50.266931 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c h"

I0123 18:59:50.266970 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_tline m c c h ? perp a c c k"
I0123 18:59:50.267131 140567322951680 graph.py:498] 
I0123 18:59:50.267190 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_tline m c c h ? perp a c c k
I0123 18:59:51.957103 140567322951680 ddar.py:60] Depth 1/1000 time = 1.6555156707763672
I0123 18:59:59.920956 140567322951680 ddar.py:60] Depth 2/1000 time = 7.963676452636719
I0123 19:00:09.095620 140567322951680 ddar.py:60] Depth 3/1000 time = 9.174450397491455
I0123 19:00:20.348591 140567322951680 ddar.py:60] Depth 4/1000 time = 11.252749919891357
I0123 19:00:29.777117 140567322951680 ddar.py:60] Depth 5/1000 time = 9.428307294845581
I0123 19:00:40.984385 140567322951680 ddar.py:60] Depth 6/1000 time = 11.206559896469116
I0123 19:00:41.023933 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:00:41.024041 140567322951680 alphageometry.py:566] LM output (score=-3.061844): "m : C e h m 18 P e f h m 19 ;"
I0123 19:00:41.024081 140567322951680 alphageometry.py:567] Translation: "ERROR: Traceback (most recent call last):
  File "/home/chi/alphageometry-test/alphageometry.py", line 438, in try_translate_constrained_to_construct
    g.copy().add_clause(clause, 0, DEFINITIONS)
  File "/home/chi/alphageometry-test/graph.py", line 2570, in add_clause
    raise DepCheckFailError(
graph.DepCheckFailError: ncoll h e f
"

I0123 19:00:41.024140 140567322951680 alphageometry.py:566] LM output (score=-3.078020): "m : D c h c m 18 D f h f m 19 ;"
I0123 19:00:41.024172 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m f h"

I0123 19:00:41.024208 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m c h, on_circle m f h ? perp a c c k"
I0123 19:00:41.024386 140567322951680 graph.py:498] 
I0123 19:00:41.024446 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m c h, on_circle m f h ? perp a c c k
I0123 19:00:42.042999 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9766700267791748
I0123 19:00:49.398388 140567322951680 ddar.py:60] Depth 2/1000 time = 7.355236053466797
I0123 19:01:01.366311 140567322951680 ddar.py:60] Depth 3/1000 time = 11.967708110809326
I0123 19:01:14.152928 140567322951680 ddar.py:60] Depth 4/1000 time = 12.78633999824524
I0123 19:01:26.848181 140567322951680 ddar.py:60] Depth 5/1000 time = 12.695024967193604
I0123 19:01:38.830443 140567322951680 ddar.py:60] Depth 6/1000 time = 11.98203420639038
I0123 19:01:51.760312 140567322951680 ddar.py:60] Depth 7/1000 time = 12.929033041000366
I0123 19:01:51.811380 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:01:51.811446 140567322951680 alphageometry.py:566] LM output (score=-3.080930): "m : D e k e m 18 D g k g m 19 ;"
I0123 19:01:51.811482 140567322951680 alphageometry.py:567] Translation: "m = on_circle m e k, on_circle m g k"

I0123 19:01:51.811519 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m g k ? perp a c c k"
I0123 19:01:51.811684 140567322951680 graph.py:498] 
I0123 19:01:51.811744 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m e k, on_circle m g k ? perp a c c k
I0123 19:01:52.836802 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9841873645782471
I0123 19:02:00.255139 140567322951680 ddar.py:60] Depth 2/1000 time = 7.418168783187866
I0123 19:02:10.759159 140567322951680 ddar.py:60] Depth 3/1000 time = 10.503769874572754
I0123 19:02:21.350887 140567322951680 ddar.py:60] Depth 4/1000 time = 10.59146761894226
I0123 19:02:31.073873 140567322951680 ddar.py:60] Depth 5/1000 time = 9.722673654556274
I0123 19:02:41.621774 140567322951680 ddar.py:60] Depth 6/1000 time = 10.547186851501465
I0123 19:02:41.675207 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:02:41.675318 140567322951680 alphageometry.py:566] LM output (score=-3.093706): "m : D b e b m 18 D e g g m 19 ;"
I0123 19:02:41.675358 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m g e"

I0123 19:02:41.675414 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m g e ? perp a c c k"
I0123 19:02:41.675612 140567322951680 graph.py:498] 
I0123 19:02:41.675672 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m g e ? perp a c c k
I0123 19:02:43.636234 140567322951680 ddar.py:60] Depth 1/1000 time = 1.9221479892730713
I0123 19:02:53.084696 140567322951680 ddar.py:60] Depth 2/1000 time = 9.448284387588501
I0123 19:03:07.551428 140567322951680 ddar.py:60] Depth 3/1000 time = 14.46651816368103
I0123 19:03:21.813191 140567322951680 ddar.py:60] Depth 4/1000 time = 14.261459350585938
I0123 19:03:37.042582 140567322951680 ddar.py:60] Depth 5/1000 time = 15.229065418243408
I0123 19:03:50.360357 140567322951680 ddar.py:60] Depth 6/1000 time = 13.31754755973816
I0123 19:04:05.349775 140567322951680 ddar.py:60] Depth 7/1000 time = 14.988632917404175
I0123 19:04:05.441354 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:04:05.441446 140567322951680 alphageometry.py:566] LM output (score=-3.093714): "m : D b e b m 18 D e h h m 19 ;"
I0123 19:04:05.441485 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m h e"

I0123 19:04:05.441533 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m h e ? perp a c c k"
I0123 19:04:05.441713 140567322951680 graph.py:498] 
I0123 19:04:05.441777 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m h e ? perp a c c k
I0123 19:04:06.533340 140567322951680 ddar.py:60] Depth 1/1000 time = 1.0532424449920654
I0123 19:04:16.125934 140567322951680 ddar.py:60] Depth 2/1000 time = 9.59245252609253
I0123 19:04:29.271907 140567322951680 ddar.py:60] Depth 3/1000 time = 13.145766973495483
I0123 19:04:42.972415 140567322951680 ddar.py:60] Depth 4/1000 time = 13.70026159286499
I0123 19:04:55.667280 140567322951680 ddar.py:60] Depth 5/1000 time = 12.694589138031006
I0123 19:05:09.305292 140567322951680 ddar.py:60] Depth 6/1000 time = 13.637796401977539
I0123 19:05:22.929859 140567322951680 ddar.py:60] Depth 7/1000 time = 13.62382960319519
I0123 19:05:36.536963 140567322951680 ddar.py:60] Depth 8/1000 time = 13.542367219924927
I0123 19:05:36.539497 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:05:36.539600 140567322951680 alphageometry.py:566] LM output (score=-3.143660): "m : D b e b m 18 D d e d m 19 ;"
I0123 19:05:36.539638 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b e, on_circle m d e"

I0123 19:05:36.539683 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m d e ? perp a c c k"
I0123 19:05:36.539870 140567322951680 graph.py:498] 
I0123 19:05:36.539931 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m b e, on_circle m d e ? perp a c c k
I0123 19:05:38.506778 140567322951680 ddar.py:60] Depth 1/1000 time = 1.9279463291168213
I0123 19:05:46.109448 140567322951680 ddar.py:60] Depth 2/1000 time = 7.602423429489136
I0123 19:05:56.793555 140567322951680 ddar.py:60] Depth 3/1000 time = 10.68391227722168
I0123 19:06:07.913367 140567322951680 ddar.py:60] Depth 4/1000 time = 11.119566202163696
I0123 19:06:18.163547 140567322951680 ddar.py:60] Depth 5/1000 time = 10.249938488006592
I0123 19:06:29.246308 140567322951680 ddar.py:60] Depth 6/1000 time = 11.08193588256836
I0123 19:06:29.303855 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:06:29.303922 140567322951680 alphageometry.py:566] LM output (score=-3.160125): "m : D e m j m 18 D e m k m 19 ;"
I0123 19:06:29.303959 140567322951680 alphageometry.py:567] Translation: "m = on_bline m j e, on_bline m k e"

I0123 19:06:29.303996 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m j e, on_bline m k e ? perp a c c k"
I0123 19:06:29.304166 140567322951680 graph.py:498] 
I0123 19:06:29.304231 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_bline m j e, on_bline m k e ? perp a c c k
I0123 19:06:32.827857 140567322951680 ddar.py:60] Depth 1/1000 time = 3.4784772396087646
I0123 19:06:40.183976 140567322951680 ddar.py:60] Depth 2/1000 time = 7.355929136276245
I0123 19:06:50.208784 140567322951680 ddar.py:60] Depth 3/1000 time = 10.024593353271484
I0123 19:07:00.523351 140567322951680 ddar.py:60] Depth 4/1000 time = 10.31434178352356
I0123 19:07:09.780403 140567322951680 ddar.py:60] Depth 5/1000 time = 9.256819725036621
I0123 19:07:19.960259 140567322951680 ddar.py:60] Depth 6/1000 time = 10.17908000946045
I0123 19:07:30.197500 140567322951680 ddar.py:60] Depth 7/1000 time = 10.236371755599976
I0123 19:07:39.631577 140567322951680 ddar.py:60] Depth 8/1000 time = 9.433812856674194
I0123 19:07:49.828249 140567322951680 ddar.py:60] Depth 9/1000 time = 10.196391105651855
I0123 19:08:00.230639 140567322951680 ddar.py:60] Depth 10/1000 time = 10.40216064453125
I0123 19:08:10.795957 140567322951680 ddar.py:60] Depth 11/1000 time = 10.534619808197021
I0123 19:08:20.647475 140567322951680 ddar.py:60] Depth 12/1000 time = 9.851311206817627
I0123 19:08:31.404506 140567322951680 ddar.py:60] Depth 13/1000 time = 10.756808042526245
I0123 19:08:42.394534 140567322951680 ddar.py:60] Depth 14/1000 time = 10.960062503814697
I0123 19:08:42.394933 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:08:42.395016 140567322951680 alphageometry.py:566] LM output (score=-3.176502): "m : D i k k m 18 ;"
I0123 19:08:42.395051 140567322951680 alphageometry.py:567] Translation: "m = on_circle m k i"

I0123 19:08:42.395099 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k i ? perp a c c k"
I0123 19:08:42.395308 140567322951680 graph.py:498] 
I0123 19:08:42.395373 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_line l a b, on_bline l b a; m = on_circle m k i ? perp a c c k
I0123 19:08:43.347750 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9177885055541992
I0123 19:08:51.735582 140567322951680 ddar.py:60] Depth 2/1000 time = 8.387580156326294
I0123 19:09:01.032083 140567322951680 ddar.py:60] Depth 3/1000 time = 9.296109199523926
I0123 19:09:10.233789 140567322951680 ddar.py:60] Depth 4/1000 time = 9.201287984848022
I0123 19:09:20.398652 140567322951680 ddar.py:60] Depth 5/1000 time = 10.164517402648926
I0123 19:09:29.608587 140567322951680 ddar.py:60] Depth 6/1000 time = 9.209208488464355
I0123 19:09:29.647506 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:09:29.647603 140567322951680 alphageometry.py:549] Decoding from {S} a : ; b : ; c : ; d : C a c d 00 D a d c d 01 ; e : C b c e 02 D b e c e 03 ; f : C a b f 04 T b e e f 05 ; g : C a b g 06 T a d d g 07 ; h : C e f h 08 T b f b h 09 ; i : C d g i 10 T a g a i 11 ; j : C b c j 12 T a j b c 13 ; k : C a j k 14 C h i k 15 ? T a c c k {F1} x00 l : P a b c l 16 ; x00
I0123 19:09:36.578308 140567322951680 alphageometry.py:566] LM output (score=-1.653228): "m : T c l c m 17 ;"
I0123 19:09:36.578591 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c l"

I0123 19:09:36.578654 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c l ? perp a c c k"
I0123 19:09:36.578828 140567322951680 graph.py:498] 
I0123 19:09:36.578894 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c l ? perp a c c k
I0123 19:09:37.292104 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6798465251922607
I0123 19:09:41.217480 140567322951680 ddar.py:60] Depth 2/1000 time = 3.92525577545166
I0123 19:09:46.254648 140567322951680 ddar.py:60] Depth 3/1000 time = 5.036975383758545
I0123 19:09:51.276259 140567322951680 ddar.py:60] Depth 4/1000 time = 5.021412134170532
I0123 19:09:56.319964 140567322951680 ddar.py:60] Depth 5/1000 time = 5.04299783706665
I0123 19:10:01.538480 140567322951680 ddar.py:60] Depth 6/1000 time = 5.192481517791748
I0123 19:10:01.538706 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:10:01.538775 140567322951680 alphageometry.py:566] LM output (score=-1.917233): "m : D a b a m 17 D a b b m 18 ;"
I0123 19:10:01.538812 140567322951680 alphageometry.py:567] Translation: "m = on_circle m a b, on_circle m b a"

I0123 19:10:01.538851 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m a b, on_circle m b a ? perp a c c k"
I0123 19:10:01.539027 140567322951680 graph.py:498] 
I0123 19:10:01.539093 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m a b, on_circle m b a ? perp a c c k
I0123 19:10:02.268025 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6939506530761719
I0123 19:10:06.727772 140567322951680 ddar.py:60] Depth 2/1000 time = 4.459626197814941
I0123 19:10:11.671967 140567322951680 ddar.py:60] Depth 3/1000 time = 4.944010019302368
I0123 19:10:16.725958 140567322951680 ddar.py:60] Depth 4/1000 time = 5.053764343261719
I0123 19:10:20.762350 140567322951680 ddar.py:60] Depth 5/1000 time = 4.035763502120972
I0123 19:10:25.670443 140567322951680 ddar.py:60] Depth 6/1000 time = 4.90644907951355
I0123 19:10:30.780295 140567322951680 ddar.py:60] Depth 7/1000 time = 5.08506441116333
I0123 19:10:30.780616 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:10:30.780697 140567322951680 alphageometry.py:566] LM output (score=-2.114129): "m : C e h m 17 D e h e m 18 ;"
I0123 19:10:30.780733 140567322951680 alphageometry.py:567] Translation: "m = on_line m e h, on_circle m e h"

I0123 19:10:30.780782 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e h, on_circle m e h ? perp a c c k"
I0123 19:10:30.780961 140567322951680 graph.py:498] 
I0123 19:10:30.781023 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e h, on_circle m e h ? perp a c c k
I0123 19:10:31.767872 140567322951680 ddar.py:60] Depth 1/1000 time = 0.9545495510101318
I0123 19:10:40.484618 140567322951680 ddar.py:60] Depth 2/1000 time = 8.716594219207764
I0123 19:10:48.945376 140567322951680 ddar.py:60] Depth 3/1000 time = 8.460553646087646
I0123 19:10:57.418531 140567322951680 ddar.py:60] Depth 4/1000 time = 8.472892761230469
I0123 19:11:06.816670 140567322951680 ddar.py:60] Depth 5/1000 time = 9.397444248199463
I0123 19:11:15.430304 140567322951680 ddar.py:60] Depth 6/1000 time = 8.586729288101196
I0123 19:11:24.111375 140567322951680 ddar.py:60] Depth 7/1000 time = 8.671170711517334
I0123 19:11:24.111608 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:11:24.111680 140567322951680 alphageometry.py:566] LM output (score=-2.148412): "m : C e g m 17 D e m g m 18 ;"
I0123 19:11:24.111717 140567322951680 alphageometry.py:567] Translation: "m = on_line m e g, on_bline m g e"

I0123 19:11:24.111757 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e g, on_bline m g e ? perp a c c k"
I0123 19:11:24.111930 140567322951680 graph.py:498] 
I0123 19:11:24.111995 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e g, on_bline m g e ? perp a c c k
I0123 19:11:24.848042 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7041416168212891
I0123 19:11:29.673248 140567322951680 ddar.py:60] Depth 2/1000 time = 4.825047492980957
I0123 19:11:33.765011 140567322951680 ddar.py:60] Depth 3/1000 time = 4.091482877731323
I0123 19:11:38.649565 140567322951680 ddar.py:60] Depth 4/1000 time = 4.884347915649414
I0123 19:11:44.308468 140567322951680 ddar.py:60] Depth 5/1000 time = 5.65813136100769
I0123 19:11:49.891836 140567322951680 ddar.py:60] Depth 6/1000 time = 5.557525634765625
I0123 19:11:49.892220 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:11:49.892309 140567322951680 alphageometry.py:566] LM output (score=-2.318499): "m : D b h b m 17 ;"
I0123 19:11:49.892347 140567322951680 alphageometry.py:567] Translation: "m = on_circle m b h"

I0123 19:11:49.892402 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m b h ? perp a c c k"
I0123 19:11:49.892593 140567322951680 graph.py:498] 
I0123 19:11:49.892658 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m b h ? perp a c c k
I0123 19:11:50.588033 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6576216220855713
I0123 19:11:55.458493 140567322951680 ddar.py:60] Depth 2/1000 time = 4.870166540145874
I0123 19:11:59.538633 140567322951680 ddar.py:60] Depth 3/1000 time = 4.0797929763793945
I0123 19:12:04.482138 140567322951680 ddar.py:60] Depth 4/1000 time = 4.943154811859131
I0123 19:12:09.456328 140567322951680 ddar.py:60] Depth 5/1000 time = 4.973515748977661
I0123 19:12:14.534568 140567322951680 ddar.py:60] Depth 6/1000 time = 5.052877187728882
I0123 19:12:14.534909 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:12:14.534996 140567322951680 alphageometry.py:566] LM output (score=-2.339278): "m : D c e c m 17 D e l l m 18 ;"
I0123 19:12:14.535034 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_circle m l e"

I0123 19:12:14.535091 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m l e ? perp a c c k"
I0123 19:12:14.535286 140567322951680 graph.py:498] 
I0123 19:12:14.535350 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m l e ? perp a c c k
I0123 19:12:15.291417 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7210474014282227
I0123 19:12:20.733575 140567322951680 ddar.py:60] Depth 2/1000 time = 5.442012548446655
I0123 19:12:25.553646 140567322951680 ddar.py:60] Depth 3/1000 time = 4.819844484329224
I0123 19:12:32.220781 140567322951680 ddar.py:60] Depth 4/1000 time = 6.666872262954712
I0123 19:12:37.018993 140567322951680 ddar.py:60] Depth 5/1000 time = 4.797898054122925
I0123 19:12:42.674018 140567322951680 ddar.py:60] Depth 6/1000 time = 5.654371500015259
I0123 19:12:49.431582 140567322951680 ddar.py:60] Depth 7/1000 time = 6.723747730255127
I0123 19:12:49.431810 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:12:49.431877 140567322951680 alphageometry.py:566] LM output (score=-2.501750): "m : C e f m 17 D e m f m 18 ;"
I0123 19:12:49.431914 140567322951680 alphageometry.py:567] Translation: "m = on_line m e f, on_bline m f e"

I0123 19:12:49.431951 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e f, on_bline m f e ? perp a c c k"
I0123 19:12:49.432134 140567322951680 graph.py:498] 
I0123 19:12:49.432198 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e f, on_bline m f e ? perp a c c k
I0123 19:12:50.351826 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8876819610595703
I0123 19:12:57.011222 140567322951680 ddar.py:60] Depth 2/1000 time = 6.659228324890137
I0123 19:13:04.104934 140567322951680 ddar.py:60] Depth 3/1000 time = 7.093414545059204
I0123 19:13:10.280335 140567322951680 ddar.py:60] Depth 4/1000 time = 6.175196409225464
I0123 19:13:17.340816 140567322951680 ddar.py:60] Depth 5/1000 time = 7.0597803592681885
I0123 19:13:24.389488 140567322951680 ddar.py:60] Depth 6/1000 time = 7.0211334228515625
I0123 19:13:24.389727 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:13:24.389806 140567322951680 alphageometry.py:566] LM output (score=-2.660105): "m : D c h c m 17 D f h f m 18 ;"
I0123 19:13:24.389844 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m f h"

I0123 19:13:24.389884 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m f h ? perp a c c k"
I0123 19:13:24.390055 140567322951680 graph.py:498] 
I0123 19:13:24.390123 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m f h ? perp a c c k
I0123 19:13:25.152109 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7238991260528564
I0123 19:13:30.027559 140567322951680 ddar.py:60] Depth 2/1000 time = 4.875304698944092
I0123 19:13:37.088550 140567322951680 ddar.py:60] Depth 3/1000 time = 7.060755729675293
I0123 19:13:43.129322 140567322951680 ddar.py:60] Depth 4/1000 time = 6.0405802726745605
I0123 19:13:49.254104 140567322951680 ddar.py:60] Depth 5/1000 time = 6.124592065811157
I0123 19:13:55.378199 140567322951680 ddar.py:60] Depth 6/1000 time = 6.123880386352539
I0123 19:14:01.454745 140567322951680 ddar.py:60] Depth 7/1000 time = 6.075769662857056
I0123 19:14:07.724962 140567322951680 ddar.py:60] Depth 8/1000 time = 6.240058898925781
I0123 19:14:14.026969 140567322951680 ddar.py:60] Depth 9/1000 time = 6.3017737865448
I0123 19:14:14.029411 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:14:14.029477 140567322951680 alphageometry.py:566] LM output (score=-2.666318): "m : C e h m 17 D e m h m 18 ;"
I0123 19:14:14.029512 140567322951680 alphageometry.py:567] Translation: "m = on_line m e h, on_bline m h e"

I0123 19:14:14.029553 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e h, on_bline m h e ? perp a c c k"
I0123 19:14:14.029721 140567322951680 graph.py:498] 
I0123 19:14:14.029784 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_line m e h, on_bline m h e ? perp a c c k
I0123 19:14:14.938840 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8772087097167969
I0123 19:14:21.541224 140567322951680 ddar.py:60] Depth 2/1000 time = 6.602260589599609
I0123 19:14:28.646342 140567322951680 ddar.py:60] Depth 3/1000 time = 7.104937314987183
I0123 19:14:35.720733 140567322951680 ddar.py:60] Depth 4/1000 time = 7.074180603027344
I0123 19:14:42.692952 140567322951680 ddar.py:60] Depth 5/1000 time = 6.971533298492432
I0123 19:14:50.911228 140567322951680 ddar.py:60] Depth 6/1000 time = 8.187576055526733
I0123 19:14:50.911566 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:14:50.911654 140567322951680 alphageometry.py:566] LM output (score=-2.669584): "m : T c h f m 17 ;"
I0123 19:14:50.911691 140567322951680 alphageometry.py:567] Translation: "m = on_tline m f c h"

I0123 19:14:50.911742 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m f c h ? perp a c c k"
I0123 19:14:50.911920 140567322951680 graph.py:498] 
I0123 19:14:50.911980 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m f c h ? perp a c c k
I0123 19:14:51.577182 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6298990249633789
I0123 19:14:55.431355 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8540446758270264
I0123 19:15:00.644095 140567322951680 ddar.py:60] Depth 3/1000 time = 5.212551593780518
I0123 19:15:05.803748 140567322951680 ddar.py:60] Depth 4/1000 time = 5.159044027328491
I0123 19:15:11.075141 140567322951680 ddar.py:60] Depth 5/1000 time = 5.246626853942871
I0123 19:15:11.075433 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:15:11.075504 140567322951680 alphageometry.py:566] LM output (score=-2.747473): "m : D c l c m 17 D c l l m 18 ;"
I0123 19:15:11.075541 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c l, on_circle m l c"

I0123 19:15:11.075590 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m l c ? perp a c c k"
I0123 19:15:11.075772 140567322951680 graph.py:498] 
I0123 19:15:11.075835 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m l c ? perp a c c k
I0123 19:15:12.710066 140567322951680 ddar.py:60] Depth 1/1000 time = 1.5994818210601807
I0123 19:15:16.516629 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8063881397247314
I0123 19:15:21.543460 140567322951680 ddar.py:60] Depth 3/1000 time = 5.026660203933716
I0123 19:15:26.591551 140567322951680 ddar.py:60] Depth 4/1000 time = 5.047911167144775
I0123 19:15:30.704956 140567322951680 ddar.py:60] Depth 5/1000 time = 4.11275839805603
I0123 19:15:35.676884 140567322951680 ddar.py:60] Depth 6/1000 time = 4.9701268672943115
I0123 19:15:40.781145 140567322951680 ddar.py:60] Depth 7/1000 time = 5.079484224319458
I0123 19:15:40.781370 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:15:40.781435 140567322951680 alphageometry.py:566] LM output (score=-2.783391): "m : T c h l m 17 ;"
I0123 19:15:40.781471 140567322951680 alphageometry.py:567] Translation: "m = on_tline m l c h"

I0123 19:15:40.781508 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m l c h ? perp a c c k"
I0123 19:15:40.781680 140567322951680 graph.py:498] 
I0123 19:15:40.781748 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m l c h ? perp a c c k
I0123 19:15:41.425760 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6092662811279297
I0123 19:15:46.257101 140567322951680 ddar.py:60] Depth 2/1000 time = 4.831218719482422
I0123 19:15:50.385883 140567322951680 ddar.py:60] Depth 3/1000 time = 4.128551483154297
I0123 19:15:55.347564 140567322951680 ddar.py:60] Depth 4/1000 time = 4.961387634277344
I0123 19:16:00.340770 140567322951680 ddar.py:60] Depth 5/1000 time = 4.992598533630371
I0123 19:16:05.521956 140567322951680 ddar.py:60] Depth 6/1000 time = 5.156267404556274
I0123 19:16:05.522193 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:16:05.522262 140567322951680 alphageometry.py:566] LM output (score=-2.786023): "m : T a c c m 17 ;"
I0123 19:16:05.522297 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c a c"

I0123 19:16:05.522335 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c a c ? perp a c c k"
I0123 19:16:05.522514 140567322951680 graph.py:498] 
I0123 19:16:05.522578 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c a c ? perp a c c k
I0123 19:16:06.190203 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6345658302307129
I0123 19:16:10.999939 140567322951680 ddar.py:60] Depth 2/1000 time = 4.8095855712890625
I0123 19:16:15.110279 140567322951680 ddar.py:60] Depth 3/1000 time = 4.110109806060791
I0123 19:16:20.147739 140567322951680 ddar.py:60] Depth 4/1000 time = 5.037266969680786
I0123 19:16:25.230295 140567322951680 ddar.py:60] Depth 5/1000 time = 5.081941366195679
I0123 19:16:30.554004 140567322951680 ddar.py:60] Depth 6/1000 time = 5.298951864242554
I0123 19:16:30.554280 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:16:30.554337 140567322951680 alphageometry.py:566] LM output (score=-2.791358): "m : D c e c m 17 D e g g m 18 ;"
I0123 19:16:30.554372 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_circle m g e"

I0123 19:16:30.554416 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m g e ? perp a c c k"
I0123 19:16:30.554604 140567322951680 graph.py:498] 
I0123 19:16:30.554669 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m g e ? perp a c c k
I0123 19:16:31.326502 140567322951680 ddar.py:60] Depth 1/1000 time = 0.737027645111084
I0123 19:16:35.290830 140567322951680 ddar.py:60] Depth 2/1000 time = 3.9642131328582764
I0123 19:16:40.779304 140567322951680 ddar.py:60] Depth 3/1000 time = 5.4882988929748535
I0123 19:16:46.276486 140567322951680 ddar.py:60] Depth 4/1000 time = 5.496985912322998
I0123 19:16:50.795349 140567322951680 ddar.py:60] Depth 5/1000 time = 4.518177509307861
I0123 19:16:56.394671 140567322951680 ddar.py:60] Depth 6/1000 time = 5.569339275360107
I0123 19:16:56.394895 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:16:56.394960 140567322951680 alphageometry.py:566] LM output (score=-2.814445): "m : T c h c m 17 ;"
I0123 19:16:56.394995 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c h"

I0123 19:16:56.395033 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c h ? perp a c c k"
I0123 19:16:56.395208 140567322951680 graph.py:498] 
I0123 19:16:56.395272 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c h ? perp a c c k
I0123 19:16:57.047269 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6168005466461182
I0123 19:17:01.792801 140567322951680 ddar.py:60] Depth 2/1000 time = 4.7454094886779785
I0123 19:17:05.937439 140567322951680 ddar.py:60] Depth 3/1000 time = 4.144451141357422
I0123 19:17:11.174242 140567322951680 ddar.py:60] Depth 4/1000 time = 5.2365782260894775
I0123 19:17:16.356489 140567322951680 ddar.py:60] Depth 5/1000 time = 5.1816041469573975
I0123 19:17:22.725384 140567322951680 ddar.py:60] Depth 6/1000 time = 6.34346866607666
I0123 19:17:22.725618 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:17:22.725696 140567322951680 alphageometry.py:566] LM output (score=-2.818419): "m : D c h c m 17 D e h e m 18 ;"
I0123 19:17:22.725733 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m e h"

I0123 19:17:22.725773 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m e h ? perp a c c k"
I0123 19:17:22.725945 140567322951680 graph.py:498] 
I0123 19:17:22.726009 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m e h ? perp a c c k
I0123 19:17:23.470484 140567322951680 ddar.py:60] Depth 1/1000 time = 0.707777738571167
I0123 19:17:29.612069 140567322951680 ddar.py:60] Depth 2/1000 time = 6.1414079666137695
I0123 19:17:39.262808 140567322951680 ddar.py:60] Depth 3/1000 time = 9.65045690536499
I0123 19:17:48.458895 140567322951680 ddar.py:60] Depth 4/1000 time = 9.195812463760376
I0123 19:17:57.497563 140567322951680 ddar.py:60] Depth 5/1000 time = 9.037822961807251
I0123 19:18:06.654966 140567322951680 ddar.py:60] Depth 6/1000 time = 9.117095947265625
I0123 19:18:06.655339 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:18:06.655428 140567322951680 alphageometry.py:566] LM output (score=-2.827427): "m : T e f f m 17 ;"
I0123 19:18:06.655462 140567322951680 alphageometry.py:567] Translation: "m = on_tline m f e f"

I0123 19:18:06.655517 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m f e f ? perp a c c k"
I0123 19:18:06.655699 140567322951680 graph.py:498] 
I0123 19:18:06.655762 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m f e f ? perp a c c k
I0123 19:18:07.350057 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6601085662841797
I0123 19:18:12.454516 140567322951680 ddar.py:60] Depth 2/1000 time = 5.104299068450928
I0123 19:18:16.762204 140567322951680 ddar.py:60] Depth 3/1000 time = 4.307384967803955
I0123 19:18:22.073753 140567322951680 ddar.py:60] Depth 4/1000 time = 5.311317443847656
I0123 19:18:27.374186 140567322951680 ddar.py:60] Depth 5/1000 time = 5.2997050285339355
I0123 19:18:32.859185 140567322951680 ddar.py:60] Depth 6/1000 time = 5.460098505020142
I0123 19:18:32.859417 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:18:32.859470 140567322951680 alphageometry.py:566] LM output (score=-2.851273): "m : C e h m 17 P e f h m 18 ;"
I0123 19:18:32.859505 140567322951680 alphageometry.py:567] Translation: "ERROR: Traceback (most recent call last):
  File "/home/chi/alphageometry-test/alphageometry.py", line 438, in try_translate_constrained_to_construct
    g.copy().add_clause(clause, 0, DEFINITIONS)
  File "/home/chi/alphageometry-test/graph.py", line 2570, in add_clause
    raise DepCheckFailError(
graph.DepCheckFailError: ncoll h e f
"

I0123 19:18:32.859548 140567322951680 alphageometry.py:566] LM output (score=-2.894353): "m : D c e c m 17 D c e e m 18 ;"
I0123 19:18:32.859576 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_circle m e c"

I0123 19:18:32.859610 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m e c ? perp a c c k"
I0123 19:18:32.859769 140567322951680 graph.py:498] 
I0123 19:18:32.859832 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_circle m e c ? perp a c c k
I0123 19:18:34.150298 140567322951680 ddar.py:60] Depth 1/1000 time = 1.2570762634277344
I0123 19:18:39.067827 140567322951680 ddar.py:60] Depth 2/1000 time = 4.9173500537872314
I0123 19:18:44.621969 140567322951680 ddar.py:60] Depth 3/1000 time = 5.553934812545776
I0123 19:18:49.098129 140567322951680 ddar.py:60] Depth 4/1000 time = 4.475954294204712
I0123 19:18:54.613847 140567322951680 ddar.py:60] Depth 5/1000 time = 5.515007972717285
I0123 19:18:59.094380 140567322951680 ddar.py:60] Depth 6/1000 time = 4.4786598682403564
I0123 19:19:04.536303 140567322951680 ddar.py:60] Depth 7/1000 time = 5.418670654296875
I0123 19:19:10.173998 140567322951680 ddar.py:60] Depth 8/1000 time = 5.627995729446411
I0123 19:19:10.174346 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:19:10.174427 140567322951680 alphageometry.py:566] LM output (score=-2.910346): "m : T c e e m 17 ;"
I0123 19:19:10.174461 140567322951680 alphageometry.py:567] Translation: "m = on_tline m e c e"

I0123 19:19:10.174511 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m e c e ? perp a c c k"
I0123 19:19:10.174686 140567322951680 graph.py:498] 
I0123 19:19:10.174746 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m e c e ? perp a c c k
I0123 19:19:11.050019 140567322951680 ddar.py:60] Depth 1/1000 time = 0.8477110862731934
I0123 19:19:17.815896 140567322951680 ddar.py:60] Depth 2/1000 time = 6.765752792358398
I0123 19:19:25.053490 140567322951680 ddar.py:60] Depth 3/1000 time = 7.237400770187378
I0123 19:19:32.424566 140567322951680 ddar.py:60] Depth 4/1000 time = 7.370824813842773
I0123 19:19:38.656049 140567322951680 ddar.py:60] Depth 5/1000 time = 6.2308080196380615
I0123 19:19:45.971664 140567322951680 ddar.py:60] Depth 6/1000 time = 7.287850618362427
I0123 19:19:45.971892 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:19:45.971962 140567322951680 alphageometry.py:566] LM output (score=-2.911147): "m : T b h l m 17 ;"
I0123 19:19:45.971997 140567322951680 alphageometry.py:567] Translation: "m = on_tline m l b h"

I0123 19:19:45.972033 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m l b h ? perp a c c k"
I0123 19:19:45.972207 140567322951680 graph.py:498] 
I0123 19:19:45.972271 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m l b h ? perp a c c k
I0123 19:19:46.618249 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6127815246582031
I0123 19:19:51.763672 140567322951680 ddar.py:60] Depth 2/1000 time = 5.145280122756958
I0123 19:19:57.253477 140567322951680 ddar.py:60] Depth 3/1000 time = 5.489579677581787
I0123 19:20:02.688646 140567322951680 ddar.py:60] Depth 4/1000 time = 5.43496561050415
I0123 19:20:08.222965 140567322951680 ddar.py:60] Depth 5/1000 time = 5.533639907836914
I0123 19:20:12.749056 140567322951680 ddar.py:60] Depth 6/1000 time = 4.503865003585815
I0123 19:20:12.749289 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:20:12.749351 140567322951680 alphageometry.py:566] LM output (score=-2.919001): "m : T a b a m 17 ;"
I0123 19:20:12.749387 140567322951680 alphageometry.py:567] Translation: "m = on_tline m a a b"

I0123 19:20:12.749426 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m a a b ? perp a c c k"
I0123 19:20:12.749606 140567322951680 graph.py:498] 
I0123 19:20:12.749679 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m a a b ? perp a c c k
I0123 19:20:13.456774 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6727888584136963
I0123 19:20:19.619489 140567322951680 ddar.py:60] Depth 2/1000 time = 6.162596225738525
I0123 19:20:25.204070 140567322951680 ddar.py:60] Depth 3/1000 time = 5.584397315979004
I0123 19:20:30.892297 140567322951680 ddar.py:60] Depth 4/1000 time = 5.687995195388794
I0123 19:20:36.502694 140567322951680 ddar.py:60] Depth 5/1000 time = 5.609706401824951
I0123 19:20:42.219216 140567322951680 ddar.py:60] Depth 6/1000 time = 5.69173789024353
I0123 19:20:42.219429 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:20:42.219499 140567322951680 alphageometry.py:566] LM output (score=-2.935256): "m : T c h k m 17 ;"
I0123 19:20:42.219536 140567322951680 alphageometry.py:567] Translation: "m = on_tline m k c h"

I0123 19:20:42.219575 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m k c h ? perp a c c k"
I0123 19:20:42.219739 140567322951680 graph.py:498] 
I0123 19:20:42.219802 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m k c h ? perp a c c k
I0123 19:20:42.887096 140567322951680 ddar.py:60] Depth 1/1000 time = 0.630319356918335
I0123 19:20:46.795103 140567322951680 ddar.py:60] Depth 2/1000 time = 3.907864570617676
I0123 19:20:52.027510 140567322951680 ddar.py:60] Depth 3/1000 time = 5.232162952423096
I0123 19:20:56.209458 140567322951680 ddar.py:60] Depth 4/1000 time = 4.181743144989014
I0123 19:21:01.372187 140567322951680 ddar.py:60] Depth 5/1000 time = 5.162087917327881
I0123 19:21:06.771966 140567322951680 ddar.py:60] Depth 6/1000 time = 5.3751842975616455
I0123 19:21:06.772232 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:21:06.772314 140567322951680 alphageometry.py:566] LM output (score=-2.941536): "m : D c e c m 17 T c l e m 18 ;"
I0123 19:21:06.772351 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c e, on_tline m e c l"

I0123 19:21:06.772397 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_tline m e c l ? perp a c c k"
I0123 19:21:06.772568 140567322951680 graph.py:498] 
I0123 19:21:06.772628 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c e, on_tline m e c l ? perp a c c k
I0123 19:21:07.529671 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7187731266021729
I0123 19:21:11.737461 140567322951680 ddar.py:60] Depth 2/1000 time = 4.207654714584351
I0123 19:21:17.362234 140567322951680 ddar.py:60] Depth 3/1000 time = 5.6245715618133545
I0123 19:21:23.105685 140567322951680 ddar.py:60] Depth 4/1000 time = 5.743262767791748
I0123 19:21:28.952981 140567322951680 ddar.py:60] Depth 5/1000 time = 5.847036123275757
I0123 19:21:34.752502 140567322951680 ddar.py:60] Depth 6/1000 time = 5.798664808273315
I0123 19:21:40.692578 140567322951680 ddar.py:60] Depth 7/1000 time = 5.908976316452026
I0123 19:21:40.697430 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:21:40.697506 140567322951680 alphageometry.py:566] LM output (score=-2.947422): "m : D c l c m 17 D j l j m 18 ;"
I0123 19:21:40.697544 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c l, on_circle m j l"

I0123 19:21:40.697582 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m j l ? perp a c c k"
I0123 19:21:40.697764 140567322951680 graph.py:498] 
I0123 19:21:40.697831 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m j l ? perp a c c k
I0123 19:21:41.471700 140567322951680 ddar.py:60] Depth 1/1000 time = 0.736987829208374
I0123 19:21:47.197979 140567322951680 ddar.py:60] Depth 2/1000 time = 5.726109743118286
I0123 19:21:53.921087 140567322951680 ddar.py:60] Depth 3/1000 time = 6.722785711288452
I0123 19:22:00.656199 140567322951680 ddar.py:60] Depth 4/1000 time = 6.734909772872925
I0123 19:22:07.437927 140567322951680 ddar.py:60] Depth 5/1000 time = 6.780991077423096
I0123 19:22:14.244573 140567322951680 ddar.py:60] Depth 6/1000 time = 6.782155275344849
I0123 19:22:22.250904 140567322951680 ddar.py:60] Depth 7/1000 time = 7.979399681091309
I0123 19:22:22.251132 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:22:22.251203 140567322951680 alphageometry.py:566] LM output (score=-2.967371): "m : T c g c m 17 ;"
I0123 19:22:22.251241 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c g"

I0123 19:22:22.251280 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c g ? perp a c c k"
I0123 19:22:22.251452 140567322951680 graph.py:498] 
I0123 19:22:22.251516 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c g ? perp a c c k
I0123 19:22:22.924813 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6389098167419434
I0123 19:22:26.859964 140567322951680 ddar.py:60] Depth 2/1000 time = 3.934985637664795
I0123 19:22:31.116119 140567322951680 ddar.py:60] Depth 3/1000 time = 4.255677223205566
I0123 19:22:36.266567 140567322951680 ddar.py:60] Depth 4/1000 time = 5.150266885757446
I0123 19:22:41.458687 140567322951680 ddar.py:60] Depth 5/1000 time = 5.19149374961853
I0123 19:22:46.897819 140567322951680 ddar.py:60] Depth 6/1000 time = 5.413553237915039
I0123 19:22:46.898117 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:22:46.898185 140567322951680 alphageometry.py:566] LM output (score=-2.976339): "m : D c l c m 17 D e l e m 18 ;"
I0123 19:22:46.898235 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c l, on_circle m e l"

I0123 19:22:46.898284 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m e l ? perp a c c k"
I0123 19:22:46.898459 140567322951680 graph.py:498] 
I0123 19:22:46.898522 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c l, on_circle m e l ? perp a c c k
I0123 19:22:47.659518 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7236957550048828
I0123 19:22:53.375031 140567322951680 ddar.py:60] Depth 2/1000 time = 5.715368986129761
I0123 19:23:00.204550 140567322951680 ddar.py:60] Depth 3/1000 time = 6.829339027404785
I0123 19:23:05.948233 140567322951680 ddar.py:60] Depth 4/1000 time = 5.743431568145752
I0123 19:23:13.722902 140567322951680 ddar.py:60] Depth 5/1000 time = 7.773886203765869
I0123 19:23:20.570197 140567322951680 ddar.py:60] Depth 6/1000 time = 6.825882434844971
I0123 19:23:26.524188 140567322951680 ddar.py:60] Depth 7/1000 time = 5.925203800201416
I0123 19:23:26.524534 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:23:26.524619 140567322951680 alphageometry.py:566] LM output (score=-2.984155): "m : D c h c m 17 T c l h m 18 ;"
I0123 19:23:26.524654 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_tline m h c l"

I0123 19:23:26.524705 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_tline m h c l ? perp a c c k"
I0123 19:23:26.524886 140567322951680 graph.py:498] 
I0123 19:23:26.524945 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_tline m h c l ? perp a c c k
I0123 19:23:28.337139 140567322951680 ddar.py:60] Depth 1/1000 time = 1.7763950824737549
I0123 19:23:33.818271 140567322951680 ddar.py:60] Depth 2/1000 time = 5.480962514877319
I0123 19:23:39.607288 140567322951680 ddar.py:60] Depth 3/1000 time = 5.788834810256958
I0123 19:23:45.547808 140567322951680 ddar.py:60] Depth 4/1000 time = 5.9402782917022705
I0123 19:23:51.544571 140567322951680 ddar.py:60] Depth 5/1000 time = 5.996472358703613
I0123 19:23:57.532572 140567322951680 ddar.py:60] Depth 6/1000 time = 5.987801790237427
I0123 19:24:03.555798 140567322951680 ddar.py:60] Depth 7/1000 time = 6.022554397583008
I0123 19:24:09.721648 140567322951680 ddar.py:60] Depth 8/1000 time = 6.138085603713989
I0123 19:24:09.725636 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:24:09.725700 140567322951680 alphageometry.py:566] LM output (score=-3.057235): "m : D c h c m 17 D l h l m 18 ;"
I0123 19:24:09.725735 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m l h"

I0123 19:24:09.725772 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m l h ? perp a c c k"
I0123 19:24:09.725949 140567322951680 graph.py:498] 
I0123 19:24:09.726012 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m l h ? perp a c c k
I0123 19:24:10.476446 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7136213779449463
I0123 19:24:16.018253 140567322951680 ddar.py:60] Depth 2/1000 time = 5.541689872741699
I0123 19:24:22.015845 140567322951680 ddar.py:60] Depth 3/1000 time = 5.997405290603638
I0123 19:24:29.137739 140567322951680 ddar.py:60] Depth 4/1000 time = 7.121660947799683
I0123 19:24:35.231477 140567322951680 ddar.py:60] Depth 5/1000 time = 6.093100309371948
I0123 19:24:41.477864 140567322951680 ddar.py:60] Depth 6/1000 time = 6.214246034622192
I0123 19:24:41.478101 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:24:41.478171 140567322951680 alphageometry.py:566] LM output (score=-3.057565): "m : D c h c m 17 D h l l m 18 ;"
I0123 19:24:41.478208 140567322951680 alphageometry.py:567] Translation: "m = on_circle m c h, on_circle m l h"

I0123 19:24:41.478246 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m l h ? perp a c c k"
I0123 19:24:41.478431 140567322951680 graph.py:498] 
I0123 19:24:41.478499 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_circle m c h, on_circle m l h ? perp a c c k
I0123 19:24:42.240996 140567322951680 ddar.py:60] Depth 1/1000 time = 0.7252590656280518
I0123 19:24:47.949230 140567322951680 ddar.py:60] Depth 2/1000 time = 5.70809006690979
I0123 19:24:54.012626 140567322951680 ddar.py:60] Depth 3/1000 time = 6.063194274902344
I0123 19:24:58.969392 140567322951680 ddar.py:60] Depth 4/1000 time = 4.956563949584961
I0123 19:25:06.074263 140567322951680 ddar.py:60] Depth 5/1000 time = 7.104193687438965
I0123 19:25:12.265363 140567322951680 ddar.py:60] Depth 6/1000 time = 6.15898871421814
I0123 19:25:12.265599 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:25:12.265672 140567322951680 alphageometry.py:566] LM output (score=-3.062762): "m : T c k c m 17 ;"
I0123 19:25:12.265711 140567322951680 alphageometry.py:567] Translation: "m = on_tline m c c k"

I0123 19:25:12.265748 140567322951680 alphageometry.py:576] Solving: "a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c k ? perp a c c k"
I0123 19:25:12.265913 140567322951680 graph.py:498] 
I0123 19:25:12.265981 140567322951680 graph.py:499] a b c = triangle a b c; d = midpoint d a c; e = midpoint e b c; f = lc_tangent f e b, on_line f a b; g = lc_tangent g d a, on_line g b a; h = lc_tangent h b f, on_line h e f; i = lc_tangent i a g, on_line i d g; j = foot j a b c; k = on_line k h i, on_line k a j; l = on_pline l c a b; m = on_tline m c c k ? perp a c c k
I0123 19:25:12.952470 140567322951680 ddar.py:60] Depth 1/1000 time = 0.6488473415374756
I0123 19:25:16.772275 140567322951680 ddar.py:60] Depth 2/1000 time = 3.8196654319763184
I0123 19:25:22.065259 140567322951680 ddar.py:60] Depth 3/1000 time = 5.292717933654785
I0123 19:25:26.308164 140567322951680 ddar.py:60] Depth 4/1000 time = 4.242638349533081
I0123 19:25:26.308936 140567322951680 alphageometry.py:221] DD+AR failed to solve the problem.
I0123 19:25:26.308991 140567322951680 alphageometry.py:585] Timeout.
